# ICARIA cookbook: recipes for data gap filling 

This chapter is dedicated to gathering a series of methodologies for data gap filling and data uncertainty methods compiled in a cookbook. It outlines data gap groups, data requirements, data collection templates, and sources, emphasizing the potential replicability of any of the methodologies in case studies or during lab tests. A series of approaches are provided to address data gaps and uncertainty, including but not limited to automated data downscaling, extrapolation, synthetic data generation, etc. focusing on data-driven methodologies and their applicability for addressing data gaps and uncertainty. Additionally, a domain users' survey based on ICARIA's internal and external network is compiled, from experts with diverse backgrounds, collecting key feedback on the current and emerging functionalities of data-driven methodologies that the experts are already using or considered to use. The survey can be treated as a recommendation tool for the CFs, promoting replication of ICARIA results beyond the case studies within the project.

## Cookbook structure and general template in Jupyter book 

A Jupyter Book is an open-source framework designed to serve as a generator of digital documents and books by integrating Jupyter Notebooks and Markdown files. It enables the seamless unification and presentation of data, code, and narrative text, making it highly suitable for interdisciplinary research and educational purposes. For combining climate resilience methodologies with data-driven techniques, the Jupyter Book will provide a structured environment for rendering extensive datasets, documenting analytical workflows, and coherently delivering results, ensuring replication, strengthening collaboration within the project, and fostering comprehensive dissemination of findings. In ICARIA, a supporting cookbook will be developed by collecting and compiling datasets and methodologies from the literature in a Jupyter notebook. This notebook will mirror the recipes listed in the initial *D1.3* document, creating a scaffold for a more rigid understanding of the data gaps, which will later inform the implementation of Trials and Mini-Trials, prioritizing which gaps tend to appear, yielding fruitful results when addressed with representative methods. More specifically the Jupyter book will be organized as follows: each section of the _D1.3_ document will be systematically transferred to the Jupyter book, with each section receiving its dedicated chapter. For Chapter 3, which enumerates the cookbook's recipes, distinct categories—statistical methods, dynamical downscaling methods, data-driven methodologies, expert elicitation methods, and uncertainty treatment methods—will each be allocated a dedicated subsection containing a detailed list of recipes. Representative information for each recipe, as presented in their designed tables, will be transferred to the appropriate subsection. Furthermore, the domain survey data, including the questionnaire, responses, and a summary of results, will be thoroughly documented. Finally, the chapter referring to the reflections on data gaps and supplementary information from the appendix will be incorporated to ensure a comprehensive and scientific presentation. The Jupyter book will be hosted in a GitHub repository, freely accessible, allowing for continuous updates and extensions of the content, besides easy access and modifications by the case study facilitators. A Figure of the footer of the <a href="https://georgiti.github.io/ICARIA-book/content/recipes/introduction/introduction.html" target="_self">Jupyter Book</a>  can be seen below.

![True color image](screenshot.322.jpg)

## Cookbook “_recipes_”
The following sections contain the technical specifications and tools selected from literature, organized taking into account the main underlying methodology with respect to those identified in Section 3, although it is worth noting that the case studies implementing the suggested “*recipes*” often adopt hybrid approaches, combining multiple methodologies.
 
#### Description of Recipe and Identification: 

Due to the interdisciplinary character and diverse areas of application of the methodologies attempting a totally rigid categorization would only add additional confusion, if not, being far from realistic. Thus, the categorization of the recipes within the cookbook was tailored to align with the project's objectives. As a result, a straightforward yet effective way to distinguish each recipe while providing a meaningful description was aimed. Each recipe is labeled using the following format: 
 *Recipe - [Category in Cookbook] [Number] [Secondary Category/Example] [Additional Characterization]* 
An example: a recipe categorized under downscaling methodologies, listed second, focused on statistical downscaling methods and identified as a review paper The unique label would be the following:  
Recipe CH01-DD-R, where: 
 - "*CH*" denotes {index}`Climate and Charge Hazard`(or EV denotes {index}`Exposure and Vulnerability data`),
 - "*01*" represents the unique number, 
 - “*DD*” representing data-driven methodologies (if any), and 
 - "*R*" is appended to indicate it is a review paper. 
Thus, all labels in recipes within the cookbook will follow the same manner, depending on the subsection and category they belong to. 

### Statistical methods

### Statistical downscaling methods

#### S1. Long-term daily stream temperature record for Scotland reveals spatio-temporal patterns in warming of rivers in the past and further warming in the future

|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Long-term daily stream temperature record for Scotland reveals spatio-temporal patterns in warming of rivers in the past and further warming in the future ({cite:p}`LOERKE2023164194`) [<a href="https://doi.org/10.1016/j.scitotenv.2023.164194" target="_self">Link</a>] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents a rigid methodology to estimate long-term daily stream temperature due to the scarcity of available datasets for creating a national daily stream water temperature dataset for Scotland. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Climatic and hydrological variables (e.g., air temperature, etc.).</li> <li>Harmonized monitoring scheme (HMS) dataset. </li> <li>National river flow archive (NRFA).  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul><li>CNNs, GLMs, XAIs. </li> <li>CNNs to statistically downscaled max and min temperatures over SSA (CNN-R: CNN model with non-linear configuration). </li> <li>"CNN showed good skills to produce plausible projections, however, differences with RAW and GLM in the intensity of the signal were identified when non-linearity was considered (CNN-R)" (sic). </li></ul></code></td> </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul><li>Outputs: (i) Estimation of long-term daily stream water temperature, (ii) Mean monthly and year precipitation maps, (iii) Environmental controls maps on studied variables, (iv) Average base flow index maps, (v) Forecasting of future stream water temperature (long-term daily records, etc.), (vi) Analysis of historical trends as coarser temporal resolution and future changes at high temporal resolution, (vii) Explore the role of controls for individual catchments. </li> <li>Temperature maps allowed for identification of the sites with the highest temperature increases, allowing for implementing thermal moderation measures to address this issue.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era-interim" target="_self">ERA-Interim analysis</a></li> <li><a href="https://esgf-node.llnl.gov/search/cmip5/" target="_self">"EC-Earth model simulations from the CMIP5 modelling experiment" (sic).</a></li> <li>"Suggestion: model uncertainty and multi-GCM ensembles with prospects to be further utilized in climate change studies over the region" (sic). </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; ML; Extreme temperature; GCMs; GLMs; CNNs. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code>Analyze historical trends and understand the role of environmental controls and the future changes under regional climate projections. </code></td> </tr> </tbody> </table> |

#### S2. Regional climate model emulator based on deep learning: concept and first evaluation of a novel hybrid downscaling approach

|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Regional climate model emulator based on deep learning: concept and first evaluation of a novel hybrid downscaling approach ({cite:p}`Doury2023`) [ <a href="https://doi.org/10.1007/s00382-022-06343-9">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a hybrid downscaling methodology to extend the high-resolution RCM simulation ensembles at a reasonable cost and identify sources of uncertainty.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Daily near-surface temperature from EUR11-CORDEX simulations based on the CNRM-ALADIN63 regional climate model driven by the CNRM-CM5 global climate model used in CMIP5.</li> <li>The historical period runs from 1951-2005.</li> <li>Scenarios (2006-2100) are based on RCP4.5 and RCP8.5.</li> <li>2D: (i) Geopotential, (ii) Humidity, (iii) Temperature, (iv) Ward wind, and (v) Sea level pressure. </li> <li>1D: (i) Digital spatial means of 2D, (ii) Daily spatial standard deviation of 2D, (iii) Solar and ozone forces, and (iv) Seasonal indicators.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>The RCM-emulator is based on a fully convolutional neural network algorithm, called UNet.</li> <li>Evaluation both on perfect model and GCM worlds.</li> <li>Reproduces the high-resolution spatial structure and daily variability of the RCM.</li> <li>Issues reproducing accurate simulations of extreme events.</li> <li> Issues reproducing the complete climate change magnitude. </li> <li> RCM's general functioning can be broken down into two parts: a large-scale transformation and a downscaling function. </li> <li> A novel hybrid downscaling approach that emulates the downscaling function of an RCM. </li> <li> The combination of both empirical statistical downscaling methods and RCMs is part of the novelty of this recipe. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Transformation from low resolution information to the high resolution near surface temperature.</li> <li>Aiming at the feasibility to emulate the RCM complexity at high-frequency and high-resolution.</li> <li>RCM-GCM inconsistencies at large scales.</li> <li> A high-resolution simulation is provided by the emulator, corrected from the GCM-RCM large-scale inconsistencies. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Relevant projects: <a href="https://www.eucp-project.eu/#:~:text=EUCP%20(European%20Climate%20Prediction)%20is,producing%20some%20of%20this%20information.">EUCP European Climate Prediction System</a> </li> <li> <a href="https://github.com/antoinedoury/RCM-Emulator">RCM-Emulator: Code and data to build and train the emulator</a></li><li>Supplementary information: summary tables of the different tests performed with the UNet-based emulators. </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td>Emulator; Hybrid downscaling; RCMs; Statistical downscaling; Deep neural network; Machine Learning; EURO-CORDEX.</td> </tr> <tr> <td>Tag/Type</td> <td>Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td >Potential use in ICARIA: Emulating the downscaling function of an RCM to improve the resolution of climate change data in case study areas.</td></tr></tbody></table> |

#### S3. Bayesian analysis of high-frequency water temperature time series through Markov switching autoregressive models
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Bayesian analysis of high-frequency water temperature time series through Markov switching autoregressive models ({cite:p}`SPEZIA2023105751`) [ <a href="https://doi.org/10.1016/j.envsoft.2023.105751" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a methodology based on autoregressive models for the estimation of water temperature time series. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S3 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>River temperature (along with covariates: flow, air temperature, rainfall, wind speed and direction, radiation, and soil temperature).</ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Methods: (i) Bayesian interference, (ii) Markov chain Monte Carlo (MSMC), and (iii) Metropolis-Kuo-Mallick (MKMK) method, and (iv) (Non-homogeneous) MSARMs (Markov switching autoregressive models). </li> <li>MSARMs allow: (i) Discrete-time stochastic process, (ii) Modelling non-linear and non-normal time series by assuming that different autoregressions, each one depending on a hidden state, alternate according to the Markovian regime switching, and (iii) Classifying the observations into a small number of homogeneous groups, labeled as the regimes of the Markov chain.</li> <li>Observed state-dependent autoregressive processes driven by an unobserved, or hidden, Markov chain, Markov switching autoregressive models.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Methods to reconstruct high-frequency time series. </li> <li>Bayesian model to study the dynamic evolution of water temperature. </li> <li>MSARMs can be improved using filly Gibbs sampling algorithms avoiding the random walk Metropolis moves.</li> <li>Data augmentation techniques can be further applied to non-homogeneous hidden Markov chains to extend the model.</li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://doi.org/10.6084/m9.figshare.21801004">MSARMS Codes</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time-series; Non-linearity; Stochastic variable selection; missing values.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess river water temperature variation as source of hazard of natural ecosystems.</code></td> </tr> </tbody> </table> |

#### S4. High-resolution downscaling with interpretable deep learning: Rainfall extremes over New Zealand
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> High-resolution downscaling with interpretable deep learning: Rainfall extremes over New Zealand ({cite:p}`RAMPAL2022100525`) [ <a href="https://doi.org/10.1016/j.wace.2022.100525">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This methodology tests deep learning techniques against existing statistical approaches for downscaling historical rainfall events. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S4 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Gridded rainfall from Virtual Climate Station Network (VSCN).</li> <li>Variables: Consecutive available potential energy, Mean Sea level pressure, Specific humidity, Temperature, Wind, Geopotential height, and Precipitation.</li> <li>Time periods: (i) Training period: 1980-2012, (ii) Validation period: 2013–2016, and (iii) Testing period: 2017–2020.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Linear statistical models: Principal component analysis (PCA) for geopotential height and air temperature. </li> <li>Candidate predictor variables: Geopotential height, air temperature, zonal wind, meridional wind, wind speed, and geostrophic vorticity. </li> <li>Deep learning/Evaluated models: (1) CNNs: (i) Models: Non-linear CNN Gamma, Linear CNN, Non-Linear Gamma, Linear Gamma, and Linear dense.</li> <li>Interpretable deep learning ("explainable AI"): (1) Grad-CAM, and (ii) Able to target the most relevant meteorological features for predicting extreme rainfall events.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Simple CNNs with traditional encoder-decoder structure provide superior results over other more recent networks. </li> <li>The deep learning framework improves rainfall downscaling, the largest for extreme rainfall events.</li> <li>The best CNN model outperforms existing statistical approaches (temporal variability and mean and extreme rainfall). </li> <li>Maps of extreme events for the Grad-CAM+ model were provided. </li> <li>Prediction of rainfall and extreme rainfall events (downscaling rainfall).</li> <li>The potential applicability of other types of networks e.g., conditional generative adversarial networks cGANs (unsupervised) is mentioned.</li> <li>Limitations: (i) Temporal relationships in data are not captured by CNNs, (ii) VCSN is known to have rainfall biases when the observation network is sparse, (iii) CNNs provide dry bias for extreme rainfall, and (iv) Due to limitations of input (e.g., historical data), these methods might not capture non-stationary processes.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://github.com/sicara/tf-explain">The Grad-CAM interpretable deep learning code</a></li><li><a href="https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels">ERA5 analysis, C3S </a></li><li>"The VCSN data is developed and maintained by NIWA and can be obtained through a data access agreement through correspondence with the authors" (sic)</li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; Deep learning; Machine learning; Precipitation extremes; Rainfall. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Hazard characterization of extreme precipitation events.</code></td> </tr> </tbody> </table> |

#### S5. Dasymetric Mapping of Population Using Land Cover Data in JBNERR, Puerto Rico during 1990–2010
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dasymetric Mapping of Population Using Land Cover Data in JBNERR, Puerto Rico during 1990–2010 ({cite:p}`land11122301`) [ <a href="https://doi.org/10.3390/land11122301">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe provides a methodology to estimate the spatial population of an area and was proposed as a solution when critical data are scarce.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S5|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Total population, (ii) Land cover datasets (high-resolution), and (ii) Raster data (climate parameters). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A dasymetric mapping methodology for enhancing population spatial data by using various geospatial sources to produce a European Union-wide dataset of population variations. <ul><li>(i) Target zone estimation, (ii) Density estimation of ancillary class, and (iii) Error estimation. </li></ul></li> <li>The methodology combines widely available geospatial data like CLC, Openstreet map, and Copernicus Land Monitoring Service datasets (European Settlement Maps) with third-party datasets (Multinet, ToMTom datasets) and statistical data from EUROSTAT in a novel approach to map daytime population dynamics</li> <li>The approach can be used to enhance other data more relevant to disaster response or impact mapping.</li><li>The proposed methodology can be a general-use methodology for enhancing/improving sectorial data used in climatic scenarios. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) The multi-temporal population grids for the European Union at 1 km2 resolution that have been generated during this study have been deposited in the European Commission’s Joint Research Centre Data Catalog, with an identifier, and can be accessed at ENACT-POP R2020A - ENACT 2011 Population Grid, (ii) Dasymetric mapping error assessment, (iii) Maps of dasymetric population. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://doi.org/10.1038/s41467-020-18344-5">Uncovering temporal changes in Europe’s population density patterns using a data fusion approach</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Intelligent Dasymetric mapping (IDM); Land use; Land cover; Census Data. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Categorizing population data with respect to land cover information.</code></td> </tr> </tbody> </table> |


#### S6. Climate change and energy performance of European residential building stocks – A comprehensive impact assessment using climate big data from the coordinated regional climate downscaling experiment
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Climate change and energy performance of European residential building stocks – A comprehensive impact assessment using climate big data from the coordinated regional climate downscaling experiment ({cite:p}`YANG2021117246`) [ <a href="https://doi.org/10.1016/j.apenergy.2021.117246">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers an impact assessment of climate change on the energy performance of residential building stocks considering different climate scenarios. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-S6|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul>  <li> Numerical energy simulations for building stocks. </li> <li>Gathering data using: (i) Tabula webtools, and (ii) "EPISCOPE".</li> <li>Measure of energy performance of buildings: Cooling and heating demands estimations. </li> <li>Future climate datasets.</li> <li>Future climate scenarios periods: 2010–2039 (near-term or NT), 2040–2069 (medium-term or MT), and 2070–2099 (long-term or LT).</li> <li>Climate data synthesized: (i) RCA4, (ii) RCPs: RCP 2.6, RCP 4.5, and RCP 8.5, (iii) Spatial resolution of 12.5 km and temporal resolution of 15 min, and (iv) GCMs: Centre National de Recherches Météorologiques Climate Model 5 (CNRM-CM5), Irish Centre for High-End Computing model (ICHEC-EC-EARTH), Institut Pierre Simon Laplace model (IPSL-CM5A-MR), Met Office Hadley Centre model (MOHC-HadGEM2-ES), and Max Planck Institute model (MPI-ESM-LR). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li> Models the energy and performance in IDA Indoor Climate and Energy (IDA ICE). </li><li>It uses the Intergovernmental Panel on Climate Change (IPCC) Third Assessment Report model summary data of the HadCM3 A2 experiment ensemble which is available from the IPCC Data Distribution Centre (IPCC DDC). </li> <li>The tool transforms ‘present-day’ EPW weather files into climate change EPW or TMY2 weather files which are compatible with most building performance simulation programs.</li> <li>Future climate scenarios are simulated using GCMs</li> <li>Dynamically downscaled weather data generated by RCMs.</li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul><li> Output: (i) Annual average of heating and cooling demand, (ii) Forecasting of weather conditions (e.g., temperature distribution, etc.), (iii) Forecasting of averages for heating demands, (iv) Forecasting of averages for cooling demands, (v) Indoor thermal comfort based on different RCPs. </li><li>The framework focuses on building energy performance case studies and on solutions for reducing energy demands. </li> <li>The vulnerability of cities to climate change based on the indoor thermal comfort is also considered and estimated.</li> <li>Short- and long-term climate variations and extremes should be considered when assessing energy demands and building performance.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://energy.soton.ac.uk/climate-change-world-weather-file-generator-for-world-wide-weather-data-ccworldweathergen/">CCWorldWeatherGen</a></li><li><a href="https://unfccc.int/topics/resilience/resources/climate-related-risks-and-extreme-events">Climate-related risks and extreme events </a></li><li><a href="https://www.eea.europa.eu/en/analysis/indicators/total-greenhouse-gas-emission-trends">Total net greenhouse gas emission trends and projections in Europe</a></li><li><a href="https://www.hse.gov.uk/temperature/thermal/index.htm">Thermal comfort </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Climate change; Extreme Events; Energy performance of buildings; Thermal comfort; Assets.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Correlate climate change trends with variation of seasonal energy needs. Incorporate in assets’ data attributes the estimate of energy performance and related cost.</code></td> </tr> </tbody> </table> |


#### S7. Comparison of stochastic and machine learning methods for multi-step ahead forecasting of hydrological processes
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Comparison of stochastic and machine learning methods for multi-step ahead forecasting of hydrological processes ({cite:p}`Papacharalampous2019`) [ <a href="https://doi.org/10.1007/s00477-018-1638-6">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe compares stochastic and data-driven methods for multi-step forecasting via computational experiments using simulated time series and real-world river discharge data </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S7|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Framework for evaluating forecasting methods in hydrology; River discharge forecasting.</li> <li>Simulation of time series using stochastic models.</li> <li>Mean annual river discharge time series.</li> <li> Hydrological variables at large time scales. </li><li>Input: (i) 12,000 simulated and 92 monthly streamflow time series, (ii) 6,000 simulated, (iii) 135 annual temperature time series, (iv) 24,000 simulated, 185 annual temperature, and (v) 112 annual precipitation time series.</li></ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Comparison between stochastic and data-driven methods for the forecasting of hydrological processes based on large-scale simulations.</li> <li>Time series forecasting can be classified into eight categories: (1) Exponential smoothing, (2) ARIMA, (3) Seasonal models, (4) State space and structural models and the Kalmar filter, (5) Nonlinear models, (6) Long-range dependence models, e.g., the family of Autoregressive Fractionally Integrated Moving Average (ARFIMA) models, (7) Autoregressive Conditional Heteroscedastic/Generalized Autoregressive Conditional Heteroscedastic (ARCH/GARCH) models, and (8) Count data forecasting. </li> <li>Simulated processes: (i) ARMA (p,q), and (ii) ARFIMA (p.q.d).</li> <li>Real-time world series: (i) Mean annual river discharge time series, (ii) Autocorrelation Function (ACF), (iii) Partial Autocorrelation Function (PACF), and (iv) Hurst–Kolmogorov (HK). </li> <li>(a) Forecasting methods: (1) Stochastic methods: (i) Packages: arfima, Arima, auto_arima, BATS, ets, forecast, rwf, ses theta, and built-in-R functions, (ii) Naive forecasting method, and (iii) Random Walk forecasting method. (b) Data-driven methods: (i) Random Forest, (ii) NN, RF, SVM; package: ksvm, and (iii) Utilization of a single hidden-layer Multilayer Perceptron (MLP). </li> <li>Evaluation criterion for the models: (i) Type 1 accuracy: the closeness of the forecasted time series to the target time series, (ii) Type 2: the closeness of the mean of the forecasts to the mean of the target value.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Stochastic generation of weather data. </li> <li>Benchmark information is available for methodologies in this recipe.</li> <li>Heatmaps of the average-case performance of the forecasting methods. </li> <li>In total, ML models are more likely to outperform the stochastic methods in terms of accuracy and computational costs, remaining prone to their own limitations. </li><li>Models applied for forecasting can be transferred for studying hydrometeorological concepts. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>R packages: Cgwtools, Devtools, EnvStats, Forecast, Fracdiff, Gdata, HKprocess, Knitr, Plyr, Readr, Rminer,Tidyr, hydroGOF. </li><li>No free lunch theorem – <a href="http://blog.drhongtao.com/">Blog source</a>.</li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">No free lunch theorem; Random Forests; River discharge; Support Vector Machines; Time series. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td> <td><code>Improve local climate change information through stochastic and data-driven approaches, focused on hydrological processes but transferable to other relevant variables.</code></td> </tr> </tbody> </table> |


#### S8. Downscaling probabilistic seasonal climate forecasts for decision support in agriculture: A comparison of parametric and nonparametric approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Downscaling probabilistic seasonal climate forecasts for decision support in agriculture: A comparison of parametric and nonparametric approach ({cite:p}`HAN201751`) [ <a href="https://doi.org/10.1016/j.crm.2017.09.003">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents two downscaling methodologies, parametric and non-parametric, which are compared for seasonal rainfall forecasts, and their performance for stable simulations of the total rainfall distributions is explored.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S8 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Seasonal rainfall and its characteristics. </li> <li>Downscale scenarios: (i) Frequency-only (π-only), (ii) rainfall amount 0nly (Rm-only), (iii) rainfall intensity (μ-only), (iv) both rainfall frequency and intensity（π-μ), (v) rainfall frequency and constraining total rainfall (Rm-μ), and (vi) rainfall intensity and constraining total rainfall (Rm -μ). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Stochastic non-parametric temporal downscaling method – FResampler1: (i) Based on the concept of "conditional block sampling", and (ii) Disaggregate SCF (seasonal climate forecasts) to daily weather realizations. </li> <li>Parametric downscaling method – predictWTD; Based on conditional stochastic weather generator. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Sensitive to data volume, sampling size, and number of realizations (requirement for stochastic models). </li> <li>FResampler1 performs equally well to the parametric predictWTD method, captures seasonality and temporal correlation structure of data, remains sensitive to the number of realizations and to data availability. </li> <li>The predictWTD remains sensitive to the length of observed data, not sensitive to number of realizations, and required longer periods of observations for rainfall amount or conditioning or intensity. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="http://iri.columbia.edu/">IRI Net Assessment Seasonal Climate Forecast </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Stochastic disaggregation; Probabilistic seasonal climate forecast; Parametric downscaling; Non-parametric downscaling; Rainfall. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Probabilistic non-parametric downscaling methodology for seasonal climate forecasts.</code></td> </tr> </tbody> </table> |


#### S9. An R package for daily precipitation climate series reconstruction
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> An R package for daily precipitation climate series reconstruction ({cite:p}`SERRANONOTIVOLI2017190`) [ <a href="https://doi.org/10.1016/j.envsoft.2016.11.005">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers the technical characteristics of an open-source package written in R language for treating large data gaps, applied to sample precipitation datasets. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S9|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: Daily precipitation (complete precipitation datasets). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Treating large data gaps.</li> <li>"*The observatories were located at less than 20 km and with a correlation of more than 0.7, else to meet the necessary requirements, the radius of proximity was recursively extended by 5km.*"</li> <li>A multiple linear regression was performed with the data all observatories had in common.</li> <li>The gaps of the standard observatory that are empty were filled in with data from the other observatories.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>"*Closest-correlated neighbor*" weather data gap-filling methodology". </li> <li>Data gap-filling for weather observations used by FIC in ICARIA.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Related projects: Junta de Andalucía SICMA Climate Change local scenarios </li> <li><a href="https://cran.r-project.org/web/packages/reddPrec/index.html">reddPrec package  </a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">reddPrec; Daily precipitation; Quality control; Missing values.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Generation of complete daily weather series (no gaps) for improved assessment of past climate in ICARIA case study areas and development of statistical downscaling.</code></td> </tr> </tbody> </table> |


#### S10. Description and validation of a two-step analogue/regression downscaling method
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Description and validation of a two-step analogue/regression downscaling method ({cite:p}`Ribalaygua2013`) [ <a href="https://doi.org/10.1007/s00704-013-0836-x">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces a two-step analogue statistical downscaling method for daily temperature and precipitation, and accurately simulates the past climate on a local scale in the studying areas.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S10|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Surface observation Data (vector data) is combined with. ERA5-Land reanalysis datasets (raster data); Low resolution data are sourced from an observed reference dataset – ERA40 Reanalysis (atmospheric dataset). </li> <li>10 CMIP6 Global Climate Models + 4 Tier 1 SSP's.</li> <li>Local downscaled climate projections at point (observation) scale.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>FICLIMA two-step analogue/regression downscaling method. </li> <li>Estimates high-resolution surface meteorological fields for a day “x”, in two steps:<ul><li>The first step is an analogue technique better adapted and improved. </li><li>In the second step, high-resolution surface information is estimated differently for precipitation (using a probabilistic approach) and temperature (using multiple linear regression). </li></ul> </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Problems addressed in this recipe: (i) Changeable relationships between predictors and predictands (including non-linear ones), (ii) Predictors are simulated by the GCMs. </li> <li>Output: Simulation of precipitation and temperature (spatial distribution of verification metrics for the studied variables (max and min temperature and precipitation). </li> <li>Advantages: (i) Low computational cost, (ii) Microclimatic features are implicit, (iii) Good verification results (e.g., full range of data variability is considered). </li> <li>Limitations: (i) Historical observations of the variables are needed, (ii) Spatial and temporal inconsistencies cannot be eliminated, (iii) Non-stationary problem in the predictors-predictands relationships cannot be excluded, and (iv) Autumn precipitation in Mediterranean areas is poorly estimated. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="http://www.ecmwf.int/research/era/do/get/era-40">ERA40- Reanalysis </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; Mean absolute error; Analogue techniques. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands. </code></td> </tr> </tbody> </table> |


#### S11. Weather Data Quality Control | Weather data temporal extension methodology
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td>  <ul> <li>Weather Data Quality Control; Weather Observations Homogeneisation Techniques</li> <li>Weather data temporal extension methodology; Mainstream (traditional) gap filling methods ({cite:p}`hess-16-3383-2012`)[ <a href="https://cordis.europa.eu/project/id/700174">Link</a> ] </li> </ul> </td> </tr> <tr> <td>Summary</td> <td> These recipes offer techniques for data-gap filling in meteorological data.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S11|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Raw weather observations (A). </li> <li>Quality-treated weather observations (A).</li> <li>Weather data with the presence of data gaps not covering all the time desired (B).</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li><ul> (A) <li>A two-way quality control methodology is applied to all weather data sources prior to their use: (i) Basic consistency. Direct rejection of self-evident wrong values, and (ii) Atypical values or ‘outliers. Unusual values within a data set. </li> <li>The way to proceed with the homogeneity test is based on the following methodology (see ref. in "*References/Useful Links*" section): (i) To quantify the similarity between data across different years, a distribution comparison test based on the Kolmogorov-Smirnov (KS) test is used, (ii) The KS test is a non-parametric statistical test which provides a p-value that can be used as a measurement of the similarity between two years., (iii) The lower the value for Log (KS), the greater the probability of inhomogeneity between two consecutive values, (iv) If one year has been selected as a possible indicator of inhomogeneity, then it is subjected to another test (“*Similarity between years*”), and (v) If a jump or a break shows up between p-values in the selected years, there is a true inhomogeneity for all the series. </li> </ul></li> <li><ul>(B)<li>Depending on the circumstances the use of a temporally homogeneous weather dataset is mandatory.</li> <li>Temporal extension of the weather data is performed using a climate reanalysis, the ERA5-Land. </li> <li>Reanalysis is crossed with the weather observations.</li><li>Corrected simulated observation is crossed and filled with the original observation obtaining the original checked weather observation with gaps filled. </li><li>Voronoi polygons to determine the buildings supplied by the substations: (i) Substitution: the water distribution system layout was missing therefore the road layout was used instead assuming that the water network followed its layout, (ii) Logical rule-based reasoning: used for the burst locations (sewers overload), and (iii) Approach based on similar historical events previously within the city or in other areas with similar conditions is explored. </li></ul></li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Quality checking performed by FIC in ICARIA for all the weather data gathered (A).</li> <li>Homogenization techniques performed by FIC in ICARIA for all the weather data gathered (A). </li> <li>Data gap-filling for weather observations used by FIC in ICARIA (B). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://zenodo.org/records/6525733">Detection of inhomogeneities in daily data: a test based on the Kolmogorov-Smirnov goodness-of-fit test. </a></li><li>Relevant projects: RESCCUE D3.2. deliverable. Tools with updated impact assessment models (A, B). </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Weather observations; Kolmogorov-Smirnov test; Data gaps.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Creation and checking of extended weather observations for improved assessment of past climate in ICARIA case study areas and development of statistical downscaling.</code></td> </tr> </tbody> </table> |


#### S12. A three-dimensional gap filling method for large geophysical datasets: Application to global satellite soil moisture observations
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A three-dimensional gap filling method for large geophysical datasets: Application to global satellite soil moisture observations ({cite:p}`WANG2012139`) [ <a href="https://doi.org/10.1016/j.envsoft.2011.10.015">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents an efficient method for handling large spatio-temporal datasets introduced and applied to a global soil moisture product from remote sensing images. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S12|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Works for large spatiotemporal datasets (both spatial & temporal variability). </li> <li>Global volumetric soil moisture product (satellite) with the Land Parameter Retrieval Model (LRM) (2003-2009). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A penalized least square method based on three-dimensional discrete cosine transforms (DCT-PLS), for the purpose of filling data gaps in large spatio-temporal datasets (for example: soil moisture satellite data) is introduced. </li> <li>This DCT-PLS method has some novel features with respect to other gap-filling methods. <ul> <li>It is a method of full three-dimensionality, and thus </li> <li>explicitly utilizes both spatial and temporal information of the dataset to derive the statistical model and </li> <li>Predict the missing values. Instinctively. </li> </ul></li> <li>This strategy is preferable for spatio-temporal datasets rather than using only spatial or temporal modelling. <li> The method utilized both spatial and temporal information of the moisture dataset. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>The statistical modelling process is completely controlled by one smoothing parameter which is easy to specify and eliminates the need for complicated model parameterizations. </li> <li>DCT-PLS provides estimation with small errors for the global moisture dataset and can be used to fill in missing values. </li>  </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="http://www.biomecardio.com/matlab/smoothn.html">BiomeCardio (Matlab package).  </a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Remote sensing; Soil moisture; Gap filling; Penalized least square regression; Discrete cosine transform.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving quality of heat and flood hazard assessment introducing soil moisture as key variable.</code></td> </tr> </tbody> </table> |


#### S13. Spatial interpolation techniques for climate data in the GAP region in Turkey
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Spatial interpolation techniques for climate data in the GAP region in Turkey ({cite:p}`Apaydin2004`) [ <a href="https://doi.org/10.3354/cr028031">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe provides a benchmark for identifying the optimal methodology for interpolating the spatial distribution of a specified set of tested climate parameters through geostatistical interpolation techniques. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-S13|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Climate parameters: (i) Solar radiation, (ii) Sunshine duration, (iii) Temperature, (iv) Relative humidity, and (v) Wind speed and (vi) rainfall. </li> <li>Long-term yearly predicted temperature maps. </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Interpolation techniques: (1) Inverse distance weighted (IDW), (2) Global polynomial interpolation (GPI), (3) Local polynomial interpolation (LPI), (4) Completely regularized spline (CRI), (5) Cokriging, and (6) Kriging with four subtypes: (i) Ordinary kriging (KO), (ii) Simple kriging (KS), (iii) Universal kriging (KU), and (iv) Disjunctive kriging (KD). </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of long-term yearly predicted temperature in the studied area. </li> <li>Spatial interpolation techniques are utilized for distribution of climate parameters. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Spatial interpolation; Inverse distance weighted; Polynomial interpolation; Kriging; Cokriging; Completely regularized spline.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improved mapping of local climate change hazard conditions and of critical variables for exposure and vulnerability assessment through geostatistical interpolation techniques.</code></td> </tr> </tbody> </table> |

 
### Dynamical downscaling methodologies

#### D1. A simple hybrid statistical–dynamical downscaling method for emulating regional climate models over Western Europe. Evaluation, application, and role of added value?
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A simple hybrid statistical–dynamical downscaling method for emulating regional climate models over Western Europe. Evaluation, application, and role of added value? ({cite:p}`Boe2023`) [ <a href="https://doi.org/10.1007/s00382-022-06552-2">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes an emulation methodology which is based on a hybrid statistical-dynamical approach based on analogues to simulate regional climate models.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, and (ii) Precipitation Data. </li> <li>RCMs from Euro-CORDEX at 12km resolution. </li> <li>Scenario: RCP8.5. </li> <li>Regional simulations: (1) CNRM-CM5 GCM from CMIP5 downscaled using three regional simulations with the GCM/RCM mode and the RCM/RCM mode, (2) RCM/RCM mode to downscale from CMIP6, and (3) Historical and ssp5-8.5 simulations from the thirteen CMIP6 models. </li></ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A hybrid statistical–dynamical downscaling method: (i) Statistical model based on the results of RCMs, (ii) Applied to downscale GCMs, (iii) Aims to emulate regional climate models, and (iv) It does not require the stationarity assumption of statistical downscaling.</li> <li>Emulate RCM results, based on the constructed analogues approach. </li> <li> Estimation method based on constructed analogues:  </li><li><ul> <li>Analogues of large-scale predictors from a low-resolution climate projection are considered: for high-resolution precipitation (temperature), the chosen predictor is low-resolution precipitation (temperature). </li> </ul></li> <li>Emulated models: (1) the GCM/RCM mode: "Fine-Scale Ref is a high-resolution regional climate simulation and Coarse-scale its driving GCM" (*sic*), and (2) the RCM/RCM mode: "*Coarse-Scale Ref is simply the Fine-Scale Ref simulation aggregated on the low-resolution grid of the model to be downscaled (Mod)*" (*sic*). </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Novelty: the analogues are searched within an RCM and therefore both in the past and the future climate. </li> <li>The hybrid method is shown to reproduce climate change signals very well and to outperform a conventional statistical downscaling method.</li> <li>"*Emulation methods make it possible to downscale very large ensembles of global climate projections and therefore to fully explore the uncertainties involved in regional climate changes*" (sic). </li> <li>"*In the RCM/RCM mode, the climate change signal at large scale of the original GCM is very well captured by the hybrid statistical downscaling method, independently of its magnitude*" (*sic*).</li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Euro-CORDEX regional climate projections: <a href="https://esgf.llnl.gov/">Earth System Grid Federation </a></li> <li>Constructed analogues method links:  <ul> <li><a href="https://doi.org/10.3402/tellusa.v46i3.15481">Searching for analogues, how long must we wait? </a> </li> <li><a href="https://doi.org/10.5194/hess-12-551-2008">Utility of daily vs. monthly large-scale climate data: an intercomparison of two statistical downscaling methods. </a> </li><li><a href="https://doi.org/10.5194/hess-14-1125-2010">The utility of daily large-scale climate data in the assessment of climate change impacts on daily streamflow in California. </a> </li><li><a href="https://doi.org/10.5194/hess-20-1483-2016">Hydrologic extremes – an intercomparison of multiple gridded statistical downscaling methods. </a> </li></ul> </li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">RCMs; Hybrid statistical dynamical downscaling; Climate change; Emulation. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Emulating the downscaling function of an RCM and improving resolution of climate change data.</code></td> </tr> </tbody> </table> |


#### D2. Dynamical and statistical downscaling of SSPs in AMB
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of SSPs in AMB ({cite:p}`arsinoe`) [ <a href="https://arsinoe-project.eu/">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Dynamical and statistical downscaling methods are employed to combine SSPs and RCPs with land use cover temporal series data and obtain future projection scenarios.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Land use cover changes.</li> <li>Ease of change data.</li> <li>Qualitative and quantitative drivers.</li><li>Observed land uses for each time series.</li><li>Land use demands.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>iCLUE/CLUEMONDO model for future land use projections simulation.</li> <li>Dynamical Downscaling combining RCPs and SSPs scenarios.</li> <li>CORINE land use cover provides land use time series data (with satellite quality)  to feed the projection models.</li><li>SSPs provide a framework to integrate the future socioeconomic pathways in a RCP environment to approach a more realistic projection.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: Future land use projections with integrated information about the different socioeconomic and climatic scenarios adjusted to a more accurate downscaled geographical case study.</li> <li>In contrast with previous methodologies, this method provides a framework for the integration of socioeconomic scenarios to the simulation parameters.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <li>Relevant projects: <a href="https://arsinoe-project.eu/">ARSINOE, </a><a href="https://www.sciencedirect.com/science/article/pii/S004896971830439X?via%3Dihub">Huber García, V., Meyer, S., Kok, K., Verweij, P., and Ludwig, R. (2018). Deriving spatially explicit water uses from land use change modelling results in four river basins across Europe. Science of The Total Environment, 628-629, 1079-1097. https://doi.org/10.1016/j.scitotenv.2018.02.051. </a></li> <li><a href="https://www.idescat.cat/pub/?id=ep&lang=es">IDESCAT Population Data </a></li><li><a href="https://www.idescat.cat/indicadors/?id=aec&n=15336&lang=es">IDESCAT GDP (province and councils) </a></li><li><a href="https://centrodedescargas.cnig.es/CentroDescargas/index.jsp">IGN CORINE land cover (time series) </a></li><li><a href="https://land.copernicus.eu/en/products/corine-land-cover">CORINE land cover CORINE land cover (metadata) </a></li> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Socioeconomic projections (SSPs), Downscaling, RCPs, AMB, Land Use Cover, Climatic projections.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands.</code></td> </tr> </tbody> </table> |


#### D3. Dynamical and statistical downscaling of seasonal temperature forecasts in Europe: Added value for user applications
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of seasonal temperature forecasts in Europe: Added value for user applications ({cite:p}`MANZANAS201844`) [ <a href="https://doi.org/10.1016/j.cliser.2017.06.004">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents an intercomparison of dynamical and statistical downscaling methods for seasonal forecasting over Europe, based on a 15-member hindcast from the EC-EARTH global model, focusing on summer mean temperature. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D3|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>E-OBS. </li> <li><a href="https://ec-earth.org/">EC-EARTH</a>  (EUROPIAS project) - Global seasonal predictions.</li> <li>Regional CM used: RACMO2, WRF, RegCM. </li> <li>Raster data (gridded seasonal temperatures). </li> <li>Vegetation maps (from ECOCLIMAP for dynamical downscaling). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Dynamical downscaling: (1) RACMO2: hydrostatic model employing 40 hybrid coordinate full vertical levels. (2) Weather Research and Forecasting system: non-hydrostatic dynamic core, employing 30 full eta vertical levels, and (3) RegCM modelling system: hydrostatic, compressible, sigma-p, vertical coordinate model considering 18 sigma-p levels. </li> <li>Statistical downscaling: relying on coarse-resolution global simulated predictors: (1) Perfect prognosis (PP), and (2) Model Output Statistics (MOS); "*PP techniques can be applied on a daily, monthly or seasonal basis, whereas MOS techniques require working at monthly or seasonal time-scales*" (*sic*). </li> <li>PP-ANA is based on the popular analogue technique, which estimates the local downscaled values corresponding to a particular atmospheric configuration from the local observations corresponding to a set of similar (or analog) atmospheric configurations within a historical catalog formed by reanalysis. </li> <li>PP-MLR is an extension of simple linear regression which attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. The fit is determined by minimizing the sum of the residuals between the regression line and the observed data. </li><li>Dynamical downscaling is based on regional models, which run on a relatively fine grid (e.g., 10–20 km) over a limited domain (e.g., Europe) initialized and driven at the boundaries by the coarse global model outputs. </li><li>These models can generate regional predictions for a suite of climate variables but still may suffer from significant biases which require post-processing with bias adjustment techniques before they can be used in impact applications. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of dynamical downscaling products for representation of the mean and extreme values.</li> <li>Statistical downscaling methods typically show minimal biases and provide realistic climate information (from the mean to the extremes) when compared to global models. </li> <li>Regional information still plays a significant role in specific sector climate indices and impact models. </li> <li>ROC Skill score was used as a measure of the accuracy of the probabilistic forecasts, providing maps where both dynamical and statistical downscaling methods were included; Both downscaling methods resulted in similar patterns showing low-to-moderate skill over most continent. </li><li>Used on energy performance case studies. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Relevant projects: (i) <a href="http://www.specs-fp7.eu/">SPECS</a>, and (ii) <a href="http://www.euporias.eu/">EUROPIAS</a></li> <li><a href="https://edepot.wur.nl/312260">Refinement and application of a regional atmospheric model for climate scenario calculations of Western Europe. </a></li> <li><a href="http://dx.doi.org/10.5065/D68S4MVH">A Description of the Advanced Research WRF Version 3 – Technical report.</a></li> <li><a href="http://dx.doi.org/10.3354/cr01018">RegCM4: model description and preliminary tests over multiple CORDEX domains. </a></li> <li><a href="http://dx.doi.org/10.1029/2012JD017650">Comparison of dynamically and statistically downscaled seasonal climate forecasts for the cold season over the United States. </a></li> <li><a href="http://dx.doi.org/10.1016/j.jcp.2006.10.024">Regional climate modelling. </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Dynamical downscaling; Statistical downscaling; Seasonal forecasting; Multiple linear regression; Precipitation; Heatwaves. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving resolution of climate change data, in particular for assessing seasonal energy needs.</code></td> </tr> </tbody> </table> |


#### D4. Dynamical and statistical downscaling of a global seasonal hindcast in eastern Africa
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of a global seasonal hindcast in eastern Africa ({cite:p}`NIKULIN201872`) [ <a href="https://doi.org/10.1016/j.cliser.2017.11.003">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Dynamical and statistical downscaling methods are combined to access seasonal forecast for impact modelling.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li><a href="https://ec-earth.org/f">EC-Earth</a></li> <li>Datasets: (1) Climate research unit time-series, (2) Global precipitation climatology center, (3) Tropical applications of meteorology, (4) African rainfall climatology, (5) African estimation algorithm, (7) Climate hazards group InfraRed precipitation stations, and (8) WATCH-forcing-Datra-ERA-Interim. </li><li>Regional CM used: CCLM4-8-21 (CCLM4), RCA4 (RCA4), RegCM-4-3 (RegCM4), WRF341I (WRF341), WRF381D (WRF381) </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>(1) Downscale ECMWF system-4 seasonal hindcasts, (2) RCMs: a domain of configurations has been selected, (3) Empirical statistical downscaling:  Two (2) ESD methods were selected to downscale the full stream of the EC-EARTH hindcast: (i) AN1: variation of the Analogue technique, and (ii) A variation of the generalized Linear Models (GLMs), (4) Selection of the subregions was based on a group of the initial datasets to the LEAP platform, and (5) Rainfall indexes were considered to evaluate seasonal forecasts: (i) the Simple Daily Intensity Index (SDII), and (ii) the Wet Day Frequency (WDF). </li> <li>Verification metrics: (i) Interannual correlation, (ii) Brier skill score, and (iv) ROC Skill Score: ROCCS maps for the EC-EARTH hindercasted rainfall provide allow to detect observational uncertainties.</li> <li>Dynamical Downscaling using RCMs is computationally expensive delaying the provision of the forecasts and requires much more resources than ESD (e.g., saving a wealth of driving boundary conditions from GCMs). </li> <li>LEAP platform offers information about humanitarian needs and interventions. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) Interannual correlation maps and maps of the global and downscaled hindcasts, (ii) ROCCS maps for the global and downscaled hindcast rainfall, (iii) Maps of rainfall tercile forecast for each model, (iv) Verification data for the rainfall indices (via maps of distribution of the ROCCSS for the global and downscaled rainfall forecasts). </li> <li>In contrast to the ESD approach, RCMs can provide a larger number of variables in a physically consistent way, including regional and local feedback which can be important in seasonal forecasting. </li> <li>Main results: (i) Observational uncertainties, (ii) A global forecast system, (ii) Both dynamical and statistical downscaling, (iv) Applicability of rainfall indexes and (v) The capabilities of an early warning system (LEAP platform). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li>Relevant projects: <a href="http://www.euporias.eu/">EUROPIAS</a></li> <li><a href="https://github.com/SantanderMetGroup/downscaleR">Link downscaleR package – GitHub repository </a></li> <li><a href="http://dx.doi.org/10.1175/JCLI-D-11-00441.1">Can a Regional Climate Model Improve the Ability to Forecast the North American Monsoon?</a></li> <li><a href="http://dx.doi.org/10.1029/2011JD016997">Dynamical downscaling of ECMWF Ensemble seasonal forecasts over East Africa with RegCM3. </a></li> <li><a href="https://doi.org/10.1111/j.1600-0870.2011.00523.x">Downscaling ECMWF seasonal precipitation forecasts in Europe using the RCA model. </a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Seasonal forecast; Downscaling; Drought early-warning system; RCMs; Precipitation; Dynamic downscaling; Generic. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands. </code></td> </tr> </tbody> </table> | 

### Data-driven based methodologies

#### DD1. Developing novel machine-learning-based fire weather indices
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Developing novel machine-learning-based fire weather indices ({cite:p}`Shmuel2023`) [ <a href="https://doi.org/10.1088/2632-2153/acc008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces a data-driven fire weather index that outperforms current traditional fire indexes (which often fall short due to the non-linear nature of wildfire risk factors) and provides accurate wildfire risk estimations which are key for optimal forest management and firefighting. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Global wildfire datasets.</li> <li>Variables: (1) daily ignition, (2) 2m temperature, (3) humidity, (4) 10m wind speed, (5) precipitation, (6) mean slope, (7) population density, (8) NDVI, and (9) Incoming short-wave solar radiation.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Models would benefit if could include: (i) including meteorological factors, (ii) topography, (iii) fuel loads, (iv) anthropogenic factors, (v) include 2-meter temperature, (vi) precipitation, (vii) RH, (viii) 10-meter wind velocity, based on the ERA5 hourly reanalysis data, and (ix) population density.</li> <li>Fourteen (1$) indexes are used for comparison, grouped in three (3) categories as following: : (1) Canadian Forest Service Fire Weather Index Rating System, (2) Australian McArthur Mark 5 Rating System, (3) U.S. Forest Service National Fire-Danger Rating System. </li> <li>The variables in each category include: (1a) fire weather index, (1b) build up index, (1c) danger index, (1d) drought code, (1e) duff moisture code, (1f) initial fire spread index, (1g) fine fuel moisture code, (1h) fire daily severity rating. (2a) Keetch-Byram drought index, and (2b) fire danger index. (3a) spread component, (3b) energy release component, (3c) burning index, and (3d) ignition component. These variables were available in a 0.25◦ resolution from the Copernicus Climate Change Service (Fire Danger Indices Historical Data from the Copernicus Emergency Management Service).</li> <li>Metrics: (1) Under the curve metric (AUC), (2) Operating characteristics curve (ROC), and (3) Precision-Recall Curve.</li> <li>Classification models: (1) RF, (2) Extreme Gradient Boosting (XGBoost), (3) MLP, a form of Neural Network and (iv) logistic regression.</li> <li>Method to study the actors in terms of wildfire risk: SHAP (SHapley Additive exPlanations) values analysis.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>XGBoost model achieved the highest score based on the ROC-AU curves.</li> <li>Traditional indices and subindices: the Duff Moisture Code and the Keetch-Byram Drought Index achieved the highest performance.</li> <li>ROXC curves for wildfire ignition prediction for the ML models are provided.</li> <li>Prediction accuracy maps for all ML-based index methods are provided, for the studied variables.</li> <li>Maps of the two-day dependence plots for wildfire occurrence are provided.</li> <li>Global maps of wildfire occurrence for all ML-based index methods  are provided.</li> <li> Temperature was estimated as the key feature for the prediction of wildfire occurrences. </li> <li> ML-based FWIs are able to provide wildfire occurrence estimation in a daily resolution in all regions worldwide.  </li> </ul> </code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2"> Machine learning, fire weather indices, forest management, wildfire risk. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> A methodology combining data-driven methodologies and fire weather indices. </code></td> </tr> </tbody> </table> |


#### DD2. PVS-GEN: Systematic Approach for Universal Synthetic Data Generation Involving Parameterization, Verification, and Segmentation
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> PVS-GEN: Systematic Approach for Universal Synthetic Data Generation Involving Parameterization, Verification, and Segmentation ({cite:p}`s24010266`) [ <a href="https://doi.org/10.3390/s24010266">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a new method that parameterizes empirical time-series data with minimal intervention. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-2
|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Empirical data and synthetic data from general-purpose time-series data of any type. </li> <li>Datasets: (i) Gas sensor array dataset, (ii) Low-Energy house dataset, (iii) EEG Alcoholism dataset, and (iv) Heterogeneity activity recognition dataset. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Process: (i) Parameterization: utilize empirical data with ACRIMA to derive automated parameters, (ii) Verification: compare the synthetic data with the empirical data using our proposed metric, the possibility of reproducibility (RoR), and (iii) Segmentation for universal synthetic data generation: enhance the time-series consistency and regularity. </li> <li>Statistical models: (i) SES, (ii) ARIMA, and (iii) GMM. </li> <li>Data-driven methods: (i) SVR, and (ii) LSTM. Other alternatives: (i) GANs, (ii) VAEs, and (iii) RNNs. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Reduced user intervention and reduced resources for acquiring and labeling large amounts of empirical data. </li> <li>A universal methodology could benefit having the following characteristics: (i) Automatic generation of time-series data for a range of sensors and data process, (ii) Parametrization of empirical data, (iii) Independent of sensor data traits, (iv) Encapsulation of the temporal dynamics of time-series data, (v) Enabling quantitative comparisons between generated and empirical data by reflecting the time-series characteristics of the data with their descriptive statistics, and (vi) Scalability. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time-series sensor data; synthetic data generation; time-series synthesis; IoT data generation; possibility of reproducibility.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Multi-purpose data generation system based on the processing of empirical data and time series. </code></td> </tr> </tbody> </table> |


#### DD3. A single-building damage detection model based on multi-feature fusion: A case study in Yangbi
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A single-building damage detection model based on multi-feature fusion: A case study in Yangbi ({cite:p}`Du2024`) [ <a href="https://www.sciencedirect.com/science/article/pii/S2589004223026639">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a multi-fusion feature model for accurate identification and classification of building damage detection to reduce information redundancy applied to earthquake events for demonstration.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-3|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Binary map of buildings, (ii) Outlines of buildings, (iii) Satellite DOM image, (iv) UAV DOM and DSM image, and (v) Google Maps-based satellite images. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Data from satellites and UAVs are obtained for damage building detection after a hazard event (earthquake). </li> <li>An image change detection model is applied. </li> <li>Methodology: (i) nDSM: extracts building contours, (ii) image segmentation: K-nearest neighbor was used for classification of the study area using spectral average grayscale value, rectangularity features, (iii) morphological closure operation: results of building contour extraction, (iv) segmentation of buildings, (vi) classification of damage types of buildings, and (vii) texture feature change analysis, image fusion, and PCA. </li> <li> Statistical analysis: (i) Maximum Likelihood Classification (ML), (ii) Neural Net Classification (NN), (iii) Mahalanobis Distance Classification (MD), and (iv) Support Vector Machine Classification (SVM) machine learning models were applied.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) Maps of damaged buildings, (ii) Post-and pre-hazard UAV and satellite images, (iii) Maps of extraction and distribution results of damaged buildings </li> <li>Limitations: (i) Model should be able to process data from diverse resources, (ii) A larger input of damaged buildings should be considered, and (iii) The procedure of extraction and selection should be automated for optimization. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Multi-feature fusion; Damage detection model; Earthquake; Normalized Digital Surface Model (nDSM); Buildings; Structural Damage; Building impact assessment. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability analysis.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Exposure and vulnerability analysis for single buildings, with a focus on structural damage, based on seismic impact assessment, potentially transferable to other hazards. </code></td> </tr> </tbody> </table> |



#### DD4. Assessing automated gap imputation of regional scale groundwater level data sets with typical gap patterns
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Assessing automated gap imputation of regional scale groundwater level data sets with typical gap patterns ({cite:p}`BIKSE2023129424`) [ <a href="https://doi.org/10.1016/j.jhydrol.2023.129424">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces and compares two data imputation methodologies to simulate complex missing value patterns by mimicking typical gap patterns, tested for reproducing daily groundwater hydrographs.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Regional scale groundwater level data sets: (i) Rechange, (ii) Groundwater-surface, and (iii) Water interaction. </li> <li>Mimicking of: (i) Typical gap patterns, and (ii) Random gap patterns. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Linear Interpolation. </li> <li>MissForest: (i) Non-parametric, (ii) Iterative, (iii) Missing values imputation, (iv) Random Forest algorithm, (v) Automatic, (vi) Unsupervised missing imputations, (vii) No assumptions about data distribution, (viii) No need for tuning parameters, and (ix) Performs for the infilling daily groundwater hydrographs. </li> <li>ImputePCA: (i) Multiple imputation method, (ii) Principal components method on an incomplete dataset, and (iii) Performs iteratively principal component analysis (PCA). Convergence: when the difference between two successive iterations is below a defined threshold. </li> <li>Artificial gaps: (i) Typical gap patterns: (ii) Eleven (11) distinct groups of gaps in groundwater hydrographs were performed, and (ii) Artificial gaps of time series were simulated. (ii) Random gap patterns: Artificial gaps were introduced in 109 hydrographs. </li> <li>Imputations performance: I) imputePCA performed less accurately with more dispersed results, (ii) Typical gap patterns were demanding for all imputation algorithms, (iii) missForest outperformed both the imputePCA and the linear interpolation algorithms, and (iv) All infilled hydrographs performed poorly when imputing typical gap patterns. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Impact of individual gaps: (i) All methods performed poorly in estimating long continuous gaps, (ii) The accuracy of the infilling in the beginning and at the end of the hydrographs performed poorly when compared to the rest of the gaps.</li> <li>Estimation of changes in the number of daily hydrographs. </li> <li>Extreme hydrographs remain challenging to address. </li> <li>Gap-filling methods fail around gaps that contain extremes.</li> <li>Random-like gap patterns are linked with more simple imputation methods in terms of performance and accuracy.</li> <li>Typical gap patterns do not offer a consistent performance on imputation, despite the gap characteristics. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code>  <ul> <li><a href="https://eu-waterres.eu/">WATERRES: EU-integrated management system of cross-border groundwater resources and anthropogenic hazards. </a> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time series; Missing values; Gap filling; Droughts; Abstraction. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> This recipe offers alternative methodologies for data imputation. </code></td> </tr> </tbody> </table> |


#### DD5. From theory to practice: optimization of available information for landslide hazard assessment in Rome relying on official, fragmented data sources
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> From theory to practice: optimization of available information for landslide hazard assessment in Rome relying on official, fragmented data sources ({cite:p}`Esposito2023`) [ <a href="https://doi.org/10.1007/s10346-023-02095-7">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-5|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>List of geological hazards. </li> <li>Datasets for known landslides.</li> <li>Prediction of landslide susceptibility.</li> <li>Point-based landslide database is represented by: (i) 1099 LIPs (289 original and 810 synthetic), and (ii) The 67 related to the January 2014 extreme rainfalls are excluded. </li> <li>Continuous map(s) of landslide initiation susceptibility based on data-driven model(s). </li> <li>Detection rate curves for the classification of the susceptibility. </li> <li> Spatial density maps of shallow landslides and earth slides.  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Objectives: (i) Dataset preparation, (ii) Susceptibility assessment, and (iii) Information about landslides. </li> <li>Evaluation of intensity and temporal probability of landslides.</li> <li>Definition of rainfall-induced landslide hazard: (i) Definition of the spatial component of the landslide hazard, (ii) Temporal component of the landslide hazard, (iii) Preliminary and large-scale quantitative hazard description, and (iv) Evaluation of the return periods of landslide trigger rainfall events.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Outputs: (i) A uniform, updated database is composed, (ii) The spatial component of the hazard is depicted by (a) Continuous maps of landslide initiation, and detection rate curves, (b) Classification of landslide susceptibility, (iii) The temporal component of the hazard is depicted by (a) Resulting landslide frequency estimation, and (b) Rainfall probability curves for the tested areas, and (iv) Persistent scatterer interferometry: (a) A-DInSAR velocity maps, and (b) Susceptibility hazard index maps for the tested areas. </li> <li>GIS- and ML-based methods were applied to collect and integrate open-source landslide inventories into a database. </li> <li>The reported products aid decision-makers in managing landslide risks by reporting activity status and susceptibility, supporting informed monitoring and investment prioritization for prevention and mitigation.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="http://sgi2.isprambiente.it/franeroma/">Known landsides </a></li> <li><a href="https://geoportale.regione.lazio.it/">Open access land use maps </a></li> <li><a href="https://www.autoritadistrettoac.it/planning/hydrographic-basin-planning/documentation-of-the-tiber-basin-plan">Hydro-geological Structure Plan</a></li> <li><a href="http://www.urbanistica.comune.roma.it/prg-2008-vigente/">Municipal land use plan </a></li> <li><a href="https://www.comune.roma.it/web-resources/cms/documents/Fasc3_RischioFrane_2021.pdf">Civil protection plans</a></li> <li><a href="https://idrogeo.isprambiente.it/app/">IDROGEO Platform</a></li> </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Susceptibility; Machine learning; Rainfall probability; Landside hazards; Landside inventories; Interferometry. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Landslide hazard assessment in relation to rainfall intensity, supporting dynamic analysis of landslide risk depending on seasonal changes in rainfall patterns and extreme events frequency/intensity. </code></td> </tr> </tbody> </table> |


#### DD6. Modelling national residential building exposure to flooding hazards
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Modelling national residential building exposure to flooding hazards ({cite:p}`PAULIK2023103826`) [ <a href="https://doi.org/10.1016/j.ijdrr.2023.103826">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a model for flood risk assessment by studying the building characteristics for object-level replacement evaluation in flooded areas utilizing public data, and data-driven methodologies for the estimation of the hazard area exposure.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-6|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Variables: (i) Location (e.g., Address count and units, etc.), (ii) Geometric and non-geometric characteristics (e.g., Floor area, and height, Building count, Land area, etc.). </li> <li>Integration of public data and geospatial physical/non-physical building characteristics.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Workflow to estimate physical and non-physical characteristics for object-level replacement valuation using (i) spatial data, (ii) geometric data, and (iii) data-driven methods.</li> <li>Geometry building properties were estimated based on geospatial operations and open topographic data. </li> <li>Building height (BHT) extraction and level (BL) enumeration were performed using a geospatial model and LIDAR point clouds. </li> <li> Data-driven methods as tree-ensemble models for value imputation (supervised learning regression and classification algorithms): (i) Random Forest, and (ii) XGBOOST.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Estimation of residential building characteristics and replacement values. </li> <li>Output: (i) Regional residential building and replacement value exposure, (ii) RF demonstrates higher overall performance compared to XGBOOST, and (iii) Object-level information for exposure in risk assessments can be critical at regional to national scales. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li>Geospatial datasets: (i) NZ building outlines (ii) NZ primary land parcels, (iii) LIDAR point clouds, (iv) NZ functional urban areas, (v) RiskScape software, (vi) CostBuilder. </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Floods; Residential buildings; Exposure; Monetary values; Supervised learning; Object-level modelling. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Flood hazard exposure and vulnerability analysis of buildings. </code></td> </tr> </tbody> </table> |


#### DD7. Deep Learning Regional Climate Model Emulators: A Comparison of Two Downscaling Training Frameworks
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Deep Learning Regional Climate Model Emulators: A Comparison of Two Downscaling Training Frameworks ({cite:p}`vanderMeer`) [ <a href="https://doi.org/10.1029/2022MS003593">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes a methodology where it explores the potential of using data-driven methodologies alternatively to dynamical downscaling, applied to a global climate model (GCM) to regional resolution. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-7|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Precipitation, (ii) Downward radiation, (iii) Humidity, (iv) Temperature, and (iv) Pressure. </li> <li>RCM target domain: box of 64 x 64 pixels. </li> <li>RCM (from MAR(ACCESS1.3)), GCM(CMIP5). </li> <li>Input features to RCM: 1D (e.g., Seasonal indicators, Spatial mead of 2D variables, etc.), and 2D (e.g., Wind, Downward radiation, Humidity, etc.). </li> <li>Climate variables: precipitation, temperature, etc…  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Two Surface mass balance (SMB) emulators, a perfect and an imperfect one, were chosen to downscale a GCM. </li> <li>Two ML models were applied to SMB to examine the downscaling potential: U-Net model.</li> <li>U-Net (CBAM (Convolution block attention) combined with depth wise-separable convolutions (DSC)), Smart-UNet. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of SMB predictors of the RCM emulators over a test period.</li> <li>Maps of evaluation metrics on predictions from the RCM emulators over a test period. </li> <li>Output: (i) Perfect model fails to reproduce SMB's extreme values, (ii) Both perfect and imperfect models succeed in reproducing complex spatial structure of the RCMs, and (iii) Inconsistencies due to the difference in resolution between large-scale and local-scale variables are not negligible and might confuse the RCM-emulator. </li> <li>Limitations: (i) Temporal and spatial inconsistencies might occur if an offset is present in the RCM time series, (ii) Inconsistencies between RCM and GCM variables remain present, (iii) The typical limitations of machine learning methods are also applicable in this context. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://esgf.nci.org.au/search/esgf-nci/">ACCESS 1.3 GCM data.</a></li> <li><a href="https://github.com/marvande/RCM-Emulator">Historical and future RCP8.5 simulations – GitHub repository.</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">DL; RCMs; GCMs; Downscaling; Deep Learning RCM-emulator; Dynamic Downscaling of GCMs; Surface Mass Balance (SMB).  </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Emulating RCM downscaling to improve resolution of climate change data in case study areas.</code></td> </tr> </tbody> </table> |


#### DD8. Self-supervised learning for climate downscaling
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Self-supervised learning for climate downscaling ({cite:p}`10066728`) [ <a href="https://doi.org/10.1109/BigComp57234.2023.00012">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a self-supervised deep-learning solution for climate downscaling that can be applied without requiring high-resolution ground truth data.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-8|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Low-Resolution Climate data: Synthetic LR data can also be created by degrading real High-Resolution data. </li> <li>Climate variables: (i) The surface temperature, (ii) total precipitation, and (iii) topographical gradient.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Community Earth System Model (CESM): Fully coupled global climate model. Capabilities of neural networks to reconstruct high-resolution data from given low-resolution simulations.</li> <li>Legacy low-resolution simulations can be downscaled to reconstruct high-resolution detail. </li> <li>Past observations that have been taken at lower resolutions can be increased to higher resolutions, opening new analysis possibilities.</li> <li>Networks: (i) Low-Frequent Data: Residual-Predicting Network (RPN), and (ii) High-Frequent Data: Deconvolutional Network (DCN). </li><li>Downscaling is performed over the surface temperature and the topographic gradient. </li><li>Deep-learning methodologies: CNN method (each model trained for 500 epochs, using Adam optimizer and LeakyReLU).</li><li>Characteristics: (i) Self-supervised deep-learning solution for climate downscaling, (ii) No high-resolution ground data input required, (iii) CNN models train on a single instance at a time, and (iv) Improvement of downscaling performance. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>The method is compared to self-supervised models (SSL~SRResNet~, and SSL~GINE~). The two SSLs have also been used as training components on the pseudo-LR and HR data. </li> <li>The method is capable of estimating HR climate data without ground truth data. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://github.com/k-s-b/ssl_climate">Repository for the work titled "Self-supervised learning for climate downscaling" - GitHub repository</a>. Data for this recipe: <a href="Ultra-high-resolution climate simulation project.">https://climatedata.ibs.re.kr/data/cesm-hires</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Climate downscaling; self-supervised; Deep Learning; CNNs; Super-resolution; Earth system models; Climate Simulation.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving resolution of climate data.  </code></td> </tr> </tbody> </table> |


#### DD9. An Exploration of Interpolation - Machine Learning Model for Climate Model Downscaling Under the Limitation of Data Quantity
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> An Exploration of Interpolation - Machine Learning Model for Climate Model Downscaling Under the Limitation of Data Quantity ({cite:p}`10212662`)  [ Link ] 2023  [ <a href="https://doi.org/10.1109/ITC-CSCC58803.2023.10212662">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes a methodology to perform downscaling and address any data-gap issues introduced, by combining interpolation and data-driven methodologies.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-9|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>LR climate data (IPSL-CM6A-LR in CMIP6 with 250 km of spatial resolution are selected as the GCM output). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>IDW (Inverse Distance Weight).</li> <li>TIN (Triangular Interpolation Network).</li> <li>ANNs (Artificial Neural Networks). </li> <li>GBRT (Gradient Boosting Regression). </li> <li>GLM (Generalized Linear Model).</li> <li>SVP (Support Vector Machine). </li> <li>HSVR (Hybrid Support Vector Regression). </li> <li>Combinations: (i) IDW-ANN, (ii) IDW-GBRT, (iii) TIN-ANN, and (iv) TIN-GBRT. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>*"The combination of IDW-ANN becomes the proper method for downscaling the climate model output for both temperature and precipitation under the limitation of data quality"* (*sic*). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Interpolation; ML; Climate model downscaling; Data gaps; GCMs; Deep learning. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Climate model downscaling through interpolation of existing data.</code></td> </tr> </tbody> </table> |


#### DD10. A ‘Total’ Imputation Algorithm that Fills Gaps in Time Series Measurements for ADEV and Phase Noise Characterizations of Power-law Noise Models
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A ‘Total’ Imputation Algorithm that Fills Gaps in Time Series Measurements for ADEV and Phase Noise Characterizations of Power-law Noise Models ({cite:p}`9850921`) [ <a href="https://doi.org/10.1109/EFTF/IFCS54560.2022.9850921">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces an imputation algorithm for data gaps occurring in live measurements, by extending a T-length data run and enhancing long-term ADEV(τ) estimation, consistently recovering gaps across various power-law noise models.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-10|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>NIST H-maser time series measurements: (I) Clock, and (ii) oscillator phase measurements. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>The Total imputer is an effective method yet devised in filling data gaps for: (i) computations of ADEV (Allan Deviation), and (ii) phase noise levels over the fullest possible range of τ-values and Fourier-frequencies.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Total imputation algorithm. </li> <li>Equally spaced time-series data without gaps. </li> <li>Treatment of large gaps. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li> <a href="https://github.com/nkschlos/time-series-imputation">Time-series-imputation package. </a> </li> <li> <a href="https://zenodo.org/records/5595200">Executable for Gap-filling Script for Noisy Time Series – Zenodo.</a> </li> <li> <a href="https://zenodo.org/records/5594587">Gap-filling Script for Noisy Time Series - Zenodo. </a> </li> <li> <a href="https://ieeexplore.ieee.org/document/9658567	">Characterizing Frequency Stability Measurements Having Multiple Data Gaps.</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time series; Noise model; Imputation Algorithm; Allan Deviation; Data models; Large data gaps. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Integration of missing modelling variables, applicable to any kind of data gap.</code></td> </tr> </tbody> </table> |


#### DD11. A data filling methodology for time series based on CNN and (Bi)LSTM neural networks
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A data filling methodology for time series based on CNN and (Bi)LSTM neural networks ({cite:p}`tzoumpas2022data`) [ <a href="https://doi.org/10.48550/arXiv.2204.09994">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe develops a method combining deep Learning models such as CNNs, LSTMs, and BiLSTMs to fill data gaps in internal temperature time series from monitored apartments, using both pre- and post-gap data, correlated external temperature data, the method accurately reconstructs the target time series, outperforming baseline deep-learning architectures.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-11|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Data from monitored apartments. </li> <li>Data from sensors for moisture, humidity, temperature, C02 concentration. energy consumption. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>CNNs, LSTMs and BiLSTMs. </li> <li>CNN-LSTM (256, 128 and 64 neurons). </li>  <li>CNN-BiLSTM (32, and 16 neurons). </li> <li>Use both networks in pre- and post-gap data. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Time-series reconstruction.</li> <li>CNN-BiLSTM is the most promising model.</li> <li>CNN-BiLSTM has the best-performing approximation of the time series.</li> <li>CNN-LSTM model performs better in generalizing its predictions. </li> <li>CNN-BiLSTM and CNN-LSTM models show a promising ability to generalize to unseen data. </li> <li>Both models outperform purely LSTM networks. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://doi.org/10.3389/fmars.2021.637759">Feedforward and LSTM Neural Networks, Gap filling. </a> </li> <li> <a href="https://doi.org/10.1142/S0129065721300011">Deep learning and time series forecasting, Review paper.</a> </li>  <li> <a href="http://www.sinfonia-smartcities.eu/">SINFONIA Project. </a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Neural Networks; Data filling; Time series; Sensor data; Deep learning; High-resolution heat wave; Hazard asssessment.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improvement of heat wave hazard characterization in urban areas based on existing monitoring devices in buildings, understanding effect of air temperature variation and urban heat island on indoor comfort, as a proxy of thermal capacity of building envelope and HVAC systems efficiency.</code></td> </tr> </tbody> </table> |


#### DD12.  Increasing the detail of European land use/cover data by combining heterogeneous data sets
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Increasing the detail of European land use/cover data by combining heterogeneous data sets ({cite:p}`doi:10.1080/17538947.2018.1550119`) [ <a href="https://www.tandfonline.com/doi/full/10.1080/17538947.2018.1550119">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents methods to improve the spatial resolution of land cover and land use data through the combination of different datasets available through Copernicus Land Monitoring System. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-12|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>European Settlement Map</li> <li>Corine Land Cover</li> <li>Copernicus High Resolution Layers</li> <li>Urban Atlas</li> <li>TomTom Multinet Polygons</li> <li>OpenStreetMap</li> <li>Local Sub-National Land use data</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Spatial refinement based on the cartographic synthesis of categorical raster data, interval raster data, and vector polygon data. </li> <li>Data fusion performed using an automated chain of raster-based map algebra operations on a set of raw or pre-processed datasets. </li> <li>Input vector data rasterised to the target 100m resolution beforehand, using the maximum combined area method to identify the dominant class in each cell. </li> <li>At each step of the sequence, the cells either remain unchanged or are updated by the overlaid input data layer, following pre-established decision rules.</li> <li> Random forest classification as machine-learning technique to predict land use classes using the derived predictor variables. </li> </ul></code></td>  </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Urban fabric classification by use.</li> <li>Vegetation classification.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://human-settlement.emergency.copernicus.eu/enact.php">ENACT project</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Data fusion; Land use; Land cover; Machine learning; Points of interest</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Case study tailored improvement of exposure and vulnerability information based on open datasets.</code></td> </tr> </tbody> </table> |


#### DD13. Power Network Component Vulnerability Analysis: A Machine Learning Approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Power Network Component Vulnerability Analysis: A Machine Learning Approach ({cite:p}`ANAND202173`) [ <a href="https://doi.org/10.1016/j.procs.2021.05.008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe suggests using data-driven methodologies on publicly available large-scale data to gauge power network vulnerability, elevate grid stability, minimize failure risks, and boost resilience for smart grids.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-13|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>State of components after an extreme event: (i) non-operational (outage), (ii) operational (in service). </li> <li>Network components: (i) power plants, (ii) transmission lines, (iii) substations.</li> <li>Extreme hazard(s): historic disruptive events data as input. Data sourced from the NOAA website. </li> <li>Variables: (i) operation capacity, (ii) total number of lines, (iii) risk factor(s), (iv) vulnerability index, and (v) disruption distance. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Data-driven methodologies: Supervised learning model: Support Vector Machines (SVMs): (i) 3216 components for training the model, (ii) 1345 operational components under thunderstorms winds, and (iii) 1309 operational components under tornadoes. Kernels: (i) linear, (ii) gaussian, (iii) polynomial, and (iv) sigmoid. </li> <li>Calculation of the vulnerability index.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Investigation of critical components under disruptions in a network.</li> <li>Consideration of an extreme event. </li> <li>Maps of in-service or outrage components. </li> <li>Output for: (i) the evaluation of the network stability, (ii) the understanding of the risk of cascade failure, and (iii) the improvement of the resilience of the overall network. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Power network resilience; Vulnerability analysis; Machine learning; Predictive analytics; Extreme events.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Enhance the predictability of resilience methodologies for power networks.</code></td> </tr> </tbody> </table> |


### Expert elicitation methods

#### EE1. ELICIPY 1.0: A Python online tool for expert elicitation
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> ELICIPY 1.0: A Python online tool for expert elicitation ({cite:p}`deMichieliVitturi2024`) [ <a href="https://www.sciencedirect.com/science/article/pii/S2352711024000128">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Python tool to perform expert elicitation sessions through a framework that covers both the questionnaire collection and the analysis parts. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-EE-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input through webforms (question label and extended text for in multiple languages; units of the expected answer; scale - uniform or logarithmic; range of admissible values for the elicited percentiles; question type - “seed” or “target”.</li> <li>Experts’ weight.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Cooke Classical method. </li> <li>Expected Relative Frequency method.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Experts’ weights with different weighting schemes. </li> <li>Itemwise graphs for seed questions (including the text of the Itemwise graphs for target questions (including the text of the questions), together with a simplified probability density function and cumulative distribution plots of the DM. </li> <li>Percentiles of target questions. </li> <li	> Optional graphs where multiple target questions could be visualized along with their percentiles. </li> <li> Probability density functions and barplots for target questions, along with the percentile values for the used weighting schemes. </li> <li> Probability density functions for each questions and subgroups.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://zenodo.org/records/8192353">ELICIPY 1.0 Github</a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


#### EE2. Using expert elicitation to strengthen future regional climate information for climate services
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Using expert elicitation to strengthen future regional climate information for climate services ({cite:p}`GRAINGER2022100278`) [ <a href="https://doi.org/10.1016/j.cliser.2021.100278">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe explores the use of structured expert elicitation to access uncertainties for future climate changes as an extension to the results of climate model simulations.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EE-2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, and (ii) Precipitation. </li> <li>CMIP5 analysis: (i) Historical data from 1975-2005, (ii) Calculated periods: 2040s and 2080s, and (iii) RCPs: RCP2.6, 4.5, 6.0 and 8.5. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Climate model outputs from CMIP5. </li> <li>Structured expert elucidation:  <ul> <li> Use of structured expert elicitation (SEE) for regional climate change.  </li> <li> Expert elicitation judgment (individually or in a group): (a) Provides additional information and knowledge that is absent from modelling approaches, and (b) Builds a framework for discussion between climate experts and regional stakeholders.  </li> <li> Snowball sampling is considered.  </li> <li> Estimates of future temperature and precipitation change are provided. </li> <li> Sources of uncertainty in estimating long-term climate changes: rank sources based on their overall contribution. </li> <li> Considering all possible GHG concentration scenarios. </li>  </ul> </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Narrower uncertainty ranges for deviations in both temperature and precipitation. </li> <li>Framework for supporting adaptation decisions. </li> <li>"*Practices are shaped by local epistemic, institutional and political cultures*" (*sic*).</li> <li> "*SEE used alongside modelling approaches, can contribute to a richer understanding of regional climate knowledge for use in climate services*" (*sic*)  </li> <li> "*Elicitation methods should be considered within the ‘toolbox’ of approaches available to climate service providers*" (*sic*)  </li>  </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Knowledge quality assessment; Climate change adaptation; Yangtze; China; Assessing Climate Uncertainties; Expert elicitation.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Adapt the methodology to assess probability of compound events and cascading effects in selected case studies scenarios.</code></td> </tr> </tbody> </table> |


#### EE3. Expert Elicitation: Using the Classical Model to Validate Experts’ Judgments
  |       Abbrev   |	Categories and data			 |
  |----------------|-------------------------------|
  | |<table>  <tbody>  <tr> <td>Title</td>  <td> Expert Elicitation: Using the Classical Model to Validate Experts’ Judgments ({cite:p}`doi:10.1093/reep/rex022`) [ <a href="https://www.journals.uchicago.edu/doi/full/10.1093/reep/rex022">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Review of thirty-three professionally contracted classical model studies that were performed between 2007 and March 2015 using the EXCALIBUR software package for structured expert judgement elicitation using Cooke’s Classical Model. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-3-R|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input and weighting through the EXCALIBUR tool.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Cooke Classical model</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Scoring of individual variables</li> <li>Scoring of average probabilities</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code>  <ul> <li><a href="https://www.lighttwist.net/wp/excalibur/">EXCALIBUR Windows Tool</a></li> <li><a href="https://github.com/grongen/anduryl/releases">EXCALIBUR Python Tool</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


### Uncertainty treatment methodologies

#### U1. How Certain is Good Enough? Managing Data Quality and Uncertainty in Ordinal Citizen Science Data Sets for Evidence-Based Policies on Fresh WateR
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> How Certain is Good Enough? Managing Data Quality and Uncertainty in Ordinal Citizen Science Data Sets for Evidence-Based Policies on Fresh Wate ({cite:p}`Stankiewicz-2023`) [ <a href="https://doi.org/10.5334/cstp.592">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe focuses on the collection of data sets for water quality involving the active contribution of citizens, offering an additional way to study and treat data gaps and uncertainties.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-U-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, (ii) Oxygen parameters, (iii) Turbidity, and (iv) pH. </li> <li>Indicators concerning: (i) Aquatic plants, (ii) Water flow, (iii) Water depth, and (iv) Riverbank characteristics. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Water Blitz events: instructions combined with a sampling kit. </li> <li>Measuring the nitrate-nitrogen and phosphate-phosphorus concentration as collected from the field kits. </li> <li>Coordinated measurements via GPS. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Citizen science contributes to monitoring activities. </li> <li>Development of resilient ways to interact with the aquatic ecosystems. </li> <li>Contribution to awareness and reflection. </li> <li> Addresses an uncertainty in a sustainable government.  </li> <li> Limitations: (i) Role of the citizen science in the community, (ii) Individual characteristics of water systems and parameters, and (iii) Public access to environmental data from government(s).  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Social-ecological systems; Water quality, Monitoring; Uncertainty. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty treatment methodology for trials and mini-trials. </code></td> </tr> </tbody> </table> |


#### U2. Where does scientific uncertainty come from, and from whom? Mapping perspectives of natural hazards science advice
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Where does scientific uncertainty come from, and from whom? Mapping perspectives of natural hazards science advice ({cite:p}`DOYLE2023103948`) [ <a href="https://doi.org/10.1016/j.ijdrr.2023.103948">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe focuses on identifying sources of uncertainty associated with natural hazards using mental model mapping and a semi-structured interview protocol.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-U-2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>The area of study was exposed frequently to a wide variety of natural hazards. </li> <li>A range of participants was recruited using the snowball approach. </li> <li>In total twenty-five (25) participants ranged from twenty-five (25) to seventy-five (75) years old.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Aims: (i) Understand what a disaster risk is, (ii) Integrate technology in decision-making about risk, and (iii) Find disaster risk communication methodologies. </li> <li>A three-face interview was constructed "to understand individual's perceptions of uncertainty associated with natural hazards" + brainstorming + indirect elicitation questions.  <ul> <li> A systematic review of mental model interview approaches. </li>  <li> Conceptual cognitive concept mapping (3CM). </li>  </ul> </li> <li>Mental models approach: <ul> <li> Key concepts: (i) Uncertainty, (ii) Knowledge, and (iii) Science.  </li> <li> Sources of uncertainty: (i) The scientists, (ii) The media, (iii) The communicators, (iv) The range of possible outcomes, (v) Human responses, and (vi) The unknown unknowns. </li>  </ul>  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Individual's mental models to identify sources of uncertainty: (i) Actors, and (ii) Known unknowns. </li> <li>Translate uncertainty in a meaningful way for the people (the public).</li> <li>Creation of science-policy interfaces for effective decision-making frameworks in disaster management crisis. </li> <li> Key influences for uncertainty: (i) Governance and funding, (ii) Societal factors, (iii) Outcomes, (iv) Emotions, (v) The communication landscape, and (vi) Decision-making.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://www.civildefence.govt.nz/cdem-sector/plans-and-strategies/national-disaster-resilience-strategy/">National Emergency Management Agency's National Disaster Resilience Strategy. </a> </li> <li> <a href="https://resiliencechallenge.nz/">Resilience to Nature's Challenge is one of Aotearoa New Zealand's National Science Challenges. </a> </li> <li> <a href="http://www.quakecore.nz/">QuakeCoRE is the NZ Centre of Research Excellence for Earthquake Resilience. </a> </li>  </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty; Mental models; Natural hazards; Societal and economic factors. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Communicating uncertainties associated with complex events hazard/impact scenario assessment to decision makers. </code></td> </tr> </tbody> </table> |


#### U3. A review of uncertainty quantification in deep learning: Techniques, applications and challenges
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A review of uncertainty quantification in deep learning: Techniques, applications and challenges ({cite:p}`ABDAR2021243`) [ <a href="https://doi.org/10.1016/j.inffus.2021.05.008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents the application of Bayesian and ensemble techniques in various domains discussing the recent advancements in uncertainty methods within deep learning for optimization and decision-making processes.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-U-3-R|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> N/A  </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Quantification methods:  <ul> <li>Bayesian techniques: (i) Monte Carlo (MC) dropout, (ii) Markov chain Monte Carlo (MCMC), (iii) Variational inference (VI), (iv) Bayesian Active Learning (BAL), (v) Bayes by Backprop (BBB), (vi) Variational autoencoders, (vii) Laplacian approximations, and (viii) Uncertainty quantification in reinforcement learning. </li> <li>Ensemble techniques: (i) Deep NNs (DNNs), (ii) Deep ensemble Bayesian/Bayesian deep ensemble, and (iii) Uncertainty in Dirichlet deep networks. </li> <li>Uncertainties: (i) Two main types of uncertainty: (a) epistemic (model uncertainty) and (b) aleatoric (data uncertainty). (ii) Three (3) uncertainly models were considered: (1) the MC dropout, (2) the Bootstrap model, and (3) the GMM model. </li> </ul> </li> <li>Others: <ul> <li>Neural Architecture Distribution Search (NADs). </li><li>Single model estimates for DNNs of epistemic and aleatoric uncertainty.</li> <li>Method to find and reject distribution data points for training a deterministic deep model with a single forward pass at test time. </li> <li>MC-DropConnect. </li> <li>Gradient-based optimization techniques. </li> <li>Noise contrastive priors (NCPs) to estimate consistent uncertainty. </li><li>Uncertainty-based class imbalance learning.</li><li>Variational approximation, termed Bayes by hypernet. (BbH), deducting hypernetworks as implicit distributions. </li><li>I Do not Know (IDK) prediction cascade approach. </li><li>Models inspired by the nonlinear differential equations utilized by physics-informed neural networks. </li><li>ProbDepthNet. </li><li>DNNs trained with mix-up.</li><li>Local interpretable model-agnostic explanations (LIME). </li><li>Randomized approach sampling from the hidden layers. during the DNN interference period. </li><li>Certainty-driven consistency loss (CCL) method. </li><li>Modified knowledge distillation method.</li><li>Models based on kernel techniques. </li><li>Stochastic quantized activation distributions (SQUAD). </li><li>Probabilistic DL method (approximate Bayesian inference + heteroscedastic noise technique). </li><li>Gaussian Processes (GP). </li><li>Stochastic, low-rank, approximate natural gradient (SLANG) technique. </li><li>Dubbed prior networks (PNs). </li><li>DVERGE</li> <li> Direct epistemic uncertainty prediction (DEUP). </li> <li> Subjective Bayesian GNN (S-BGNN). </li> <li> Doubly stochastic variational neural process (DSVNP). </li> <li> Non-Bayesian NN models </li> <li> kol </li> <li> Uncertainty-aware deep Dirichlet neural networks. </li> <li> Deep Gaussian processes (DGPs): (i) In combination with stochastic weight averaging (SWA), (ii) SWA-Gaussian, (iii) GPDNNs: a hybrid model of GP and DNNs, (iv) GPs + YOLOv3, (v) A natural gradient-based algorithm for Gaussian mean-field, (vi) Matrix variate Gaussian (MVG), and (vii) Introduction of a variety of stochastic layers. </li> <li> A variety of other techniques uniquely specified and tailored for desired applications are listed within the last subsections of the paper.  </li> </ul></li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Gaps and methods to approach them: (1) Fusion-based methods, (2) Ensemble methods, (3) Decision making, (4) Active learning, (5) Transfer learning, (6) Neural architecture search (NAS) methods, (7) Self-supervised learning (SSL) methods, (8) Hypernetworks, (9) Continual learning, (10) GNNs: Graph Neural Networks, (11( BO: global optimization method for optimizing time-consuming black-box objective functions, and (12) Uncertainty calibration. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty quantification; Deep learning; Machine learning; Bayesian statistics; Ensemble learning; Review article. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty quantification in propagation of damage following consecutive compound events and/or cascading effects (Climate Change and Hazard data). </code></td> </tr> </tbody> </table> |


#### U4. SHELF: The Sheffield Elicitation Framework
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> SHELF: The Sheffield Elicitation Framework ({cite:p}`Gosling2018`) [ <a href="https://link.springer.com/chapter/10.1007/978-3-319-65052-4_4">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> R-based package of documents, templates and software to carry out elicitation of probability distributions for uncertain quantities from a group of experts. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input and weighting through the SHELF package of documents, templates and software.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Single expert</li> <li>Multiple experts</li> <li>Bivariate elicitation</li> <li> Dirichlet elicitation </li> <li> Extension method (continuous) </li> <li> Extension method (discrete) </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Probability distribution with respect to elicited variables.</li> <li>Multiple visual, graph and table formats. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://shelf.sites.sheffield.ac.uk/">SHELF Tool</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


#### U5. Combining Quantitative and Qualitative Measures of Uncertainty in Model-Based Environmental Assessment: The NUSAP System
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Combining Quantitative and Qualitative Measures of Uncertainty in Model-Based Environmental Assessment: The NUSAP System ({cite:p}`vanderSluijs`) [ <a href="https://doi.org/10.1111/j.1539-6924.2005.00604.x">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe showcases the applicability of a system designed to combine quantitative and qualitative uncertainty measures, demonstrating its effectiveness for accessing both parameter uncertainty and model assumptions.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Data from environmental policy issues, for example, emissions of acidifying gases (NO~x~, SO~2~, and NH~3~). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Treatment of multidimensional uncertainty assessment with increasing complexity. </li> <li>Emission monitoring systems, complex energy models, and environmental indicators are used. </li> <li>NUSAP is applied to complex models in a meaningful way. </li> <li> Ability to serve as a diagnostic tool for assessing the robustness of a given knowledge base for policy-making. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Numeral Unit Spread Assessment Pedigree (NUSAP) system for multidimensional uncertainty assessment. </li> <li>Potentially applicable for ICARIA use cases/trials, etc...</li> <li>A tool for prioritizing uncertainties qualitatively and quantitatively. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://doi.org/10.1007/s11069-016-2364-3">A framework to assess quality and uncertainty in disaster loss data </a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty; Controversy; Value-laden assumptions; Problem frames; Diagnostic analysis. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty treatment methodology for trials and mini-trials. </code></td> </tr> </tbody> </table> |


### Other methodologies related to hazard, exposure, and vulnerability.

#### HEV1. Urban pluvial flood modelling in the absence of sewer drainage network data: A physics-based approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Urban pluvial flood modelling in the absence of sewer drainage network data: A physics-based approach ({cite:p}`MONTALVO2024131043`) [ <a href="https://doi.org/10.1016/j.jhydrol.2024.131043">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe focuses on a physics-based method for assessing urban pluvial floods using a virtual sewer network generation tool when sewer network data is scarce. Comparing results from four storm events, the method effectively, and accurately represented drainage capacity and accounting for sewer overflows, confirming its robustness for urban flood modelling. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Information from a virtual sewer network.</li> <li>Information from 1D/2D models using the actual sewer network.</li> <li>Stormwater flow (synthetic design storm parameters).</li> <li>Wasterwater flow (based on the population density, land registry, and daily per capita water capacity).</li> <li>Number of rainfall events.</li> <li>Network elements: manholes, outfalls, and conduits.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Physics-based assessment of urban pluvial floods.</li> <li>1D/2D hydrodynamic dual drainage model Iber-SWMM.</li> <li>2D dynamic sewer mode: the Soil Conservation Service Curve Number was used.</li><li>1D dynamic sewer model: (i) EPA SWMM (Storm Water Management Model), and (ii) Allows retrieval of hydraulic variables.</li><li>Creation of a representative virtual sewer network: Virtual sewer network generation and dimensioning tool: (i) Defines realistic network topology, (ii) Manholes are located where streets intersect with each other, and (iii) Manhole invert elevations are calculated.</li><li>Scenarios: (i) 1D/2D dual model using the actual network, (ii) 2D overflow model without sewer network, (iii) 2D overflow model with rainfall reduction for sewer network representation, (iv) 1D/2D dual model using a virtual sewer network, and (v) 2D overflow model using a virtual inlet layout.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Estimates accurately the sewer’s networks drainage capacity (SNDC). during pluvial floods.</li> <li>Soil Conservation Service Curve Number maps are created.</li> <li>Virtual and real sewer network maps are provided.</li> <li>Numerical simulated maximum inundation extent maps for all five (5) scenarios are provided.</li> <li>Scenarios with the actual network and without the sewer network indicate the importance of the SNDC. </li> <li>Scenario using the rainfall induction method are not efficient.</li> <li>The virtual sewer scenario resulted in the most effective estimations in the absence of any sewer network information.</li> <li>The SNDC of the virtual network is more extended when compared to the actual network.</li> <li> Evaluation through satellite images might contribute to a optimal performance of the proposed method in this recipe. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://meteogalicia.gal/">Meteorological data from the MeteoGalicia agency.</a></li> <li><a href="https://www.puertos.es/">Observed sea level data from the Spanish Port system.</a></li> <li><a href="https://www.miteco.gob.es/">Digital elevation model from the Spanish Ministry for Ecological, Transition and Demographic Challenges.</a></li> <li><a href="https://www.sedecatastro.gob.es/">Land Registry, soil use, and population information from the Spanish General Directiorate of the Land Registry.</a></li> <li><a href="https://www.openstreetmap.org/">The Street network layout from OpenStreetMap geodatabase.</a></li> <li><a href="https://augasdegalicia.xunta.gal/">The LiDAR-derive digital elevation model, observed water elevation data form the gause station, and the sewer network layout from the regional water administration Augas de Galicia.</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Urban pluvial flooding, Dual models, Iber, SWMM, Data scarcity.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> A potential methodology for the creation of a virtual network might be useful for the lab tests in ICARIA project.</code></td> </tr> </tbody> </table> |


#### HEV2. Storm damage beyond wind speed – Impacts of wind characteristics and other meteorological factors on tree fall along railway lines
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Storm damage beyond wind speed – Impacts of wind characteristics and other meteorological factors on tree fall along railway lines ({cite:p}`egusphere-2024-120`) [ <a href="https://doi.org/10.5194/egusphere-2024-120">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe examines the tree fall risk during hazard events, emphasizing the role of meteorological factors and conditions that influence tree falls, supporting the addition of local climatological conditions for improved risk assessment.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Parameters: (i) Wind speeds, precipitation, soil water volume, air density, and the precipitation sum of the previous year increase tree fall risk, and snow. </li> <li>Datasets: (i) Deutsche Bahn (2017-2021) and meteorological data from ERA5 reanalysis and RADOLAN radar, (ii) Tree fall events along the German railway network were derived from a data set created by the Deutsche Bahn, (iii) It contains 15311 tree fall events between 2017 and 2021, (iv) The dataset ranging from 2017 to 2021 covering the whole country and including long-term and large-scale storm damage contributes to the novelty of the recipe, (v) Hourly ERA5 data for all meteorological parameters except precipitation accessed using the ClimXtreme Central Evaluation System and (vi) Rail density index. </li>  </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A logistic regression model predicts the risk of a tree falling on a railway line in a 31 km grid cell. </li> <li>The analysis considered only the extended winter season, focusing on winter windstorms, which cause the most extreme peaks in tree fall events. </li> <li>Meteorological predictors like precipitation or soil moisture are considered less often: (i) Predictors describing precipitation and soil conditions at different time scales are also considered, (ii) Wind load can be considered as a model predictor, and (iii) Interactions can reveal the combined effect of predictors and their interconnection. </li> <li>Storm duration, gust factor, and air density are important factors in calculating the risk of tree fall. </li> <li>Inclusion of antecedent weather situations; Index: the Standardized Precipitation-Evapotranspiration Index (SPEI), which has been used in recent research on forest disturbance. </li><li>Snow and soil frost: (i) Potentially influential variables, and (ii) Derived from ERA5, which tends to overestimate snow water equivalent in the Northern Hemisphere. </li> <li>Limitations: (i) The events might be related to meteorological events not resolved by the ERA5 analysis, (ii) The wind speeds caused by heavy thunderstorms are likely to be underestimated, and (iii) Data with higher spatial resolution that include convective effects were not included (helpful in understanding the effects of the phenomena). </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul>  <li>Duration of strong winds is important because trees do not fail instantly but fail with repeated swaying that fractures the root/soil system and this process can take many hours. </li> <li>Future modelling might benefit from the addition of local tree wind exposure. </li>  <li>High and prolonged wind speeds, especially in combination with wet conditions (high precipitation and high soil moisture) and a high air density, increase the risk of tree fall. </li> <li>Predictors for daily precipitation, daily soil water volume, and daily maximum gust speed might improve the model's skill. </li> <li>Previous trees fall and forest storm damage events are restricted to a single event or a small research region. </li> <li>Wind-related parameters (e.g., gust factor, duration of strong wind speeds, air density, etc.) and predictors related to meteorology, have a significant impact on tree fall risk. </li><li>Taking tree adaptation to the environment should be considered</li> <li>Models that can add trees, soil, or stand data or have access to higher spatial resolution meteorological data will likely produce better model skills and be able to examine the relationships between tree fall and meteorology in more detail. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Windstorm; Railway system; Trees; Logistic regression model; Gust speed; Meteorological parameters. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improved assessment of windstorm impact on trees, support to vulnerability analysis of trees under extreme winds, potentially correlated to cascading impacts on transport and energy networks.</code></td> </tr> </tbody> </table> |


#### HEV3. OpenStreetMap for multi-faceted climate risk assessments
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> OpenStreetMap for multi-faceted climate risk assessments ({cite:p}`Muhlhofer_2024`) [ <a href="https://doi.org/10.1088/2515-7620/ad15ab">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents specific approaches to exploit OSM data and tools for informing hazard/impact assessments. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-3|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>OpenStreetmap data, and automation: Geofabrik.</li> <li>Automatic pipeline with CLIMADA. </li> <li>Variables: (i) Wind: for forests, wind intensities above 38.9 m/s were considered more adequate to capture tree snapping, (ii) Nightlight intensity and population (count at 30 arcsecond resolution with LitPop), and (iii) A population exposure at the same resolution based on the SEDAC GPW v4.0 dataset. </li> <li>Exposure data for heritage sites, forests, etc... </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Retrieval of geospatial exposure data from OSM. </li> <li>Features can be extracted from OSM and converted into geographical tabular format: (i) By reading data directly from the Overpass API, (ii) By downloading regional data dumps as protocol buffer binary format files. </li> <li>Technical details: (i) Python-based (tabular formats, geopandas, etc.), (ii) Efficiently parses large sets of OSM data based on user-specified queries from PBF data dumps within arbitrary and fully user-defined geographical boundaries, and (iii) Computational efficiency and user flexibility required to perform multi-faceted risk analyses. </li> <li>Integration within the natural hazard risk assessment platform CLIMADA and perform end-to-end assessments. </li><li>OSM with CLIMADA: (i) Compute risk according to the IPCC risk definition as the product of hazard, exposure, and vulnerability, (ii) CLIMADA's engine is designed only for pointwise data, thus data must be interpolated to points before impact calculations, and (iii) Dedicated hazard and vulnerability data can be provided in the CLIMADA data API. </li> <li>Risk management strategies, opening the potential for non-conventional exposure data. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>For forests and general asset values, physical losses and damages are modeled. </li> <li>Vulnerability curves relating to hazard intensity to damage extent were obtained for the wind-induced general asset damages. </li> <li>The possibility of retrieving an even larger variety of features (ecological regions, critical infrastructure, urban assets, etc.) remains open. </li> <li>Comparison with print media accounts, official records, and insurance reports, strengthens the picture of multi-faceted impacts obtained from computations. </li> <li>The standard impact computations within CLIMADA capture these metrics as asset damages and affected population. </li> <li>Considering probabilistic risk metrics to gauge the potential risk landscape and to adequately place the occurrence of historic events therein might be considered beneficial. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://github.com/osm-flex/osm-flex">OSM-flex package – GitHub repository. </a>  </li> <li> <a href="https://github.com/jameschevalier/cities">Polygon files extraction – GitHub repository.</a>  </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">OpenStreetMap, open-source GIS tools, climate risk assessment, natural hazards, adaptation, Urban areas, Hazard local effect; Vulnerability analysis.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Integration of high resolution local geospatial data variables to improve hazard characterization (e.g., run-off of different land cover types), exposure and vulnerability analysis (e.g., classification of buildings, road network, open spaces) depending on specific impact models input.</code></td> </tr> </tbody> </table> |


#### HEV4. On the positioning of emergencies detection units based on geospatial data of urban response centres
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> On the positioning of emergencies detection units based on geospatial data of urban response centres ({cite:p}`PEIXOTO2023104713`) [ <a href="https://doi.org/10.1016/j.scs.2023.104713">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe proposes a data-driven methodology for the optimal placement of multi-emergency detection units in smart cities, combined with geospatial data on urban infrastructure, ultimately, to define mitigation zones and enhance urban resilience to emergencies.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-HEV-4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input from mitigation response centers and their geospatial metadata (files in XML format). </li> <li>Input from existing urban infrastructure. </li> <li>General data: (i) Extraction area: OpenStreetMap, (ii) Pols and roads: OpenStreetMap, (iii) Mitigation zones (MZ), and (iv) Positions of Emergency Detection Units (EDU). </li> <li> Parameter for algorithms: Severity index of the zones.  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Mathematical definitions of the zone of interest, mitigation zone, point of interest, and severity index are proposed. </li> <li>Algorithms to indicate EDUs' positions: <ul> <li> Random: (i) Lowest computational cost, and (ii) No criteria for selecting the units’ positions. </li> <li> Balanced: (i) Utilized after the definition of MZs, (ii) Avoid uncovered areas and EDUs overlapping, (iii) Calculates coverage radius of EDU in each mitigation level so units avoid overlapping, and (iv) No guaranteed coverage around the level's borders.  </li> <li> Balanced+: (i) Improves Balanced algorithm positioning unit correctly covering around the level's borders, and (ii) No uncovered areas within the area of influence.  </li> <li> Restricted: (i) Add restrictions to the optimization problem for improving the applicability of the units' deployment, (ii) Cases where actual deployment is not possible, and (iii) Most computationally demanding. </li> <li> Computation of (i) the risk perception function, (iI the equation for a mitigation level of a zone, (iii) the total number of EDUs, (iv) the total number of EDUs per mitigation level.  </li> </ul> </li> <li>Mitigation zones act as data layers of a target area. <ul> <li> Based on the indirect relation between geospatial data, and urban hazards and emergencies.  </li> <li> The resilience to untreated emergencies based on the urban infrastructure was considered.  </li> </ul></li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>The concept of mitigation zones is proposed.</li> <li>The placement of Emergency Detection Units is considered as a potential issue for macrosystems solutions for entire cities. </li> <li>Maps of mitigation zones and response centers for an area of influence. (i) Depiction of the zones with low, medium, and high mitigation risk, and (ii) Depiction of the positions of the EDUs within the zones of risk to highlight uncovered areas. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Smart cities; Sustainable and resilient cities; Emergency detection, Sensors positioning; Urban infrastructure monitoring, Vulnerability analysis of service networks.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Sensor-based model to enhance the real time monitoring of service network (e.g., electricity, transport) and improve vulnerability analysis over time through monitoring.</code></td> </tr> </tbody> </table> |


#### HEV5. Advancing building data models for the automation of high-fidelity regional loss estimations using open data
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Advancing building data models for the automation of high-fidelity regional loss estimations using open data ({cite:p}`ANGELES2022104382`) [ <a href="https://doi.org/10.1016/j.autcon.2022.104382">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents a conceptual data model to integrate and query detailed building information, substantiated by a case study showing the model's effectiveness in generating models for accurate loss estimation.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-HEV-5|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Spatial and geometric modelling data (Fragility library available). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Building damages: (i) Assembling and managing spatial and geometric data of thousands of constructed buildings, and (ii) Building Topology Ontology (BOT). </li> <li>Hazards: (i) Wind, wind-driven rain, wind-borne debris, (ii) Specification on site-specific building geometries and locations paired with DEM, and (iii) Rain Admittance Factor (RAF) to discern the intensity of horizontal rainfall. </li> <li>Response: (i) Realistic loading characterizations for each actual constructed building, (ii) Supporting holistic simulation of each building's unique load path to derive consequent response quantities, and (iii) The automated development of structural analysis models to incorporate engineering demand parameters for specific components. </li> <li> Damage: (i) Automated probabilistic analyses in the damage assessment, (ii) Scenarios → global fragility or vulnerability curves for each generic building model, (iii) Fragility descriptions for wind-vulnerable building elements, (iv) Component-specific fragility models, and (v) Assembly-based vulnerability (ABV) approaches.  </li> <li> Scenarios: (i) Scenario 1: Hazard Analysis: Given a reference building and a site, find all buildings on the site that are within a given distance from the reference building, (ii) Scenario 2: Response Analysis (Fault Trees): Given a breach in the building façade, quantify the new internal pressure per story and determine which elements require load recalculation, (iii) Scenario 3: Damage Analysis: Determine the correlation coefficient, between the damage states of the i-th and j-th elements, considering elements of the same type, and (iv) Scenario 4: Loss Analysis: For a given story within a building, calculate the total surface areas of each element sub-class and type. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> N/A </code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Hurricane, Commercial, Regional loss estimation, Data model, Open data. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Multi-hazard exposure and vulnerability classification and analysis for buildings structural damage assessment.</code></td> </tr> </tbody> </table> |


#### HEV6. Estimating exposure of residential assets to natural hazards in Europe using open data
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Estimating exposure of residential assets to natural hazards in Europe using open data ({cite:p}`nhess-20-323-2020`) [ <a href="https://doi.org/10.5194/nhess-20-323-2020">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a methodology based on a non-parametric Bayesian network model using open data to estimate residential asset exposure to natural hazards in various European capitals, providing improved national-level economic valuations of residential properties.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-HEV-6|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Data: (i) building footprints (OpenStreetMap), (ii) high-resolution city models, (iii) pan-European raster datasets, (iv) historical hazard events, (v) Country-level socioeconomic data, and (vi) Alternative country-level asset value estimates. </li> <li>Main sources: (i) Eurostat, (ii) OpenStreetMap, (iii) HANZE database, and (iv) Copernicus Land Monitoring Service.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Calculations: (i) Identification of residential buildings, (ii) Models for building height prediction, (iii) Calculation of floor space, (iv) Residential building stock estimation, (v) Household content stock estimation. </li> <li>Application of a building-level damage model. </li> <li>The estimation of building height and number of floors was based on a non-parametric Bayesian network (BN), a probabilistic model allowing multivariate dependency analysis and uncertainty distributions of the predictors.  </li> <li> Country-level asset validation of buildings and households: (i) Perpetual inventory method (PIM): estimate the value of a stock (e.g., stock of dwellings), and (ii) Households: memorandum items in ESA 2010 were considered. The PIM method was applied once again. Annual investment was calculated based on the Classification of Individual Consumption by Purpose (COICOP).  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Average national-level gross replacement costs of the residential assets are computed. </li> <li>Output information: (i) Building-level asset value estimates for a test study area, (iii) Country-level building/content value per square space of floor space.</li> <li>Validation statistics for the building height prediction model and pan-European estimations of content value both for buildings and households. </li> <li> Limitations: (i) datasets can be affected by regional methodological specifics (e.g., rural areas), (ii) Quality of expenditure data are not robust given the divergence in deflators for individual items, (iii) households stock also semi-perishables and perishables which are excluded from any wealth assessments due to lack of information, (iv) non-homogeneous datasets, (v) the BN model is configured using expert knowledge. </li>  <li> This methodology might be extended: (i) to calculate past recorded damages from natural hazards, (ii) to calculate the average quality of residential buildings and households’ incomes and (iii) to rescale absolute damage functions.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li> BN model code (in Matlab) is available upon request.  </li> <li>  <a href="https://www.lighttwist.net/wp/uninet/">UNINET</a> Tool (free for academic purposes).  </li> <li> Data retrieval and processing in formats other than GIS utilized GDAL/OGR tools.  </li> <li> Flood damage in the  <a href="http://howas21.gfz-potsdam.de/howas21/">HOWAS21 database. </a> </li> <li> Additional resources of data for estimating residential building value can be seen in the supplementary information, Table S3.  </li> <li> Additional information on Consumption expenditure categories by COICOP 3-digit codes and durable items included in those categories by COICOP 4-digit codes can be seen in the supplementary information, Table S6.  </li> <li> Data for the household final consumption expenditure can be seen in the supplementary information, Table S8.  </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Residential assets; Bayesian-based models; Buildings Exposure; Buildings Vulnerability;  </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Classification of buildings features supporting exposure and vulnerability analysis of residential assets under different natural hazards.</code></td> </tr> </tbody> </table> |


#### HEV7. Asset exposure data for global physical risk assessment
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td>  Asset exposure data for global physical risk assessment ({cite:p}`essd-12-817-2020`) [ <a href="https://doi.org/10.5194/essd-12-817-2020">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces a transferable, high-resolution asset exposure dataset using the LitPop methodology combining nightlight intensity and population data to improve the spatial distribution of asset values, to enhance economic disaster risk assessments and climate change adaptation methods. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-HEV-7|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Datasets: (i) Gridded nightlights (Lit); satellite data from Nasa Earth Observatory/Black Marble product, (ii) Gridded population (Pop); non-spatial population and cartography data, (iii) Produced capital, (iv) GDP-to-wealth ratio, (v) GDP and GRP. </li> <li>GDP does not directly measure physical assets but fills data gaps for the evaluation of the LitPop methodology. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>LitPop downscaling: Lit and Pop data produce a gridded digital number and are combined with the total asset value per country to obtain asset exposure data and to compare GDP (macroeconomic output indicator) against the GRP for evaluation of the approach. </li> <li>Total assets per country and GDP are distributed and calculated according to a function of nightlight luminosity and population count. </li> <li>lpix; the asset value per cell grid; ltot: represents either asset value or GDP. </li> <li> Evaluation: ten combinations of Lit and Pop are assessed (Lit<sup>m</sup>Pop<sup>n</sup>).   </li>  <li> Limitations: (i) Asset distribution assumes physical wealth is distributed equally, (ii) Assets assumed to be located exactly where people live, (iii) Population data in many countries are coarse, (iv) Nightlight-based models are prone to saturation and blooming limitations, (v) Lack of reference asset value data on subnational level, (vi) Lack of consistent exposure data on a global scale, and (vii) The methodology does not include infrastructure type and vulnerability.  </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>LitPop-based asset exposure data are accessible and usable as a basis for global comparable economic risk assessments. </li> <li>The application of the asset exposure data for local assessments in countries within low-income groups should be treated with caution.</li> <li>Lit<sup>1</sup>Pop<sup>1</sup> combination distributes favors GDP distribution to the subnational level than the other combinations of nightlight and population data accessed. </li> <li> Additional sector-specific asset inventories and auxiliary data should be considered.  </li> <li> High-resolution asset exposure for LitPop combinations is estimated.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>  <a href="https://doi.org/10.3929/ethz-b-000331316" target="_self">Asset exposure for 224 countries. </a> </li> <li>  <a href="https://doi.org/10.5905/ethz-1007-226" target="_self">Open-source software for adaptation: CLIMADA. </a> </li> <li>  <a href="https://climada-python.readthedocs.io/en/stable/" target="_self">LitPop module and Tutorial on LitPop calculations.</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Asset exposure; Nightlight intensity; economic assessment; risk assessment; climate change. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability methodology.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Global high-resolution asset exposure methodology, applicable for estimating economic impact assessment under different natural hazards. </code></td> </tr> </tbody> </table> |


#### HEV8. Mapping Europe into local climate zones
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Mapping Europe into local climate zones ({cite:p}`10.1371/journal.pone.0214474`) [ <a href="https://doi.org/10.1371/journal.pone.0214474">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe constructs a European database, focusing on characterizing urbanized landscapes, offering dedicated datasets for the training areas.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-8|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>WUDAPT data. </li> <li>Products: (i) Sentinel-1, (ii) Sentinel-2, (iii) Defense Meteorological Program Operational Linescan System: Nighttime lights, and (iv) Local Climate Zone maps (LCZ) and their parameters. </li> <li>Indexes based on Earth Observation data: (i) the minimum and maximum Normalized Difference Vegetation Index (NDVI), (ii) the Biophysical Composition Index (BCI), (iii) the mean Normalized Difference BAreness Index (NDBAI, (iv) the mean Enhanced Built-up and Bare land Index (EBBI), (v) the mean Normalized Difference Water Index (NDWI), (vi) the mean Normalized Difference Built Index (NDBI), (vii) the Normalized Difference Urban Index (NDUI: the combination of the maximum values of NDVI, NDWI and NDBI indexes with the coarser resolution nighttime light imagery. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A step-by-step methodology in creating a general-use European Local Climate Zone map that can be used for climate studies is presented. The derived datasets can be used as substitute data to cover limitations in sector-specific local data gaps. </li> <li>Evaluation of LCZ map techniques: (i) Urban land cover, (ii) Impervious surface cover (IMD) and building height (BH), (iii) Anthropogenic heat flux (AHF), and (iv) Sky view factor (SVF). </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Map of the European LCZ classification based on the random forest classifier, binary urban maps, and assessment of urban land cover. </li> <li>Urban canopy parameters: (i) Building height, (ii) Maps of impervious surface fraction (IMD) and anthropogenic heat flux (AHF), Sky view factors map. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> The European LCZ map is available from the official  <a href="http://www.wudapt.org/">WUDAPT</a> (World Urban Database) data portal.  </li> <li> There is an LCZ generator provided at https://lcz-generator.rub.de/.   </li><li> LCZ datasets derived from the use of the generator are provided at https://lcz-generator.rub.de/submissions.  </li> </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">European Local Climate Zone map; E-OBS data.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improved hazard assessment based on urban/land morphology and cover. Classification of urban density, building types and land cover.</code></td> </tr> </tbody> </table> |


#### HEV9. CLIMADA v1: a global weather and climate risk assessment platform
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td>  CLIMADA v1: a global weather and climate risk assessment platform ({cite:p}`gmd-12-3085-2019`) [ <a href="https://doi.org/10.5194/gmd-12-3085-2019">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents an open-source, modular multi-hazard decision support tool for assessing extreme events and socioeconomic impact by hazard, exposure, and vulnerability data, supporting scalable, parallel computations and multi-hazard probabilistic assessment.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-9|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Hazard events for: storms, floods, droughts, heatwaves.</li> <li>Socioeconomic aspect: exposure and impact (vulnerability) functions. </li> <li>Exposure: e.g., geographical distribution of people, livelihoods, infrastructure, services, etc…</li>  <li>Impact functions: impact of a hazard on the corresponding exposures.</li>  <li>Nighttime lights of NASA's Black Marble 2016.</li>  <li>GDP values.</li> <li> International Best Track Archive for Climate Stewardship (IBTrACS) archive for tropical cyclones. </li></ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A fully probabilistic risk assessment modelling methodology is combined with economic development and climate impact scenarios to assess adaptation measures. </li> <li>Engine's risk metrics: (i) Expected annual impact (EAI), (ii) Average annual impact (AAI), (iii) Probable maximum impact (PMI), and (iv) Impact at the event. </li> <li>Medium (10 km) to high (500 m) resolution.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Supports risk management options and adaptation measures.</li> <li>Estimates: (i) the expected socioeconomic impact of weather and climate, (ii) the incremental increase from economic growth, (iii) the incremental increase due to climate change. </li> <li>Characteristics: of CLIMADA (i) open source, (ii) modular, (iii) scalable. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> CLIMADA <a href="https://github.com/CLIMADA-project/climada_python">GitHub repository</a> and <a href="https://github.com/CLIMADA-project/climada_papers">scripts</a> for the recipe. </li> <li> <a href="https://doi.org/10.5905/ethz-1007-187">ETH Data Archive</a> </li> <li> <a href="https://ethz.ch/content/dam/ethz/special-interest/usys/ied/wcr-dam/documents/Economics_of_Climate_Adaptation_ECA.pdf">Shaping climate-resilient development: a framework for decision-making </a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Risk assessment; Socioeconomic impact; Probabilistic approaches; Damage estimation. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Open-source platform for multi-hazard calculations suitable for regional to whole-country economic impact assessment studies. </code></td> </tr> </tbody> </table> |


#### HEV10. Comparing an insurer’s perspective on building damages with modelled damages from pan-European winter windstorm event sets: a case study from Zurich, Switzerland
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Comparing an insurer’s perspective on building damages with modelled damages from pan-European winter windstorm event sets: a case study from Zurich, Switzerland ({cite:p}`nhess-21-279-2021`) [ <a href="https://doi.org/10.5194/nhess-21-279-2021">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe highlights the benefits of a probabilistic approach for assessing rare events impacts and uncertainties, for claims-based risk assessment with test examples of the risks of winter windstorms in Europe. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-HEV-10|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>OpenStreetMap data. </li> <li>Hazard input: (i) Windstorm Information Service (WISC): Windstorms, and (ii) GVZ database: damages of past events. </li> <li>Other input: (i) Historic windstorm hazard set: 140 windstorm events in Europe (1940-2014); "WISC operational", (ii) Windstorm footprints (computed running the UK Met Office Unified Model at 4.4km resolution with ERA-20C reanalysis and ERA-Interim analysis; "WISC synthetic", and (iii) Insurance claims data. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Probabilistic windstorm hazard extension; “WISC probabilistic extension”: perturbations in the WISC historic events are introduced creating new probabilistic footprints (scenarios) of possible hazard events (windstorms in this recipe). <ul> <li> The frequencies of the footprints are estimated to recreate the cumulative distribution function of generalized extreme values fitted to historic events.  </li> <li> 4118 probabilistic events and 142 original events were considered.    </li>  </ul> </li> <li>Damage modelling: the damage results are based on: (i) the intensity of the hazard event, (ii) the value of the assets, and (iii) the susceptibility of the asset to damage. <ul> <li> GVZ damage model (proprietary): (i) uses a dedicated building database, (ii) only buildings affected by gusts with speed more than 90km h-1 are considered, (iii) the value of each building is multiplied by the mean damage degree (MDD) factor (obtain from vulnerability curves) to estimate damage, and (iv) provides the probability of building affected using a stochastic approach.  </li> <li> CLIMADA impact model: (i) exposure is based on public data (the total value of the physical assets, the nightlight intensity, and the population density are included), (ii) uses MDD curves for exposure evaluation.   </li>  </ul>  </li> <li>Damage and risk assessment: risk = extent of damage x probability of damage. Metric for risk assessment in this recipe: (i) Average annual damage (AAD), (ii) Exceedance frequency curve (uncertainty of exceedance frequency curve), and (iii) Pareto pricing (defines the price of insurance contracts) and general Pareto distribution (GPD).</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) Maps of wind gusts for every grid cell in the tested area for WISC historic, synthetic, and probabilistic extensions, (ii) AAD is provided based on the insured damages, (iii) Exceedance frequency curves for building damages including uncertainty are provided, (iv) Normalized the insured total damages in comparison to the modeled total damages are provided, (v) Rapid damage estimation directly after a hazard event is offered, useful for damage assessment, and (vi) WISC historic event data and local exposure information enable a reliable derivation of the return period of a (rare) hazard event. </li> <li>Uncertainties for damage estimation: (i) uncertainty associated with the assessment of the event, (ii) uncertainty regarding the damage model itself, (iii) Insurance claims might not report the exact time and date of damage (which introduces uncertainties), and (iv) In damage modelling estimations, movable property, damage to infrastructure, and business interruption are not included.   </li> <li>A probabilistic extension of the assessment of potential asset damages and risk of (extreme) hazard events is provided and associated with the evaluation of uncertainties.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> CLIMADA <a href="https://github.com/CLIMADA-project/climada_python">GitHub repository</a> and <a href="https://github.com/CLIMADA-project/climada_papers">scripts</a> for the recipe. </li> <li> <a href="https://doi.org/10.5905/ethz-1007-187">ETH Data Archive</a> </li> <li> <a href="https://doi.org/10.5281/zenodo.4442602">Winter Windstorm model: </a> (i) <a href="https://doi.org/10.3929/ethz-b-000406567">Probabilistic Windstorm Hazard Event Set for Europe</a> , and (ii) <a href="https://doi.org/10.3929/ethz-b-000406567">The probabilistic hazard event set WISC probabilistic extension for each European country </a>  </li>  </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Hazard events; Windstorms; Probabilistic methods; Insurance claims.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Connection of public hazard datasets with exposure and vulnerability methodology to assess impacts and uncertainties, focused on windstorms but transferable to other hazards.</code></td> </tr> </tbody> </table> |
