# <u>Recurring data gaps in impact assessment modelling </u>

ICARIA modelling framework (see *D1.1*) is aimed at quantifying impact from complex events, implying compound hazards and cascading effects conditions, with respect to multiple assets. Such multi-hazard and multi-receptor focus increase the complexity of assessing Hazard, Exposure and Vulnerability variables in time with the adequate spatial resolution to provide quantitative impact assessment information to support resilient planning and decision-making. Therefore, addressing data gaps implies their mapping across Trials and Mini-Trials, both to fill gaps and treating uncertainties, both to acknowledge in the assessment the assumptions and limitations related to data and their elaboration through modelling.  

The templates provided in Annex (introduced in *D1.1* to map for each Trial main data types expected input from T1.2, WP2 and WP3) have been developed to map the relevant data required the implement the hazard characterization, the exposure and vulnerability analysis and the risk/impact assessment in Case Study and followers regions. They also include an “event tree scenario building tool”, adapted from SNOWBALL project {cite:p}`ZUCCARO2018199`, intended to provide a visual representation of the specific modelling workflow(s) adopted in the studies and useful to support data-gap filling and uncertainties treatment (e.g. to determine hazards transition probabilities through expert elicitation procedures).

The ICARIA cookbook and the Jupyter platform introduced in Section 5 have been developed to provide references and technical specifications to address data gaps, including methods tested in T1.4. 

Based on the analysis from domain user survey and contributions from Case Study Facilitators ({index}`CFs`), the main critical data gaps can be grouped in two main categories: 
 - <u> __Climate Change and Hazard data__ </u>,  which determine the boundary conditions for hazard characterization in space and time, including aspects long term variation and seasonal trends of climate change patterns, extreme events frequency and intensity, local downscaling of hazards (i.e. with a spatial resolution higher than that derived by Regional Climate models ({index}`RCMs`)), probability of occurrence of coincident compound events, probability of transition among natural hazards in consecutive compound events, probability of transition in cascading effects from a given triggering hazard impacting critical service networks (e.g. transport, energy, water distribution).
 - <u> __Exposure and Vulnerability data__ </u>, which allow to determine expected impacts on risk receptors based on specific impact assessment models input requirements. Even considering the diversity of data input required by different impact models, recurring datasets can be identified with respect to the main hazard types.
 
## <u> Climate change and Hazard data </u>

<table>  <thead> <tr>  <tr>  <th> Data Group </th> <th> Description </th>  <th> Data gap-filling approach </th>  <th> Source </th>  </tr>  </thead>  <tbody>  
<tr> <td> Weather data not fully covering spatially the CS area considered </td>  <td> Thin Plate Spline ({index}`TPS`) methodology </td>  <td><code>Spatial interpolation techniques for distribution of climate parameters </code></td>  <td><code> CSFs, and Domain user survey </code></td>  </tr>  
<tr> <td> Weather data presents gaps in its time series, (i.e. lack of some daily registers for the variables considered) </td>  <td> For each observatory, the observatories located at a distance of less than 20 km and with a correlation of more than 0.7 are selected. In case there are less than 6 observatories that meet these requirements, the radius of proximity will be recursively extended by 5 km until there are 6 nearby observatories. Of the six (6) observatories that meet the above requirements, the three (3) with the highest number of data between 1979 and 2020 are selected. A multiple linear regression is performed with the data that the observatory to be filled and the three (3) observatories selected above have in common. With the parameters of the linear regression, the gaps of the standard observatory that are empty and whose data from the three (3) selected observatories are complete are filled in. No gaps are filled for a given day if any of the three (3) observatories with which the linear regression has been performed have no data for that day. All the previous points are repeated six (6) times with the objective that, in each iteration, more and more gaps are filled in. In the first three (3) iterations, gaps will be filled for the whole series, while in the last three (3) iterations, only gaps between the years 1979 and 2020 will be filled. </td>  <td><code> "_Closest-correlated neighbour_" weather data gap-filling methodology </code></td>  <td><code> CSFs, and Domain user survey </code></td> </tr>  
<tr> <td> Weather observations are too short, either not reaching the minimum years required for its use or not having data back in time enough for some modeling </td> <td> For some procedures, the use of a temporally homogeneous weather dataset is mandatory, with data covering (without gaps) the same extension of time. For this reason, and since most of the weather observations are quite recent, a temporal extension of weather data is performed thanks to the use of a climate reanalysis, the ERA5-Land in this case. Since observations and reanalysis do not always correlate perfectly (event with improved experiments), checking and testing of correlations are done locally between ERA5-Land and a set of regional stations. To further improve the reanalysis, a set of parameters is obtained and used to correct the reanalysis against the regional weather signals. On the other hand, this reanalysis is crossed with the weather observations, and thanks to the use of several transfer functions, the ERA5-Land, in the temporal extension desired, is corrected to properly reflect the true weather signal of the point, constructing, therefore, a simulated extended observation for the desired point. Last, this corrected simulated observation is crossed and filled with the original observation in those spots available, obtaining the original checked weather observation with gaps filled with a corrected reanalysis up to the date desired. </td>  <td><code> Weather data temporal extension methodology </code></td>  <td><code> CSFs, and Domain user survey </code></td>   </tr>  
<tr> <td> Weather observations are used for statistical downscaling presenting outliers, errors, or missing data.
</td> <td> A two-way quality control methodology is applied generally to all weather data sources prior to their use.
<ol>
  <li>Basic consistency. Direct rejection of self-evident wrong values: for example, negative values for precipitation.</li>
  <li>Atypical values or ‘outliers’. Unusual values within a data set: values that could come from different sources of data or values that could have been generated differently from the rest of the data. In this case, the theoretical difficulty of their recognition depends on our definition of “atypical”. In practice, the recognition is generally referred to values whose absolute magnitude is unusually high.</li> </td>  <td><code> Weather Data Quality Control </code></td>  <td><code> CSFs, and Domain user survey </code></td>   </tr>  
<tr> <td> Weather observations used for statistical downscaling presenting changes in trends due to modifications of instrumentations or locations, among others. </td> <td> The way to proceed with the homogeneity test that we have used is based on a method that detects gaps inhomogeneities in daily data {cite:p}`monjo_2022_6525733`:
<ol>
  <li>To measure how similar is data belonging to one year to data belonging to another year, it is used a distribution comparison test based on the Kolmogorov-Smirnov ({index}`KS`) test. The KS test is a non-parametric statistical test (it does not presuppose distributions of the studied variable) which provides a p-value that can be used as a measurement of the similarity between two years. Values that are close to 0 show that two years have a value distribution very similar and we can infer that there is not an inhomogeneity between them. The lower the value for Log(KS), the greater the probability of inhomogeneity between two consecutive values.</li>
  <li>If one year has been selected as a possible indicator of inhomogeneity, then it is subjected to another test (“Similarity between years”). Once we select the year that possibly presents an inhomogeneity and the following one, we figure out the p-value of every year of the series with respect those two years. If a jump or a break shows up between all those p-values in the years that we are considering, then we can infer that there is a true inhomogeneity for all the series. </li> </ol></td>  <td><code> Weather Observations Homogeneisation techniques </code></td>  <td><code> CSFs, and Domain user survey </code></td>   </tr>  
<tr> <td> Hazard downscaling at high resolution (<250m) </td> <td> Climate change affects urban areas unevenly depending on local conditions. Both heat and flood extreme events hazard intensity magnitude can greatly vary depending on specific local factors, such as urban morphology, surface materials and vegetative cover, location of critical assets and components of service networks (e.g. transport, energy, water distribution). Most hazard models adopted in ICARIA include the assessment of such variables to quantify impacts at local level and support resilient planning and decision-making. In order to capture the effect of urban infrastructure on hazards and potential cascading effects, a Land Use Land Cover ({index}`LULC`) database mapping their geospatial distribution should include information with adequate resolution to provide hazard models with the needed input parameters. </td>  <td><code> Remote sensing data can be used as proxy of heat / flood hazard (e.g. Land Surface Temperature as proxy of UHI, soil imperviousness as proxy of flood hazard); Data fusion methods combining multiple open datasets </code></td>  <td><code> CSFs, and Domain user survey </code></td>  </tr> 
<tr> <td> Probability of occurrence of coincident compound events </td> <td> The occurrence of coincident compound hazards in a given area can be assessed through joint probability approaches. The analysis must be linked to historical data related to the respective hazards to identify possible correlations and supported by expert elicitation. Different methods are proposed in ICARIA (see _D2.2_), such as Spearman’s rank or Pearson coefficient, to determine hazards correlation from past events datasets analysis. Once this step is completed, joint probability can be assessed through statistical methods such as copula models, which allow to analyse the relationship/dependence between variables, or Monte Carlo simulations, where a large number of scenarios based on their individual probability distributions and correlations can be run. The final step Analysis can then be carried out on the frequency that both these hazards occur simultaneously (or sequentially) to estimate their joint probability. </td>  <td><code> Statistical methods (joint probability), supported by open datasets (e.g. database of past events, such as EM-DAT) and Expert elicitation methods </code></td>  <td><code> CFs </code></td> </tr>  
<tr> <td> Probability of occurrence of consecutive compound events and/or of cascading effects </td> <td> The occurrence of consecutive compound hazards in a given area can be assessed through conditional probability approaches. The analysis can be linked to historical data related to the respective hazards to identify possible correlations and supported by expert elicitation. Recurring approaches include Bayesian methods to assess conditional probabilities of transition among consecutive compound events and/or cascading effects, and the use of conditional probability tables to illustrate the relationships. </td>  <td><code>Statistical methods (conditional probability), supported by open datasets (e.g. database of past events, such as Emergency Events Database ({index}`EM-DAT`)) and expert elicitation methods </code></td>  <td><code> CFs </code></td> </tr> </tbody> </table>

## <u> Exposure and Vulnerability data </u>
 
<table>  <thead> <tr>  <tr>  <th> Data Group </th> <th> Description </th>  <th> Data gap-filling approach </th>  <th> Source </th>  </tr>  </thead>  <tbody>  
<tr> <td> Missing information at local scale (i.e. urban area) </td>  <td> Detailed exposure and vulnerability analyses require high-resolution information based on specific impact models requirements. Such information can be integrated in a GIS platform with the LULC database to optimize data exchange and interoperability. Recurring data gaps by hazard type can be summarized as follows:
<ul>
  <li><u> Heat waves </u> - Buildings: building envelope (walls + windows) S/V ratio; construction typologies; {index}`HVAC`(Heating, Ventilation, and  Air Conditioning) system type; Outdoor spaces (artificial and vegetated): albedo, emissivity, shading conditions, Sky View Fastor ({index}`SVF`), evapotranspiration, surface temperature; Population: spatial distribution; age; income.</li>
  <li><u> Floods (pluvial/coastal/river) </u> - Buildings: ground/underground level permeability;  Outdoor spaces (artificial and vegetated): urban watershed relative altimetry; proximity of run-off streams; drainage capacity by land use; Service networks: sewer capacity (including manholes status); Energy network: primary/secondary cabins; distribution network; Population: spatial distribution; Property  (structure + content): opening ratio at ground floors; underground floors; sidewalk / steps to enter ground floors.</li>
  <li><u> Droughts </u> - Land cover (natural, agricultural, urban green); vegetation inventory; local water supply sources; resistance of plant types.</li>
  <li><u> Forest fire </u> - Buildings: building envelope (walls + windows); construction typologies; Outdoor spaces (artificial and vegetated): Land cover (natural, agricultural, urban green); vegetation inventory; local water supply sources; resistance of plant types; Population: spatial distribution; age; income. </li>
</ul></td>  <td><code>Data interpolation through statistical methods based on available open data sets; Expert elicitation </code></td>  <td><code> CFs </code></td>  </tr>  
<  </tr>  </tbody>  </table>
