# <u> ICARIA cookbook: recipes for data gap filling </u>

This chapter is dedicated to gathering a series of methodologies for data gap filling and data uncertainty methods compiled in a cookbook. It outlines data gap groups, data requirements, data collection templates, and sources, emphasizing the potential replicability of any of the methodologies in case studies or during lab tests. A series of approaches are provided to address data gaps and uncertainty, including but not limited to automated data downscaling, extrapolation, synthetic data generation, etc. focusing on data-driven methodologies and their applicability for addressing data gaps and uncertainty. Additionally, a domain users' survey based on ICARIA's internal and external network is compiled, from experts with diverse backgrounds, collecting key feedback on the current and emerging functionalities of data-driven methodologies that the experts are already using or considered to use. The survey can be treated as a recommendation tool for the CFs, promoting replication of ICARIA results beyond the case studies within the project.

## <o> Cookbook structure and general template in Jupyter book </u>

A Jupyter Book is an open-source framework designed to serve as a generator of digital documents and books by integrating Jupyter Notebooks and Markdown files. It enables the seamless unification and presentation of data, code, and narrative text, making it highly suitable for interdisciplinary research and educational purposes. For combining climate resilience methodologies with data-driven techniques, the Jupyter Book will provide a structured environment for rendering extensive datasets, documenting analytical workflows, and coherently delivering results, ensuring replication, strengthening collaboration within the project, and fostering comprehensive dissemination of findings. In ICARIA, a supporting cookbook will be developed by collecting and compiling datasets and methodologies from the literature in a Jupyter notebook. This notebook will mirror the recipes listed in the initial _D1.3_ document, creating a scaffold for a more rigid understanding of the data gaps, which will later inform the implementation of Trials and Mini-Trials, prioritizing which gaps tend to appear, yielding fruitful results when addressed with representative methods. More specifically the Jupyter book will be organized as follows: each section of the _D1.3_ document will be systematically transferred to the Jupyter book, with each section receiving its dedicated chapter. For Chapter 3, which enumerates the cookbook's recipes, distinct categories—statistical methods, dynamical downscaling methods, data-driven methodologies, expert elicitation methods, and uncertainty treatment methods—will each be allocated a dedicated subsection containing a detailed list of recipes. Representative information for each recipe, as presented in their designed tables, will be transferred to the appropriate subsection. Furthermore, the domain survey data, including the questionnaire, responses, and a summary of results, will be thoroughly documented. Finally, the chapter referring to the reflections on data gaps and supplementary information from the appendix will be incorporated to ensure a comprehensive and scientific presentation. The Jupyter book will be hosted in a GitHub repository, freely accessible, allowing for continuous updates and extensions of the content, besides easy access and modifications by the case study facilitators. A Figure of the footer of the Jupyter book can be seen below.

<p align="center">
  <img width="620" height="200" src="screenshot.322.jpg">
</p>

## Cookbook “_recipes_”
The following sections contain the technical specifications and tools selected from literature, organized taking into account the main underlying methodology with respect to those identified in Section 3, although it is worth noting that the case studies implementing the suggested “_recipes_” often adopt hybrid approaches, combining multiple methodologies.
 
#### Description of Recipe and Identification: 

Due to the interdisciplinary character and diverse areas of application of the methodologies attempting a totally rigid categorization would only add additional confusion, if not, being far from realistic. Thus, the categorization of the recipes within the cookbook was tailored to align with the project's objectives. As a result, a straightforward yet effective way to distinguish each recipe while providing a meaningful description was aimed. Each recipe is labeled using the following format: 
 _Recipe - [Category in Cookbook] [Number] [Secondary Category/Example] [Additional Characterization]_ 
An example: a recipe categorized under downscaling methodologies, listed second, focused on statistical downscaling methods and identified as a review paper The unique label would be the following:  
Recipe CH01-DD-R, where: 
 - "CH" denotes {index}`Climate and Charge Hazard`(or EV denotes {index}`Exposure and Vulnerability data`),
 - "01" represents the unique number, 
 - “DD” representing data-driven methodologies (if any), and 
 - "R" is appended to indicate it is a review paper. 
Thus, all labels in recipes within the cookbook will follow the same manner, depending on the subsection and category they belong to. 

### Statistical methods

### Dynamical downscaling methods

#### S1. Long-term daily stream temperature record for Scotland reveals spatio-temporal patterns in warming of rivers in the past and further warming in the future

|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Long-term daily stream temperature record for Scotland reveals spatio-temporal patterns in warming of rivers in the past and further warming in the future [<a href="https://doi.org/10.1016/j.scitotenv.2023.164194" target="_self">Link</a>] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents a rigid methodology to estimate long-term daily stream temperature due to the scarcity of available datasets for creating a national daily stream water temperature dataset for Scotland. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Climatic and hydrological variables (e.g., air temperature, etc.).</li> <li>Harmonized monitoring scheme (HMS) dataset. </li> <li>National river flow archive (NRFA).  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul><li>CNNs, GLMs, XAIs. </li> <li>CNNs to statistically downscaled max and min temperatures over SSA (CNN-R: CNN model with non-linear configuration). </li> <li>"CNN showed good skills to produce plausible projections, however, differences with RAW and GLM in the intensity of the signal were identified when non-linearity was considered (CNN-R)" (sic). </li></ul></code></td> </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul><li>Outputs: (i) Estimation of long-term daily stream water temperature, (ii) Mean monthly and year precipitation maps, (iii) Environmental controls maps on studied variables, (iv) Average base flow index maps, (v) Forecasting of future stream water temperature (long-term daily records, etc.), (vi) Analysis of historical trends as coarser temporal resolution and future changes at high temporal resolution, (vii) Explore the role of controls for individual catchments. </li> <li>Temperature maps allowed for identification of the sites with the highest temperature increases, allowing for implementing thermal moderation measures to address this issue.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era-interim" target="_self">ERA-Interim analysis</a></li> <li><a href="https://esgf-node.llnl.gov/search/cmip5/" target="_self">"EC-Earth model simulations from the CMIP5 modelling experiment" (sic).</a></li> <li>"Suggestion: model uncertainty and multi-GCM ensembles with prospects to be further utilized in climate change studies over the region" (sic). </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; ML; Extreme temperature; GCMs; GLMs; CNNs. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code>Analyze historical trends and understand the role of environmental controls and the future changes under regional climate projections. </code></td> </tr> </tbody> </table> |

#### S2. Regional climate model emulator based on deep learning: concept and first evaluation of a novel hybrid downscaling approach

|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Regional climate model emulator based on deep learning: concept and first evaluation of a novel hybrid downscaling approach [ <a href="https://doi.org/10.1007/s00382-022-06343-9">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a hybrid downscaling methodology to extend the high-resolution RCM simulation ensembles at a reasonable cost and identify sources of uncertainty.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Daily near-surface temperature from EUR11-CORDEX simulations based on the CNRM-ALADIN63 regional climate model driven by the CNRM-CM5 global climate model used in CMIP5.</li> <li>The historical period runs from 1951-2005.</li> <li>Scenarios (2006-2100) are based on RCP4.5 and RCP8.5.</li> <li>2D: (i) Geopotential, (ii) Humidity, (iii) Temperature, (iv) Ward wind, and (v) Sea level pressure. </li> <li>1D: (i) Digital spatial means of 2D, (ii) Daily spatial standard deviation of 2D, (iii) Solar and ozone forces, and (iv) Seasonal indicators.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>The RCM-emulator is based on a fully convolutional neural network algorithm, called UNet.</li> <li>Evaluation both on perfect model and GCM worlds.</li> <li>Reproduces the high-resolution spatial structure and daily variability of the RCM.</li> <li>Issues reproducing accurate simulations of extreme events.</li> <li> Issues reproducing the complete climate change magnitude. </li> <li> RCM's general functioning can be broken down into two parts: a large-scale transformation and a downscaling function. </li> <li> A novel hybrid downscaling approach that emulates the downscaling function of an RCM. </li> <li> The combination of both empirical statistical downscaling methods and RCMs is part of the novelty of this recipe. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Transformation from low resolution information to the high resolution near surface temperature.</li> <li>Aiming at the feasibility to emulate the RCM complexity at high-frequency and high-resolution.</li> <li>RCM-GCM inconsistencies at large scales.</li> <li> A high-resolution simulation is provided by the emulator, corrected from the GCM-RCM large-scale inconsistencies. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Relevant projects: <a href="https://www.eucp-project.eu/#:~:text=EUCP%20(European%20Climate%20Prediction)%20is,producing%20some%20of%20this%20information.">EUCP European Climate Prediction System</a> </li> <li> <a href="https://github.com/antoinedoury/RCM-Emulator">RCM-Emulator: Code and data to build and train the emulator</a></li><li>Supplementary information: summary tables of the different tests performed with the UNet-based emulators. </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td>Emulator; Hybrid downscaling; RCMs; Statistical downscaling; Deep neural network; Machine Learning; EURO-CORDEX.</td> </tr> <tr> <td>Tag/Type</td> <td>Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td >Potential use in ICARIA: Emulating the downscaling function of an RCM to improve the resolution of climate change data in case study areas.</td></tr></tbody></table> |

#### S3. Bayesian analysis of high-frequency water temperature time series through Markov switching autoregressive models
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Bayesian analysis of high-frequency water temperature time series through Markov switching autoregressive models [ <a href="https://doi.org/10.1016/j.envsoft.2023.105751" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a methodology based on autoregressive models for the estimation of water temperature time series. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S3 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>River temperature (along with covariates: flow, air temperature, rainfall, wind speed and direction, radiation, and soil temperature).</ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Methods: (i) Bayesian interference, (ii) Markov chain Monte Carlo (MSMC), and (iii) Metropolis-Kuo-Mallick (MKMK) method, and (iv) (Non-homogeneous) MSARMs (Markov switching autoregressive models). </li> <li>MSARMs allow: (i) Discrete-time stochastic process, (ii) Modelling non-linear and non-normal time series by assuming that different autoregressions, each one depending on a hidden state, alternate according to the Markovian regime switching, and (iii) Classifying the observations into a small number of homogeneous groups, labeled as the regimes of the Markov chain.</li> <li>Observed state-dependent autoregressive processes driven by an unobserved, or hidden, Markov chain, Markov switching autoregressive models.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Methods to reconstruct high-frequency time series. </li> <li>Bayesian model to study the dynamic evolution of water temperature. </li> <li>MSARMs can be improved using filly Gibbs sampling algorithms avoiding the random walk Metropolis moves.</li> <li>Data augmentation techniques can be further applied to non-homogeneous hidden Markov chains to extend the model.</li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://doi.org/10.6084/m9.figshare.21801004">MSARMS Codes</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time-series; Non-linearity; Stochastic variable selection; missing values.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess river water temperature variation as source of hazard of natural ecosystems.</code></td> </tr> </tbody> </table> |

#### S4. High-resolution downscaling with interpretable deep learning: Rainfall extremes over New Zealand
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> High-resolution downscaling with interpretable deep learning: Rainfall extremes over New Zealand [ <a href="https://doi.org/10.1016/j.wace.2022.100525">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This methodology tests deep learning techniques against existing statistical approaches for downscaling historical rainfall events. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S4 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Gridded rainfall from Virtual Climate Station Network (VSCN).</li> <li>Variables: Consecutive available potential energy, Mean Sea level pressure, Specific humidity, Temperature, Wind, Geopotential height, and Precipitation.</li> <li>Time periods: (i) Training period: 1980-2012, (ii) Validation period: 2013–2016, and (iii) Testing period: 2017–2020.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Linear statistical models: Principal component analysis (PCA) for geopotential height and air temperature. </li> <li>Candidate predictor variables: Geopotential height, air temperature, zonal wind, meridional wind, wind speed, and geostrophic vorticity. </li> <li>Deep learning/Evaluated models: (1) CNNs: (i) Models: Non-linear CNN Gamma, Linear CNN, Non-Linear Gamma, Linear Gamma, and Linear dense.</li> <li>Interpretable deep learning ("explainable AI"): (1) Grad-CAM, and (ii) Able to target the most relevant meteorological features for predicting extreme rainfall events.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Simple CNNs with traditional encoder-decoder structure provide superior results over other more recent networks. </li> <li>The deep learning framework improves rainfall downscaling, the largest for extreme rainfall events.</li> <li>The best CNN model outperforms existing statistical approaches (temporal variability and mean and extreme rainfall). </li> <li>Maps of extreme events for the Grad-CAM+ model were provided. </li> <li>Prediction of rainfall and extreme rainfall events (downscaling rainfall).</li> <li>The potential applicability of other types of networks e.g., conditional generative adversarial networks cGANs (unsupervised) is mentioned.</li> <li>Limitations: (i) Temporal relationships in data are not captured by CNNs, (ii) VCSN is known to have rainfall biases when the observation network is sparse, (iii) CNNs provide dry bias for extreme rainfall, and (iv) Due to limitations of input (e.g., historical data), these methods might not capture non-stationary processes.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://github.com/sicara/tf-explain">The Grad-CAM interpretable deep learning code</a></li><li><a href="https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels">ERA5 analysis, C3S </a></li><li>"The VCSN data is developed and maintained by NIWA and can be obtained through a data access agreement through correspondence with the authors" (sic)</li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; Deep learning; Machine learning; Precipitation extremes; Rainfall. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Hazard characterization of extreme precipitation events.</code></td> </tr> </tbody> </table> |

#### S5. Dasymetric Mapping of Population Using Land Cover Data in JBNERR, Puerto Rico during 1990–2010
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dasymetric Mapping of Population Using Land Cover Data in JBNERR, Puerto Rico during 1990–2010 [ <a href="https://doi.org/10.3390/land11122301">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe provides a methodology to estimate the spatial population of an area and was proposed as a solution when critical data are scarce.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S5|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Total population, (ii) Land cover datasets (high-resolution), and (ii) Raster data (climate parameters). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A dasymetric mapping methodology for enhancing population spatial data by using various geospatial sources to produce a European Union-wide dataset of population variations. <ul><li>(i) Target zone estimation, (ii) Density estimation of ancillary class, and (iii) Error estimation. </li></ul></li> <li>The methodology combines widely available geospatial data like CLC, Openstreet map, and Copernicus Land Monitoring Service datasets (European Settlement Maps) with third-party datasets (Multinet, ToMTom datasets) and statistical data from EUROSTAT in a novel approach to map daytime population dynamics</li> <li>The approach can be used to enhance other data more relevant to disaster response or impact mapping.</li><li>The proposed methodology can be a general-use methodology for enhancing/improving sectorial data used in climatic scenarios. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) The multi-temporal population grids for the European Union at 1 km2 resolution that have been generated during this study have been deposited in the European Commission’s Joint Research Centre Data Catalog, with an identifier, and can be accessed at ENACT-POP R2020A - ENACT 2011 Population Grid, (ii) Dasymetric mapping error assessment, (iii) Maps of dasymetric population. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://doi.org/10.1038/s41467-020-18344-5">Uncovering temporal changes in Europe’s population density patterns using a data fusion approach</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Intelligent Dasymetric mapping (IDM); Land use; Land cover; Census Data. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Categorizing population data with respect to land cover information.</code></td> </tr> </tbody> </table> |


#### S6. Climate change and energy performance of European residential building stocks – A comprehensive impact assessment using climate big data from the coordinated regional climate downscaling experiment
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Climate change and energy performance of European residential building stocks – A comprehensive impact assessment using climate big data from the coordinated regional climate downscaling experimen [ <a href="https://doi.org/10.1016/j.apenergy.2021.117246">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers an impact assessment of climate change on the energy performance of residential building stocks considering different climate scenarios. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-S6|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul>  <li> Numerical energy simulations for building stocks. </li> <li>Gathering data using: (i) Tabula webtools, and (ii) "EPISCOPE".</li> <li>Measure of energy performance of buildings: Cooling and heating demands estimations. </li> <li>Future climate datasets.</li> <li>Future climate scenarios periods: 2010–2039 (near-term or NT), 2040–2069 (medium-term or MT), and 2070–2099 (long-term or LT).</li> <li>Climate data synthesized: (i) RCA4, (ii) RCPs: RCP 2.6, RCP 4.5, and RCP 8.5, (iii) Spatial resolution of 12.5 km and temporal resolution of 15 min, and (iv) GCMs: Centre National de Recherches Météorologiques Climate Model 5 (CNRM-CM5), Irish Centre for High-End Computing model (ICHEC-EC-EARTH), Institut Pierre Simon Laplace model (IPSL-CM5A-MR), Met Office Hadley Centre model (MOHC-HadGEM2-ES), and Max Planck Institute model (MPI-ESM-LR). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li> Models the energy and performance in IDA Indoor Climate and Energy (IDA ICE). </li><li>It uses the Intergovernmental Panel on Climate Change (IPCC) Third Assessment Report model summary data of the HadCM3 A2 experiment ensemble which is available from the IPCC Data Distribution Centre (IPCC DDC). </li> <li>The tool transforms ‘present-day’ EPW weather files into climate change EPW or TMY2 weather files which are compatible with most building performance simulation programs.</li> <li>Future climate scenarios are simulated using GCMs</li> <li>Dynamically downscaled weather data generated by RCMs.</li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul><li> Output: (i) Annual average of heating and cooling demand, (ii) Forecasting of weather conditions (e.g., temperature distribution, etc.), (iii) Forecasting of averages for heating demands, (iv) Forecasting of averages for cooling demands, (v) Indoor thermal comfort based on different RCPs. </li><li>The framework focuses on building energy performance case studies and on solutions for reducing energy demands. </li> <li>The vulnerability of cities to climate change based on the indoor thermal comfort is also considered and estimated.</li> <li>Short- and long-term climate variations and extremes should be considered when assessing energy demands and building performance.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://energy.soton.ac.uk/climate-change-world-weather-file-generator-for-world-wide-weather-data-ccworldweathergen/">CCWorldWeatherGen</a></li><li><a href="https://unfccc.int/topics/resilience/resources/climate-related-risks-and-extreme-events">Climate-related risks and extreme events </a></li><li><a href="https://www.eea.europa.eu/en/analysis/indicators/total-greenhouse-gas-emission-trends">Total net greenhouse gas emission trends and projections in Europe</a></li><li><a href="https://www.hse.gov.uk/temperature/thermal/index.htm">Thermal comfort </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Climate change; Extreme Events; Energy performance of buildings; Thermal comfort; Assets.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Correlate climate change trends with variation of seasonal energy needs. Incorporate in assets’ data attributes the estimate of energy performance and related cost.</code></td> </tr> </tbody> </table> |


#### S7. Comparison of stochastic and machine learning methods for multi-step ahead forecasting of hydrological processes
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Comparison of stochastic and machine learning methods for multi-step ahead forecasting of hydrological processes [ <a href="https://doi.org/10.1007/s00477-018-1638-6">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe compares stochastic and data-driven methods for multi-step forecasting via computational experiments using simulated time series and real-world river discharge data </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S7|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Framework for evaluating forecasting methods in hydrology; River discharge forecasting.</li> <li>Simulation of time series using stochastic models.</li> <li>Mean annual river discharge time series.</li> <li> Hydrological variables at large time scales. </li><li>Input: (i) 12,000 simulated and 92 monthly streamflow time series, (ii) 6,000 simulated, (iii) 135 annual temperature time series, (iv) 24,000 simulated, 185 annual temperature, and (v) 112 annual precipitation time series.</li></ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Comparison between stochastic and data-driven methods for the forecasting of hydrological processes based on large-scale simulations.</li> <li>Time series forecasting can be classified into eight categories: (1) Exponential smoothing, (2) ARIMA, (3) Seasonal models, (4) State space and structural models and the Kalmar filter, (5) Nonlinear models, (6) Long-range dependence models, e.g., the family of Autoregressive Fractionally Integrated Moving Average (ARFIMA) models, (7) Autoregressive Conditional Heteroscedastic/Generalized Autoregressive Conditional Heteroscedastic (ARCH/GARCH) models, and (8) Count data forecasting. </li> <li>Simulated processes: (i) ARMA (p,q), and (ii) ARFIMA (p.q.d).</li> <li>Real-time world series: (i) Mean annual river discharge time series, (ii) Autocorrelation Function (ACF), (iii) Partial Autocorrelation Function (PACF), and (iv) Hurst–Kolmogorov (HK). </li> <li>(a) Forecasting methods: (1) Stochastic methods: (i) Packages: arfima, Arima, auto_arima, BATS, ets, forecast, rwf, ses theta, and built-in-R functions, (ii) Naive forecasting method, and (iii) Random Walk forecasting method. (b) Data-driven methods: (i) Random Forest, (ii) NN, RF, SVM; package: ksvm, and (iii) Utilization of a single hidden-layer Multilayer Perceptron (MLP). </li> <li>Evaluation criterion for the models: (i) Type 1 accuracy: the closeness of the forecasted time series to the target time series, (ii) Type 2: the closeness of the mean of the forecasts to the mean of the target value.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Stochastic generation of weather data. </li> <li>Benchmark information is available for methodologies in this recipe.</li> <li>Heatmaps of the average-case performance of the forecasting methods. </li> <li>In total, ML models are more likely to outperform the stochastic methods in terms of accuracy and computational costs, remaining prone to their own limitations. </li><li>Models applied for forecasting can be transferred for studying hydrometeorological concepts. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>R packages: Cgwtools, Devtools, EnvStats, Forecast, Fracdiff, Gdata, HKprocess, Knitr, Plyr, Readr, Rminer,Tidyr, hydroGOF. </li><li>No free lunch theorem – <a href="http://blog.drhongtao.com/">Blog source</a>.</li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">No free lunch theorem; Random Forests; River discharge; Support Vector Machines; Time series. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td> <td><code>Improve local climate change information through stochastic and data-driven approaches, focused on hydrological processes but transferable to other relevant variables.</code></td> </tr> </tbody> </table> |


#### S8. Downscaling probabilistic seasonal climate forecasts for decision support in agriculture: A comparison of parametric and nonparametric approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Downscaling probabilistic seasonal climate forecasts for decision support in agriculture: A comparison of parametric and nonparametric approach [ <a href="https://doi.org/10.1016/j.crm.2017.09.003">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents two downscaling methodologies, parametric and non-parametric, which are compared for seasonal rainfall forecasts, and their performance for stable simulations of the total rainfall distributions is explored.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S8 |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Seasonal rainfall and its characteristics. </li> <li>Downscale scenarios: (i) Frequency-only (π-only), (ii) rainfall amount 0nly (Rm-only), (iii) rainfall intensity (μ-only), (iv) both rainfall frequency and intensity（π-μ), (v) rainfall frequency and constraining total rainfall (Rm-μ), and (vi) rainfall intensity and constraining total rainfall (Rm -μ). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Stochastic non-parametric temporal downscaling method – FResampler1: (i) Based on the concept of "conditional block sampling", and (ii) Disaggregate SCF (seasonal climate forecasts) to daily weather realizations. </li> <li>Parametric downscaling method – predictWTD; Based on conditional stochastic weather generator. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Sensitive to data volume, sampling size, and number of realizations (requirement for stochastic models). </li> <li>FResampler1 performs equally well to the parametric predictWTD method, captures seasonality and temporal correlation structure of data, remains sensitive to the number of realizations and to data availability. </li> <li>The predictWTD remains sensitive to the length of observed data, not sensitive to number of realizations, and required longer periods of observations for rainfall amount or conditioning or intensity. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="http://iri.columbia.edu/">IRI Net Assessment Seasonal Climate Forecast </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Stochastic disaggregation; Probabilistic seasonal climate forecast; Parametric downscaling; Non-parametric downscaling; Rainfall. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Probabilistic non-parametric downscaling methodology for seasonal climate forecasts.</code></td> </tr> </tbody> </table> |


#### S9. An R package for daily precipitation climate series reconstruction
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> An R package for daily precipitation climate series reconstruction [ <a href="https://doi.org/10.1016/j.envsoft.2016.11.005">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers the technical characteristics of an open-source package written in R language for treating large data gaps, applied to sample precipitation datasets. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S9|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: Daily precipitation (complete precipitation datasets). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Treating large data gaps.</li> <li>"*The observatories were located at less than 20 km and with a correlation of more than 0.7, else to meet the necessary requirements, the radius of proximity was recursively extended by 5km.*"</li> <li>A multiple linear regression was performed with the data all observatories had in common.</li> <li>The gaps of the standard observatory that are empty were filled in with data from the other observatories.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>"*Closest-correlated neighbor*" weather data gap-filling methodology". </li> <li>Data gap-filling for weather observations used by FIC in ICARIA.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Related projects: Junta de Andalucía SICMA Climate Change local scenarios </li> <li><a href="https://cran.r-project.org/web/packages/reddPrec/index.html">reddPrec package  </a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">reddPrec; Daily precipitation; Quality control; Missing values.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Generation of complete daily weather series (no gaps) for improved assessment of past climate in ICARIA case study areas and development of statistical downscaling.</code></td> </tr> </tbody> </table> |


#### S10. Description and validation of a two-step analogue/regression downscaling method
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Description and validation of a two-step analogue/regression downscaling method [ <a href="https://doi.org/10.1007/s00704-013-0836-x">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces a two-step analogue statistical downscaling method for daily temperature and precipitation, and accurately simulates the past climate on a local scale in the studying areas.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S10|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Surface observation Data (vector data) is combined with. ERA5-Land reanalysis datasets (raster data); Low resolution data are sourced from an observed reference dataset – ERA40 Reanalysis (atmospheric dataset). </li> <li>10 CMIP6 Global Climate Models + 4 Tier 1 SSP's.</li> <li>Local downscaled climate projections at point (observation) scale.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>FICLIMA two-step analogue/regression downscaling method. </li> <li>Estimates high-resolution surface meteorological fields for a day “x”, in two steps:<ul><li>The first step is an analogue technique better adapted and improved. </li><li>In the second step, high-resolution surface information is estimated differently for precipitation (using a probabilistic approach) and temperature (using multiple linear regression). </li></ul> </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Problems addressed in this recipe: (i) Changeable relationships between predictors and predictands (including non-linear ones), (ii) Predictors are simulated by the GCMs. </li> <li>Output: Simulation of precipitation and temperature (spatial distribution of verification metrics for the studied variables (max and min temperature and precipitation). </li> <li>Advantages: (i) Low computational cost, (ii) Microclimatic features are implicit, (iii) Good verification results (e.g., full range of data variability is considered). </li> <li>Limitations: (i) Historical observations of the variables are needed, (ii) Spatial and temporal inconsistencies cannot be eliminated, (iii) Non-stationary problem in the predictors-predictands relationships cannot be excluded, and (iv) Autumn precipitation in Mediterranean areas is poorly estimated. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="http://www.ecmwf.int/research/era/do/get/era-40">ERA40- Reanalysis </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Statistical downscaling; Mean absolute error; Analogue techniques. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands. </code></td> </tr> </tbody> </table> |


#### S11. Weather Data Quality Control | Weather data temporal extension methodology
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td>  <ul> <li>Weather Data Quality Control; Weather Observations Homogeneisation Techniques</li> <li>Weather data temporal extension methodology; Mainstream (traditional) gap filling methods [ <a href="https://cordis.europa.eu/project/id/700174">Link</a> ] </li> </ul> </td> </tr> <tr> <td>Summary</td> <td> These recipes offer techniques for data-gap filling in meteorological data.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S11|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Raw weather observations (A). </li> <li>Quality-treated weather observations (A).</li> <li>Weather data with the presence of data gaps not covering all the time desired (B).</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li><ul> (A) <li>A two-way quality control methodology is applied to all weather data sources prior to their use: (i) Basic consistency. Direct rejection of self-evident wrong values, and (ii) Atypical values or ‘outliers. Unusual values within a data set. </li> <li>The way to proceed with the homogeneity test is based on the following methodology (see ref. in "*References/Useful Links*" section): (i) To quantify the similarity between data across different years, a distribution comparison test based on the Kolmogorov-Smirnov (KS) test is used, (ii) The KS test is a non-parametric statistical test which provides a p-value that can be used as a measurement of the similarity between two years., (iii) The lower the value for Log (KS), the greater the probability of inhomogeneity between two consecutive values, (iv) If one year has been selected as a possible indicator of inhomogeneity, then it is subjected to another test (“*Similarity between years*”), and (v) If a jump or a break shows up between p-values in the selected years, there is a true inhomogeneity for all the series. </li> </ul></li> <li><ul>(B)<li>Depending on the circumstances the use of a temporally homogeneous weather dataset is mandatory.</li> <li>Temporal extension of the weather data is performed using a climate reanalysis, the ERA5-Land. </li> <li>Reanalysis is crossed with the weather observations.</li><li>Corrected simulated observation is crossed and filled with the original observation obtaining the original checked weather observation with gaps filled. </li><li>Voronoi polygons to determine the buildings supplied by the substations: (i) Substitution: the water distribution system layout was missing therefore the road layout was used instead assuming that the water network followed its layout, (ii) Logical rule-based reasoning: used for the burst locations (sewers overload), and (iii) Approach based on similar historical events previously within the city or in other areas with similar conditions is explored. </li></ul></li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Quality checking performed by FIC in ICARIA for all the weather data gathered (A).</li> <li>Homogenization techniques performed by FIC in ICARIA for all the weather data gathered (A). </li> <li>Data gap-filling for weather observations used by FIC in ICARIA (B). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul><li><a href="https://zenodo.org/records/6525733">Detection of inhomogeneities in daily data: a test based on the Kolmogorov-Smirnov goodness-of-fit test. </a></li><li>Relevant projects: RESCCUE D3.2. deliverable. Tools with updated impact assessment models (A, B). </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Weather observations; Kolmogorov-Smirnov test; Data gaps.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Creation and checking of extended weather observations for improved assessment of past climate in ICARIA case study areas and development of statistical downscaling.</code></td> </tr> </tbody> </table> |


#### S12. A three-dimensional gap filling method for large geophysical datasets: Application to global satellite soil moisture observations
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A three-dimensional gap filling method for large geophysical datasets: Application to global satellite soil moisture observations [ <a href="https://doi.org/10.1016/j.envsoft.2011.10.015">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents an efficient method for handling large spatio-temporal datasets introduced and applied to a global soil moisture product from remote sensing images. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-S12|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Works for large spatiotemporal datasets (both spatial & temporal variability). </li> <li>Global volumetric soil moisture product (satellite) with the Land Parameter Retrieval Model (LRM) (2003-2009). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A penalized least square method based on three-dimensional discrete cosine transforms (DCT-PLS), for the purpose of filling data gaps in large spatio-temporal datasets (for example: soil moisture satellite data) is introduced. </li> <li>This DCT-PLS method has some novel features with respect to other gap-filling methods. <ul> <li>It is a method of full three-dimensionality, and thus </li> <li>explicitly utilizes both spatial and temporal information of the dataset to derive the statistical model and </li> <li>Predict the missing values. Instinctively. </li> </ul></li> <li>This strategy is preferable for spatio-temporal datasets rather than using only spatial or temporal modelling. <li> The method utilized both spatial and temporal information of the moisture dataset. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>The statistical modelling process is completely controlled by one smoothing parameter which is easy to specify and eliminates the need for complicated model parameterizations. </li> <li>DCT-PLS provides estimation with small errors for the global moisture dataset and can be used to fill in missing values. </li>  </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="http://www.biomecardio.com/matlab/smoothn.html">BiomeCardio (Matlab package).  </a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Remote sensing; Soil moisture; Gap filling; Penalized least square regression; Discrete cosine transform.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving quality of heat and flood hazard assessment introducing soil moisture as key variable.</code></td> </tr> </tbody> </table> |


#### S13. Spatial interpolation techniques for climate data in the GAP region in Turkey
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Spatial interpolation techniques for climate data in the GAP region in Turkey [ <a href="https://doi.org/10.3354/cr028031">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe provides a benchmark for identifying the optimal methodology for interpolating the spatial distribution of a specified set of tested climate parameters through geostatistical interpolation techniques. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-S13|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Climate parameters: (i) Solar radiation, (ii) Sunshine duration, (iii) Temperature, (iv) Relative humidity, and (v) Wind speed and (vi) rainfall. </li> <li>Long-term yearly predicted temperature maps. </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Interpolation techniques: (1) Inverse distance weighted (IDW), (2) Global polynomial interpolation (GPI), (3) Local polynomial interpolation (LPI), (4) Completely regularized spline (CRI), (5) Cokriging, and (6) Kriging with four subtypes: (i) Ordinary kriging (KO), (ii) Simple kriging (KS), (iii) Universal kriging (KU), and (iv) Disjunctive kriging (KD). </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of long-term yearly predicted temperature in the studied area. </li> <li>Spatial interpolation techniques are utilized for distribution of climate parameters. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Spatial interpolation; Inverse distance weighted; Polynomial interpolation; Kriging; Cokriging; Completely regularized spline.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improved mapping of local climate change hazard conditions and of critical variables for exposure and vulnerability assessment through geostatistical interpolation techniques.</code></td> </tr> </tbody> </table> |

 
### Data-driven based methodologies

#### D1. A simple hybrid statistical–dynamical downscaling method for emulating regional climate models over Western Europe. Evaluation, application, and role of added value?
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A simple hybrid statistical–dynamical downscaling method for emulating regional climate models over Western Europe. Evaluation, application, and role of added value? [ <a href="https://doi.org/10.1007/s00382-022-06552-2">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes an emulation methodology which is based on a hybrid statistical-dynamical approach based on analogues to simulate regional climate models.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, and (ii) Precipitation Data. </li> <li>RCMs from Euro-CORDEX at 12km resolution. </li> <li>Scenario: RCP8.5. </li> <li>Regional simulations: (1) CNRM-CM5 GCM from CMIP5 downscaled using three regional simulations with the GCM/RCM mode and the RCM/RCM mode, (2) RCM/RCM mode to downscale from CMIP6, and (3) Historical and ssp5-8.5 simulations from the thirteen CMIP6 models. </li></ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>A hybrid statistical–dynamical downscaling method: (i) Statistical model based on the results of RCMs, (ii) Applied to downscale GCMs, (iii) Aims to emulate regional climate models, and (iv) It does not require the stationarity assumption of statistical downscaling.</li> <li>Emulate RCM results, based on the constructed analogues approach. </li> <li> Estimation method based on constructed analogues:  </li><li><ul> <li>Analogues of large-scale predictors from a low-resolution climate projection are considered: for high-resolution precipitation (temperature), the chosen predictor is low-resolution precipitation (temperature). </li> </ul></li> <li>Emulated models: (1) the GCM/RCM mode: "Fine-Scale Ref is a high-resolution regional climate simulation and Coarse-scale its driving GCM" (*sic*), and (2) the RCM/RCM mode: "*Coarse-Scale Ref is simply the Fine-Scale Ref simulation aggregated on the low-resolution grid of the model to be downscaled (Mod)*" (*sic*). </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Novelty: the analogues are searched within an RCM and therefore both in the past and the future climate. </li> <li>The hybrid method is shown to reproduce climate change signals very well and to outperform a conventional statistical downscaling method.</li> <li>"*Emulation methods make it possible to downscale very large ensembles of global climate projections and therefore to fully explore the uncertainties involved in regional climate changes*" (sic). </li> <li>"*In the RCM/RCM mode, the climate change signal at large scale of the original GCM is very well captured by the hybrid statistical downscaling method, independently of its magnitude*" (*sic*).</li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Euro-CORDEX regional climate projections: <a href="https://esgf.llnl.gov/">Earth System Grid Federation </a></li> <li>Constructed analogues method links:  <ul> <li><a href="https://doi.org/10.3402/tellusa.v46i3.15481">Searching for analogues, how long must we wait? </a> </li> <li><a href="https://doi.org/10.5194/hess-12-551-2008">Utility of daily vs. monthly large-scale climate data: an intercomparison of two statistical downscaling methods. </a> </li><li><a href="https://doi.org/10.5194/hess-14-1125-2010">The utility of daily large-scale climate data in the assessment of climate change impacts on daily streamflow in California. </a> </li><li><a href="https://doi.org/10.5194/hess-20-1483-2016">Hydrologic extremes – an intercomparison of multiple gridded statistical downscaling methods. </a> </li></ul> </li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">RCMs; Hybrid statistical dynamical downscaling; Climate change; Emulation. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Emulating the downscaling function of an RCM and improving resolution of climate change data.</code></td> </tr> </tbody> </table> |


#### D2. Dynamical and statistical downscaling of SSPs in AMB
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of SSPs in AMB [ <a href="https://arsinoe-project.eu/">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Dynamical and statistical downscaling methods are employed to combine SSPs and RCPs with land use cover temporal series data and obtain future projection scenarios.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Land use cover changes.</li> <li>Ease of change data.</li> <li>Qualitative and quantitative drivers.</li><li>Observed land uses for each time series.</li><li>Land use demands.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>iCLUE/CLUEMONDO model for future land use projections simulation.</li> <li>Dynamical Downscaling combining RCPs and SSPs scenarios.</li> <li>CORINE land use cover provides land use time series data (with satellite quality)  to feed the projection models.</li><li>SSPs provide a framework to integrate the future socioeconomic pathways in a RCP environment to approach a more realistic projection.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: Future land use projections with integrated information about the different socioeconomic and climatic scenarios adjusted to a more accurate downscaled geographical case study.</li> <li>In contrast with previous methodologies, this method provides a framework for the integration of socioeconomic scenarios to the simulation parameters.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <li>Relevant projects: <a href="https://arsinoe-project.eu/">ARSINOE, </a><a href="https://www.sciencedirect.com/science/article/pii/S004896971830439X?via%3Dihub">Huber García, V., Meyer, S., Kok, K., Verweij, P., and Ludwig, R. (2018). Deriving spatially explicit water uses from land use change modelling results in four river basins across Europe. Science of The Total Environment, 628-629, 1079-1097. https://doi.org/10.1016/j.scitotenv.2018.02.051. </a></li> <li><a href="https://www.idescat.cat/pub/?id=ep&lang=es">IDESCAT Population Data </a></li><li><a href="https://www.idescat.cat/indicadors/?id=aec&n=15336&lang=es">IDESCAT GDP (province and councils) </a></li><li><a href="https://centrodedescargas.cnig.es/CentroDescargas/index.jsp">IGN CORINE land cover (time series) </a></li><li><a href="https://land.copernicus.eu/en/products/corine-land-cover">CORINE land cover CORINE land cover (metadata) </a></li> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Socioeconomic projections (SSPs), Downscaling, RCPs, AMB, Land Use Cover, Climatic projections.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands.</code></td> </tr> </tbody> </table> |


#### D3. Dynamical and statistical downscaling of seasonal temperature forecasts in Europe: Added value for user applications
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of seasonal temperature forecasts in Europe: Added value for user applications [ <a href="https://doi.org/10.1016/j.cliser.2017.06.004">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents an intercomparison of dynamical and statistical downscaling methods for seasonal forecasting over Europe, based on a 15-member hindcast from the EC-EARTH global model, focusing on summer mean temperature. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D3|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>E-OBS. </li> <li><a href="https://ec-earth.org/">EC-EARTH</a>  (EUROPIAS project) - Global seasonal predictions.</li> <li>Regional CM used: RACMO2, WRF, RegCM. </li> <li>Raster data (gridded seasonal temperatures). </li> <li>Vegetation maps (from ECOCLIMAP for dynamical downscaling). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Dynamical downscaling: (1) RACMO2: hydrostatic model employing 40 hybrid coordinate full vertical levels. (2) Weather Research and Forecasting system: non-hydrostatic dynamic core, employing 30 full eta vertical levels, and (3) RegCM modelling system: hydrostatic, compressible, sigma-p, vertical coordinate model considering 18 sigma-p levels. </li> <li>Statistical downscaling: relying on coarse-resolution global simulated predictors: (1) Perfect prognosis (PP), and (2) Model Output Statistics (MOS); "*PP techniques can be applied on a daily, monthly or seasonal basis, whereas MOS techniques require working at monthly or seasonal time-scales*" (*sic*). </li> <li>PP-ANA is based on the popular analogue technique, which estimates the local downscaled values corresponding to a particular atmospheric configuration from the local observations corresponding to a set of similar (or analog) atmospheric configurations within a historical catalog formed by reanalysis. </li> <li>PP-MLR is an extension of simple linear regression which attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. The fit is determined by minimizing the sum of the residuals between the regression line and the observed data. </li><li>Dynamical downscaling is based on regional models, which run on a relatively fine grid (e.g., 10–20 km) over a limited domain (e.g., Europe) initialized and driven at the boundaries by the coarse global model outputs. </li><li>These models can generate regional predictions for a suite of climate variables but still may suffer from significant biases which require post-processing with bias adjustment techniques before they can be used in impact applications. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of dynamical downscaling products for representation of the mean and extreme values.</li> <li>Statistical downscaling methods typically show minimal biases and provide realistic climate information (from the mean to the extremes) when compared to global models. </li> <li>Regional information still plays a significant role in specific sector climate indices and impact models. </li> <li>ROC Skill score was used as a measure of the accuracy of the probabilistic forecasts, providing maps where both dynamical and statistical downscaling methods were included; Both downscaling methods resulted in similar patterns showing low-to-moderate skill over most continent. </li><li>Used on energy performance case studies. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li>Relevant projects: (i) <a href="http://www.specs-fp7.eu/">SPECS</a>, and (ii) <a href="http://www.euporias.eu/">EUROPIAS</a></li> <li><a href="https://edepot.wur.nl/312260">Refinement and application of a regional atmospheric model for climate scenario calculations of Western Europe. </a></li> <li><a href="http://dx.doi.org/10.5065/D68S4MVH">A Description of the Advanced Research WRF Version 3 – Technical report.</a></li> <li><a href="http://dx.doi.org/10.3354/cr01018">RegCM4: model description and preliminary tests over multiple CORDEX domains. </a></li> <li><a href="http://dx.doi.org/10.1029/2012JD017650">Comparison of dynamically and statistically downscaled seasonal climate forecasts for the cold season over the United States. </a></li> <li><a href="http://dx.doi.org/10.1016/j.jcp.2006.10.024">Regional climate modelling. </a></li></ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Dynamical downscaling; Statistical downscaling; Seasonal forecasting; Multiple linear regression; Precipitation; Heatwaves. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving resolution of climate change data, in particular for assessing seasonal energy needs.</code></td> </tr> </tbody> </table> |


#### D4. Dynamical and statistical downscaling of a global seasonal hindcast in eastern Africa
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Dynamical and statistical downscaling of a global seasonal hindcast in eastern Africa [ <a href="https://doi.org/10.1016/j.cliser.2017.11.003">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Dynamical and statistical downscaling methods are combined to access seasonal forecast for impact modelling.   </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-D4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li><a href="https://ec-earth.org/f">EC-Earth</a></li> <li>Datasets: (1) Climate research unit time-series, (2) Global precipitation climatology center, (3) Tropical applications of meteorology, (4) African rainfall climatology, (5) African estimation algorithm, (7) Climate hazards group InfraRed precipitation stations, and (8) WATCH-forcing-Datra-ERA-Interim. </li><li>Regional CM used: CCLM4-8-21 (CCLM4), RCA4 (RCA4), RegCM-4-3 (RegCM4), WRF341I (WRF341), WRF381D (WRF381) </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>(1) Downscale ECMWF system-4 seasonal hindcasts, (2) RCMs: a domain of configurations has been selected, (3) Empirical statistical downscaling:  Two (2) ESD methods were selected to downscale the full stream of the EC-EARTH hindcast: (i) AN1: variation of the Analogue technique, and (ii) A variation of the generalized Linear Models (GLMs), (4) Selection of the subregions was based on a group of the initial datasets to the LEAP platform, and (5) Rainfall indexes were considered to evaluate seasonal forecasts: (i) the Simple Daily Intensity Index (SDII), and (ii) the Wet Day Frequency (WDF). </li> <li>Verification metrics: (i) Interannual correlation, (ii) Brier skill score, and (iv) ROC Skill Score: ROCCS maps for the EC-EARTH hindercasted rainfall provide allow to detect observational uncertainties.</li> <li>Dynamical Downscaling using RCMs is computationally expensive delaying the provision of the forecasts and requires much more resources than ESD (e.g., saving a wealth of driving boundary conditions from GCMs). </li> <li>LEAP platform offers information about humanitarian needs and interventions. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) Interannual correlation maps and maps of the global and downscaled hindcasts, (ii) ROCCS maps for the global and downscaled hindcast rainfall, (iii) Maps of rainfall tercile forecast for each model, (iv) Verification data for the rainfall indices (via maps of distribution of the ROCCSS for the global and downscaled rainfall forecasts). </li> <li>In contrast to the ESD approach, RCMs can provide a larger number of variables in a physically consistent way, including regional and local feedback which can be important in seasonal forecasting. </li> <li>Main results: (i) Observational uncertainties, (ii) A global forecast system, (ii) Both dynamical and statistical downscaling, (iv) Applicability of rainfall indexes and (v) The capabilities of an early warning system (LEAP platform). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li>Relevant projects: <a href="http://www.euporias.eu/">EUROPIAS</a></li> <li><a href="https://github.com/SantanderMetGroup/downscaleR">Link downscaleR package – GitHub repository </a></li> <li><a href="http://dx.doi.org/10.1175/JCLI-D-11-00441.1">Can a Regional Climate Model Improve the Ability to Forecast the North American Monsoon?</a></li> <li><a href="http://dx.doi.org/10.1029/2011JD016997">Dynamical downscaling of ECMWF Ensemble seasonal forecasts over East Africa with RegCM3. </a></li> <li><a href="https://doi.org/10.1111/j.1600-0870.2011.00523.x">Downscaling ECMWF seasonal precipitation forecasts in Europe using the RCA model. </a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Seasonal forecast; Downscaling; Drought early-warning system; RCMs; Precipitation; Dynamic downscaling; Generic. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Already considered and applied for ICARIA project's demands. </code></td> </tr> </tbody> </table> | 

### Data-driven based methodologies

#### DD1. Developing novel machine-learning-based fire weather indices
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Developing novel machine-learning-based fire weather indices [ <a href="https://doi.org/10.1088/2632-2153/acc008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces a data-driven fire weather index that outperforms current traditional fire indexes (which often fall short due to the non-linear nature of wildfire risk factors) and provides accurate wildfire risk estimations which are key for optimal forest management and firefighting. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Global wildfire datasets.</li> <li>Variables: (1) daily ignition, (2) 2m temperature, (3) humidity, (4) 10m wind speed, (5) precipitation, (6) mean slope, (7) population density, (8) NDVI, and (9) Incoming short-wave solar radiation.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Models would benefit if could include: (i) including meteorological factors, (ii) topography, (iii) fuel loads, (iv) anthropogenic factors, (v) include 2-meter temperature, (vi) precipitation, (vii) RH, (viii) 10-meter wind velocity, based on the ERA5 hourly reanalysis data, and (ix) population density.</li> <li>Fourteen (1$) indexes are used for comparison, grouped in three (3) categories as following: : (1) Canadian Forest Service Fire Weather Index Rating System, (2) Australian McArthur Mark 5 Rating System, (3) U.S. Forest Service National Fire-Danger Rating System. </li> <li>The variables in each category include: (1a) fire weather index, (1b) build up index, (1c) danger index, (1d) drought code, (1e) duff moisture code, (1f) initial fire spread index, (1g) fine fuel moisture code, (1h) fire daily severity rating. (2a) Keetch-Byram drought index, and (2b) fire danger index. (3a) spread component, (3b) energy release component, (3c) burning index, and (3d) ignition component. These variables were available in a 0.25◦ resolution from the Copernicus Climate Change Service (Fire Danger Indices Historical Data from the Copernicus Emergency Management Service).</li> <li>Metrics: (1) Under the curve metric (AUC), (2) Operating characteristics curve (ROC), and (3) Precision-Recall Curve.</li> <li>Classification models: (1) RF, (2) Extreme Gradient Boosting (XGBoost), (3) MLP, a form of Neural Network and (iv) logistic regression.</li> <li>Method to study the actors in terms of wildfire risk: SHAP (SHapley Additive exPlanations) values analysis.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>XGBoost model achieved the highest score based on the ROC-AU curves.</li> <li>Traditional indices and subindices: the Duff Moisture Code and the Keetch-Byram Drought Index achieved the highest performance.</li> <li>ROXC curves for wildfire ignition prediction for the ML models are provided.</li> <li>Prediction accuracy maps for all ML-based index methods are provided, for the studied variables.</li> <li>Maps of the two-day dependence plots for wildfire occurrence are provided.</li> <li>Global maps of wildfire occurrence for all ML-based index methods  are provided.</li> <li> Temperature was estimated as the key feature for the prediction of wildfire occurrences. </li> <li> ML-based FWIs are able to provide wildfire occurrence estimation in a daily resolution in all regions worldwide.  </li> </ul> </code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2"> Machine learning, fire weather indices, forest management, wildfire risk. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> A methodology combining data-driven methodologies and fire weather indices. </code></td> </tr> </tbody> </table> |


#### DD2. PVS-GEN: Systematic Approach for Universal Synthetic Data Generation Involving Parameterization, Verification, and Segmentation
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> PVS-GEN: Systematic Approach for Universal Synthetic Data Generation Involving Parameterization, Verification, and Segmentation [ <a href="https://doi.org/10.3390/s24010266">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a new method that parameterizes empirical time-series data with minimal intervention. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-2
|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Empirical data and synthetic data from general-purpose time-series data of any type. </li> <li>Datasets: (i) Gas sensor array dataset, (ii) Low-Energy house dataset, (iii) EEG Alcoholism dataset, and (iv) Heterogeneity activity recognition dataset. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Process: (i) Parameterization: utilize empirical data with ACRIMA to derive automated parameters, (ii) Verification: compare the synthetic data with the empirical data using our proposed metric, the possibility of reproducibility (RoR), and (iii) Segmentation for universal synthetic data generation: enhance the time-series consistency and regularity. </li> <li>Statistical models: (i) SES, (ii) ARIMA, and (iii) GMM. </li> <li>Data-driven methods: (i) SVR, and (ii) LSTM. Other alternatives: (i) GANs, (ii) VAEs, and (iii) RNNs. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Reduced user intervention and reduced resources for acquiring and labeling large amounts of empirical data. </li> <li>A universal methodology could benefit having the following characteristics: (i) Automatic generation of time-series data for a range of sensors and data process, (ii) Parametrization of empirical data, (iii) Independent of sensor data traits, (iv) Encapsulation of the temporal dynamics of time-series data, (v) Enabling quantitative comparisons between generated and empirical data by reflecting the time-series characteristics of the data with their descriptive statistics, and (vi) Scalability. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time-series sensor data; synthetic data generation; time-series synthesis; IoT data generation; possibility of reproducibility.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Multi-purpose data generation system based on the processing of empirical data and time series. </code></td> </tr> </tbody> </table> |


#### DD3. A single-building damage detection model based on multi-feature fusion: A case study in Yangbi
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A single-building damage detection model based on multi-feature fusion: A case study in Yangbi [ <a href="https://www.sciencedirect.com/science/article/pii/S2589004223026639">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a multi-fusion feature model for accurate identification and classification of building damage detection to reduce information redundancy applied to earthquake events for demonstration.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-3|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Binary map of buildings, (ii) Outlines of buildings, (iii) Satellite DOM image, (iv) UAV DOM and DSM image, and (v) Google Maps-based satellite images. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Data from satellites and UAVs are obtained for damage building detection after a hazard event (earthquake). </li> <li>An image change detection model is applied. </li> <li>Methodology: (i) nDSM: extracts building contours, (ii) image segmentation: K-nearest neighbor was used for classification of the study area using spectral average grayscale value, rectangularity features, (iii) morphological closure operation: results of building contour extraction, (iv) segmentation of buildings, (vi) classification of damage types of buildings, and (vii) texture feature change analysis, image fusion, and PCA. </li> <li> Statistical analysis: (i) Maximum Likelihood Classification (ML), (ii) Neural Net Classification (NN), (iii) Mahalanobis Distance Classification (MD), and (iv) Support Vector Machine Classification (SVM) machine learning models were applied.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Output: (i) Maps of damaged buildings, (ii) Post-and pre-hazard UAV and satellite images, (iii) Maps of extraction and distribution results of damaged buildings </li> <li>Limitations: (i) Model should be able to process data from diverse resources, (ii) A larger input of damaged buildings should be considered, and (iii) The procedure of extraction and selection should be automated for optimization. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Multi-feature fusion; Damage detection model; Earthquake; Normalized Digital Surface Model (nDSM); Buildings; Structural Damage; Building impact assessment. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability analysis.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Exposure and vulnerability analysis for single buildings, with a focus on structural damage, based on seismic impact assessment, potentially transferable to other hazards. </code></td> </tr> </tbody> </table> |



#### DD4. Assessing automated gap imputation of regional scale groundwater level data sets with typical gap patterns
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Assessing automated gap imputation of regional scale groundwater level data sets with typical gap patterns [ <a href="https://doi.org/10.1016/j.jhydrol.2023.129424">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces and compares two data imputation methodologies to simulate complex missing value patterns by mimicking typical gap patterns, tested for reproducing daily groundwater hydrographs.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Regional scale groundwater level data sets: (i) Rechange, (ii) Groundwater-surface, and (iii) Water interaction. </li> <li>Mimicking of: (i) Typical gap patterns, and (ii) Random gap patterns. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Linear Interpolation. </li> <li>MissForest: (i) Non-parametric, (ii) Iterative, (iii) Missing values imputation, (iv) Random Forest algorithm, (v) Automatic, (vi) Unsupervised missing imputations, (vii) No assumptions about data distribution, (viii) No need for tuning parameters, and (ix) Performs for the infilling daily groundwater hydrographs. </li> <li>ImputePCA: (i) Multiple imputation method, (ii) Principal components method on an incomplete dataset, and (iii) Performs iteratively principal component analysis (PCA). Convergence: when the difference between two successive iterations is below a defined threshold. </li> <li>Artificial gaps: (i) Typical gap patterns: (ii) Eleven (11) distinct groups of gaps in groundwater hydrographs were performed, and (ii) Artificial gaps of time series were simulated. (ii) Random gap patterns: Artificial gaps were introduced in 109 hydrographs. </li> <li>Imputations performance: I) imputePCA performed less accurately with more dispersed results, (ii) Typical gap patterns were demanding for all imputation algorithms, (iii) missForest outperformed both the imputePCA and the linear interpolation algorithms, and (iv) All infilled hydrographs performed poorly when imputing typical gap patterns. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Impact of individual gaps: (i) All methods performed poorly in estimating long continuous gaps, (ii) The accuracy of the infilling in the beginning and at the end of the hydrographs performed poorly when compared to the rest of the gaps.</li> <li>Estimation of changes in the number of daily hydrographs. </li> <li>Extreme hydrographs remain challenging to address. </li> <li>Gap-filling methods fail around gaps that contain extremes.</li> <li>Random-like gap patterns are linked with more simple imputation methods in terms of performance and accuracy.</li> <li>Typical gap patterns do not offer a consistent performance on imputation, despite the gap characteristics. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code>  <ul> <li><a href="https://eu-waterres.eu/">WATERRES: EU-integrated management system of cross-border groundwater resources and anthropogenic hazards. </a> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time series; Missing values; Gap filling; Droughts; Abstraction. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> This recipe offers alternative methodologies for data imputation. </code></td> </tr> </tbody> </table> |


#### DD5. From theory to practice: optimization of available information for landslide hazard assessment in Rome relying on official, fragmented data sources
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> From theory to practice: optimization of available information for landslide hazard assessment in Rome relying on official, fragmented data sources [ <a href="https://doi.org/10.1007/s10346-023-02095-7">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-5|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>List of geological hazards. </li> <li>Datasets for known landslides.</li> <li>Prediction of landslide susceptibility.</li> <li>Point-based landslide database is represented by: (i) 1099 LIPs (289 original and 810 synthetic), and (ii) The 67 related to the January 2014 extreme rainfalls are excluded. </li> <li>Continuous map(s) of landslide initiation susceptibility based on data-driven model(s). </li> <li>Detection rate curves for the classification of the susceptibility. </li> <li> Spatial density maps of shallow landslides and earth slides.  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Objectives: (i) Dataset preparation, (ii) Susceptibility assessment, and (iii) Information about landslides. </li> <li>Evaluation of intensity and temporal probability of landslides.</li> <li>Definition of rainfall-induced landslide hazard: (i) Definition of the spatial component of the landslide hazard, (ii) Temporal component of the landslide hazard, (iii) Preliminary and large-scale quantitative hazard description, and (iv) Evaluation of the return periods of landslide trigger rainfall events.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Outputs: (i) A uniform, updated database is composed, (ii) The spatial component of the hazard is depicted by (a) Continuous maps of landslide initiation, and detection rate curves, (b) Classification of landslide susceptibility, (iii) The temporal component of the hazard is depicted by (a) Resulting landslide frequency estimation, and (b) Rainfall probability curves for the tested areas, and (iv) Persistent scatterer interferometry: (a) A-DInSAR velocity maps, and (b) Susceptibility hazard index maps for the tested areas. </li> <li>GIS- and ML-based methods were applied to collect and integrate open-source landslide inventories into a database. </li> <li>The reported products aid decision-makers in managing landslide risks by reporting activity status and susceptibility, supporting informed monitoring and investment prioritization for prevention and mitigation.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="http://sgi2.isprambiente.it/franeroma/">Known landsides </a></li> <li><a href="https://geoportale.regione.lazio.it/">Open access land use maps </a></li> <li><a href="https://www.autoritadistrettoac.it/planning/hydrographic-basin-planning/documentation-of-the-tiber-basin-plan">Hydro-geological Structure Plan</a></li> <li><a href="http://www.urbanistica.comune.roma.it/prg-2008-vigente/">Municipal land use plan </a></li> <li><a href="https://www.comune.roma.it/web-resources/cms/documents/Fasc3_RischioFrane_2021.pdf">Civil protection plans</a></li> <li><a href="https://idrogeo.isprambiente.it/app/">IDROGEO Platform</a></li> </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Susceptibility; Machine learning; Rainfall probability; Landside hazards; Landside inventories; Interferometry. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data. </td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Landslide hazard assessment in relation to rainfall intensity, supporting dynamic analysis of landslide risk depending on seasonal changes in rainfall patterns and extreme events frequency/intensity. </code></td> </tr> </tbody> </table> |


#### DD6. Modelling national residential building exposure to flooding hazards
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Modelling national residential building exposure to flooding hazards [ <a href="https://doi.org/10.1016/j.ijdrr.2023.103826">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a model for flood risk assessment by studying the building characteristics for object-level replacement evaluation in flooded areas utilizing public data, and data-driven methodologies for the estimation of the hazard area exposure.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-6|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Variables: (i) Location (e.g., Address count and units, etc.), (ii) Geometric and non-geometric characteristics (e.g., Floor area, and height, Building count, Land area, etc.). </li> <li>Integration of public data and geospatial physical/non-physical building characteristics.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Workflow to estimate physical and non-physical characteristics for object-level replacement valuation using (i) spatial data, (ii) geometric data, and (iii) data-driven methods.</li> <li>Geometry building properties were estimated based on geospatial operations and open topographic data. </li> <li>Building height (BHT) extraction and level (BL) enumeration were performed using a geospatial model and LIDAR point clouds. </li> <li> Data-driven methods as tree-ensemble models for value imputation (supervised learning regression and classification algorithms): (i) Random Forest, and (ii) XGBOOST.  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Estimation of residential building characteristics and replacement values. </li> <li>Output: (i) Regional residential building and replacement value exposure, (ii) RF demonstrates higher overall performance compared to XGBOOST, and (iii) Object-level information for exposure in risk assessments can be critical at regional to national scales. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li>Geospatial datasets: (i) NZ building outlines (ii) NZ primary land parcels, (iii) LIDAR point clouds, (iv) NZ functional urban areas, (v) RiskScape software, (vi) CostBuilder. </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Floods; Residential buildings; Exposure; Monetary values; Supervised learning; Object-level modelling. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Flood hazard exposure and vulnerability analysis of buildings. </code></td> </tr> </tbody> </table> |


#### DD7. Deep Learning Regional Climate Model Emulators: A Comparison of Two Downscaling Training Frameworks
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Deep Learning Regional Climate Model Emulators: A Comparison of Two Downscaling Training Frameworks [ <a href="https://doi.org/10.1029/2022MS003593">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes a methodology where it explores the potential of using data-driven methodologies alternatively to dynamical downscaling, applied to a global climate model (GCM) to regional resolution. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-7|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Precipitation, (ii) Downward radiation, (iii) Humidity, (iv) Temperature, and (iv) Pressure. </li> <li>RCM target domain: box of 64 x 64 pixels. </li> <li>RCM (from MAR(ACCESS1.3)), GCM(CMIP5). </li> <li>Input features to RCM: 1D (e.g., Seasonal indicators, Spatial mead of 2D variables, etc.), and 2D (e.g., Wind, Downward radiation, Humidity, etc.). </li> <li>Climate variables: precipitation, temperature, etc…  </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Two Surface mass balance (SMB) emulators, a perfect and an imperfect one, were chosen to downscale a GCM. </li> <li>Two ML models were applied to SMB to examine the downscaling potential: U-Net model.</li> <li>U-Net (CBAM (Convolution block attention) combined with depth wise-separable convolutions (DSC)), Smart-UNet. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Maps of SMB predictors of the RCM emulators over a test period.</li> <li>Maps of evaluation metrics on predictions from the RCM emulators over a test period. </li> <li>Output: (i) Perfect model fails to reproduce SMB's extreme values, (ii) Both perfect and imperfect models succeed in reproducing complex spatial structure of the RCMs, and (iii) Inconsistencies due to the difference in resolution between large-scale and local-scale variables are not negligible and might confuse the RCM-emulator. </li> <li>Limitations: (i) Temporal and spatial inconsistencies might occur if an offset is present in the RCM time series, (ii) Inconsistencies between RCM and GCM variables remain present, (iii) The typical limitations of machine learning methods are also applicable in this context. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://esgf.nci.org.au/search/esgf-nci/">ACCESS 1.3 GCM data.</a></li> <li><a href="https://github.com/marvande/RCM-Emulator">Historical and future RCP8.5 simulations – GitHub repository.</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">DL; RCMs; GCMs; Downscaling; Deep Learning RCM-emulator; Dynamic Downscaling of GCMs; Surface Mass Balance (SMB).  </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Emulating RCM downscaling to improve resolution of climate change data in case study areas.</code></td> </tr> </tbody> </table> |


#### DD8. Self-supervised learning for climate downscaling
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Self-supervised learning for climate downscaling [ <a href="https://doi.org/10.1109/BigComp57234.2023.00012">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe offers a self-supervised deep-learning solution for climate downscaling that can be applied without requiring high-resolution ground truth data.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-8|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Low-Resolution Climate data: Synthetic LR data can also be created by degrading real High-Resolution data. </li> <li>Climate variables: (i) The surface temperature, (ii) total precipitation, and (iii) topographical gradient.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Community Earth System Model (CESM): Fully coupled global climate model. Capabilities of neural networks to reconstruct high-resolution data from given low-resolution simulations.</li> <li>Legacy low-resolution simulations can be downscaled to reconstruct high-resolution detail. </li> <li>Past observations that have been taken at lower resolutions can be increased to higher resolutions, opening new analysis possibilities.</li> <li>Networks: (i) Low-Frequent Data: Residual-Predicting Network (RPN), and (ii) High-Frequent Data: Deconvolutional Network (DCN). </li><li>Downscaling is performed over the surface temperature and the topographic gradient. </li><li>Deep-learning methodologies: CNN method (each model trained for 500 epochs, using Adam optimizer and LeakyReLU).</li><li>Characteristics: (i) Self-supervised deep-learning solution for climate downscaling, (ii) No high-resolution ground data input required, (iii) CNN models train on a single instance at a time, and (iv) Improvement of downscaling performance. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>The method is compared to self-supervised models (SSL~SRResNet~, and SSL~GINE~). The two SSLs have also been used as training components on the pseudo-LR and HR data. </li> <li>The method is capable of estimating HR climate data without ground truth data. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://github.com/k-s-b/ssl_climate">Repository for the work titled "Self-supervised learning for climate downscaling" - GitHub repository</a>. Data for this recipe: <a href="Ultra-high-resolution climate simulation project.">https://climatedata.ibs.re.kr/data/cesm-hires</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Climate downscaling; self-supervised; Deep Learning; CNNs; Super-resolution; Earth system models; Climate Simulation.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improving resolution of climate data.  </code></td> </tr> </tbody> </table> |


#### DD9. An Exploration of Interpolation - Machine Learning Model for Climate Model Downscaling Under the Limitation of Data Quantity
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> An Exploration of Interpolation - Machine Learning Model for Climate Model Downscaling Under the Limitation of Data Quantity47. [ Link ] 2023  [ <a href="https://doi.org/10.1109/ITC-CSCC58803.2023.10212662">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe describes a methodology to perform downscaling and address any data-gap issues introduced, by combining interpolation and data-driven methodologies.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-9|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>LR climate data (IPSL-CM6A-LR in CMIP6 with 250 km of spatial resolution are selected as the GCM output). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>IDW (Inverse Distance Weight).</li> <li>TIN (Triangular Interpolation Network).</li> <li>ANNs (Artificial Neural Networks). </li> <li>GBRT (Gradient Boosting Regression). </li> <li>GLM (Generalized Linear Model).</li> <li>SVP (Support Vector Machine). </li> <li>HSVR (Hybrid Support Vector Regression). </li> <li>Combinations: (i) IDW-ANN, (ii) IDW-GBRT, (iii) TIN-ANN, and (iv) TIN-GBRT. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>*"The combination of IDW-ANN becomes the proper method for downscaling the climate model output for both temperature and precipitation under the limitation of data quality"* (*sic*). </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Interpolation; ML; Climate model downscaling; Data gaps; GCMs; Deep learning. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change Hazard data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Climate model downscaling through interpolation of existing data.</code></td> </tr> </tbody> </table> |


#### DD10. A ‘Total’ Imputation Algorithm that Fills Gaps in Time Series Measurements for ADEV and Phase Noise Characterizations of Power-law Noise Models
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A ‘Total’ Imputation Algorithm that Fills Gaps in Time Series Measurements for ADEV and Phase Noise Characterizations of Power-law Noise Models [ <a href="https://doi.org/10.1109/EFTF/IFCS54560.2022.9850921">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe introduces an imputation algorithm for data gaps occurring in live measurements, by extending a T-length data run and enhancing long-term ADEV(τ) estimation, consistently recovering gaps across various power-law noise models.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-DD-10|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>NIST H-maser time series measurements: (I) Clock, and (ii) oscillator phase measurements. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>The Total imputer is an effective method yet devised in filling data gaps for: (i) computations of ADEV (Allan Deviation), and (ii) phase noise levels over the fullest possible range of τ-values and Fourier-frequencies.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Total imputation algorithm. </li> <li>Equally spaced time-series data without gaps. </li> <li>Treatment of large gaps. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code><ul> <li> <a href="https://github.com/nkschlos/time-series-imputation">Time-series-imputation package. </a> </li> <li> <a href="https://zenodo.org/records/5595200">Executable for Gap-filling Script for Noisy Time Series – Zenodo.</a> </li> <li> <a href="https://zenodo.org/records/5594587">Gap-filling Script for Noisy Time Series - Zenodo. </a> </li> <li> <a href="https://ieeexplore.ieee.org/document/9658567	">Characterizing Frequency Stability Measurements Having Multiple Data Gaps.</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Time series; Noise model; Imputation Algorithm; Allan Deviation; Data models; Large data gaps. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Integration of missing modelling variables, applicable to any kind of data gap.</code></td> </tr> </tbody> </table> |


#### DD11. A data filling methodology for time series based on CNN and (Bi)LSTM neural networks
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A data filling methodology for time series based on CNN and (Bi)LSTM neural networks [ <a href="https://doi.org/10.48550/arXiv.2204.09994">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe develops a method combining deep Learning models such as CNNs, LSTMs, and BiLSTMs to fill data gaps in internal temperature time series from monitored apartments, using both pre- and post-gap data, correlated external temperature data, the method accurately reconstructs the target time series, outperforming baseline deep-learning architectures.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-DD-11|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Data from monitored apartments. </li> <li>Data from sensors for moisture, humidity, temperature, C02 concentration. energy consumption. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>CNNs, LSTMs and BiLSTMs. </li> <li>CNN-LSTM (256, 128 and 64 neurons). </li>  <li>CNN-BiLSTM (32, and 16 neurons). </li> <li>Use both networks in pre- and post-gap data. </li></ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Time-series reconstruction.</li> <li>CNN-BiLSTM is the most promising model.</li> <li>CNN-BiLSTM has the best-performing approximation of the time series.</li> <li>CNN-LSTM model performs better in generalizing its predictions. </li> <li>CNN-BiLSTM and CNN-LSTM models show a promising ability to generalize to unseen data. </li> <li>Both models outperform purely LSTM networks. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://doi.org/10.3389/fmars.2021.637759">Feedforward and LSTM Neural Networks, Gap filling. </a> </li> <li> <a href="https://doi.org/10.1142/S0129065721300011">Deep learning and time series forecasting, Review paper.</a> </li>  <li> <a href="http://www.sinfonia-smartcities.eu/">SINFONIA Project. </a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Neural Networks; Data filling; Time series; Sensor data; Deep learning; High-resolution heat wave; Hazard asssessment.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Improvement of heat wave hazard characterization in urban areas based on existing monitoring devices in buildings, understanding effect of air temperature variation and urban heat island on indoor comfort, as a proxy of thermal capacity of building envelope and HVAC systems efficiency.</code></td> </tr> </tbody> </table> |


#### DD12.  Increasing the detail of European land use/cover data by combining heterogeneous data sets
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Increasing the detail of European land use/cover data by combining heterogeneous data sets [ <a href="https://www.tandfonline.com/doi/full/10.1080/17538947.2018.1550119">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents methods to improve the spatial resolution of land cover and land use data through the combination of different datasets available through Copernicus Land Monitoring System. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-12|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>European Settlement Map</li> <li>Corine Land Cover</li> <li>Copernicus High Resolution Layers</li> <li>Urban Atlas</li> <li>TomTom Multinet Polygons</li> <li>OpenStreetMap</li> <li>Local Sub-National Land use data</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Spatial refinement based on the cartographic synthesis of categorical raster data, interval raster data, and vector polygon data. </li> <li>Data fusion performed using an automated chain of raster-based map algebra operations on a set of raw or pre-processed datasets. </li> <li>Input vector data rasterised to the target 100m resolution beforehand, using the maximum combined area method to identify the dominant class in each cell. </li> <li>At each step of the sequence, the cells either remain unchanged or are updated by the overlaid input data layer, following pre-established decision rules.</li> <li> Random forest classification as machine-learning technique to predict land use classes using the derived predictor variables. </li> </ul></code></td>  </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Urban fabric classification by use.</li> <li>Vegetation classification.</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li><a href="https://human-settlement.emergency.copernicus.eu/enact.php">ENACT project</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Data fusion; Land use; Land cover; Machine learning; Points of interest</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Case study tailored improvement of exposure and vulnerability information based on open datasets.</code></td> </tr> </tbody> </table> |


#### DD13. Power Network Component Vulnerability Analysis: A Machine Learning Approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Power Network Component Vulnerability Analysis: A Machine Learning Approach [ <a href="https://doi.org/10.1016/j.procs.2021.05.008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe suggests using data-driven methodologies on publicly available large-scale data to gauge power network vulnerability, elevate grid stability, minimize failure risks, and boost resilience for smart grids.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-DD-13|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>State of components after an extreme event: (i) non-operational (outage), (ii) operational (in service). </li> <li>Network components: (i) power plants, (ii) transmission lines, (iii) substations.</li> <li>Extreme hazard(s): historic disruptive events data as input. Data sourced from the NOAA website. </li> <li>Variables: (i) operation capacity, (ii) total number of lines, (iii) risk factor(s), (iv) vulnerability index, and (v) disruption distance. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Data-driven methodologies: Supervised learning model: Support Vector Machines (SVMs): (i) 3216 components for training the model, (ii) 1345 operational components under thunderstorms winds, and (iii) 1309 operational components under tornadoes. Kernels: (i) linear, (ii) gaussian, (iii) polynomial, and (iv) sigmoid. </li> <li>Calculation of the vulnerability index.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Investigation of critical components under disruptions in a network.</li> <li>Consideration of an extreme event. </li> <li>Maps of in-service or outrage components. </li> <li>Output for: (i) the evaluation of the network stability, (ii) the understanding of the risk of cascade failure, and (iii) the improvement of the resilience of the overall network. </li></ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Power network resilience; Vulnerability analysis; Machine learning; Predictive analytics; Extreme events.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Enhance the predictability of resilience methodologies for power networks.</code></td> </tr> </tbody> </table> |


### Expert elicitation methods

#### EE1. ELICIPY 1.0: A Python online tool for expert elicitation
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> ELICIPY 1.0: A Python online tool for expert elicitation [ <a href="https://www.sciencedirect.com/science/article/pii/S2352711024000128">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Python tool to perform expert elicitation sessions through a framework that covers both the questionnaire collection and the analysis parts. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-EE-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input through webforms (question label and extended text for in multiple languages; units of the expected answer; scale - uniform or logarithmic; range of admissible values for the elicited percentiles; question type - “seed” or “target”.</li> <li>Experts’ weight.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Cooke Classical method. </li> <li>Expected Relative Frequency method.</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Experts’ weights with different weighting schemes. </li> <li>Itemwise graphs for seed questions (including the text of the Itemwise graphs for target questions (including the text of the questions), together with a simplified probability density function and cumulative distribution plots of the DM. </li> <li>Percentiles of target questions. </li> <li	> Optional graphs where multiple target questions could be visualized along with their percentiles. </li> <li> Probability density functions and barplots for target questions, along with the percentile values for the used weighting schemes. </li> <li> Probability density functions for each questions and subgroups.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://zenodo.org/records/8192353">ELICIPY 1.0 Github</a> </li>  </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


#### EE2. Using expert elicitation to strengthen future regional climate information for climate services
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Using expert elicitation to strengthen future regional climate information for climate services [ <a href="https://doi.org/10.1016/j.cliser.2021.100278">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe explores the use of structured expert elicitation to access uncertainties for future climate changes as an extension to the results of climate model simulations.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EE-2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, and (ii) Precipitation. </li> <li>CMIP5 analysis: (i) Historical data from 1975-2005, (ii) Calculated periods: 2040s and 2080s, and (iii) RCPs: RCP2.6, 4.5, 6.0 and 8.5. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Climate model outputs from CMIP5. </li> <li>Structured expert elucidation:  <ul> <li> Use of structured expert elicitation (SEE) for regional climate change.  </li> <li> Expert elicitation judgment (individually or in a group): (a) Provides additional information and knowledge that is absent from modelling approaches, and (b) Builds a framework for discussion between climate experts and regional stakeholders.  </li> <li> Snowball sampling is considered.  </li> <li> Estimates of future temperature and precipitation change are provided. </li> <li> Sources of uncertainty in estimating long-term climate changes: rank sources based on their overall contribution. </li> <li> Considering all possible GHG concentration scenarios. </li>  </ul> </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Narrower uncertainty ranges for deviations in both temperature and precipitation. </li> <li>Framework for supporting adaptation decisions. </li> <li>"*Practices are shaped by local epistemic, institutional and political cultures*" (*sic*).</li> <li> "*SEE used alongside modelling approaches, can contribute to a richer understanding of regional climate knowledge for use in climate services*" (*sic*)  </li> <li> "*Elicitation methods should be considered within the ‘toolbox’ of approaches available to climate service providers*" (*sic*)  </li>  </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Knowledge quality assessment; Climate change adaptation; Yangtze; China; Assessing Climate Uncertainties; Expert elicitation.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Adapt the methodology to assess probability of compound events and cascading effects in selected case studies scenarios.</code></td> </tr> </tbody> </table> |


#### EE3. Expert Elicitation: Using the Classical Model to Validate Experts’ Judgments
  |       Abbrev   |	Categories and data			 |
  |----------------|-------------------------------|
  | |<table>  <tbody>  <tr> <td>Title</td>  <td> Expert Elicitation: Using the Classical Model to Validate Experts’ Judgments [ <a href="https://www.journals.uchicago.edu/doi/full/10.1093/reep/rex022">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> Review of thirty-three professionally contracted classical model studies that were performed between 2007 and March 2015 using the EXCALIBUR software package for structured expert judgement elicitation using Cooke’s Classical Model. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-3-R|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input and weighting through the EXCALIBUR tool.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Cooke Classical model</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Scoring of individual variables</li> <li>Scoring of average probabilities</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code>  <ul> <li><a href="https://www.lighttwist.net/wp/excalibur/">EXCALIBUR Windows Tool</a></li> <li><a href="https://github.com/grongen/anduryl/releases">EXCALIBUR Python Tool</a></li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


### Uncertainty treatment methodologies

#### U1. How Certain is Good Enough? Managing Data Quality and Uncertainty in Ordinal Citizen Science Data Sets for Evidence-Based Policies on Fresh WateR
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> How Certain is Good Enough? Managing Data Quality and Uncertainty in Ordinal Citizen Science Data Sets for Evidence-Based Policies on Fresh Wate [ <a href="https://doi.org/10.5334/cstp.592">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe focuses on the collection of data sets for water quality involving the active contribution of citizens, offering an additional way to study and treat data gaps and uncertainties.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> EV-U-1|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Input: (i) Temperature, (ii) Oxygen parameters, (iii) Turbidity, and (iv) pH. </li> <li>Indicators concerning: (i) Aquatic plants, (ii) Water flow, (iii) Water depth, and (iv) Riverbank characteristics. </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Water Blitz events: instructions combined with a sampling kit. </li> <li>Measuring the nitrate-nitrogen and phosphate-phosphorus concentration as collected from the field kits. </li> <li>Coordinated measurements via GPS. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Citizen science contributes to monitoring activities. </li> <li>Development of resilient ways to interact with the aquatic ecosystems. </li> <li>Contribution to awareness and reflection. </li> <li> Addresses an uncertainty in a sustainable government.  </li> <li> Limitations: (i) Role of the citizen science in the community, (ii) Individual characteristics of water systems and parameters, and (iii) Public access to environmental data from government(s).  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Social-ecological systems; Water quality, Monitoring; Uncertainty. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty treatment methodology for trials and mini-trials. </code></td> </tr> </tbody> </table> |


#### U2. Where does scientific uncertainty come from, and from whom? Mapping perspectives of natural hazards science advice
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Where does scientific uncertainty come from, and from whom? Mapping perspectives of natural hazards science advice [ <a href="https://doi.org/10.1016/j.ijdrr.2023.103948">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe focuses on identifying sources of uncertainty associated with natural hazards using mental model mapping and a semi-structured interview protocol.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-U-2|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>The area of study was exposed frequently to a wide variety of natural hazards. </li> <li>A range of participants was recruited using the snowball approach. </li> <li>In total twenty-five (25) participants ranged from twenty-five (25) to seventy-five (75) years old.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Aims: (i) Understand what a disaster risk is, (ii) Integrate technology in decision-making about risk, and (iii) Find disaster risk communication methodologies. </li> <li>A three-face interview was constructed "to understand individual's perceptions of uncertainty associated with natural hazards" + brainstorming + indirect elicitation questions.  <ul> <li> A systematic review of mental model interview approaches. </li>  <li> Conceptual cognitive concept mapping (3CM). </li>  </ul> </li> <li>Mental models approach: <ul> <li> Key concepts: (i) Uncertainty, (ii) Knowledge, and (iii) Science.  </li> <li> Sources of uncertainty: (i) The scientists, (ii) The media, (iii) The communicators, (iv) The range of possible outcomes, (v) Human responses, and (vi) The unknown unknowns. </li>  </ul>  </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Individual's mental models to identify sources of uncertainty: (i) Actors, and (ii) Known unknowns. </li> <li>Translate uncertainty in a meaningful way for the people (the public).</li> <li>Creation of science-policy interfaces for effective decision-making frameworks in disaster management crisis. </li> <li> Key influences for uncertainty: (i) Governance and funding, (ii) Societal factors, (iii) Outcomes, (iv) Emotions, (v) The communication landscape, and (vi) Decision-making.  </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://www.civildefence.govt.nz/cdem-sector/plans-and-strategies/national-disaster-resilience-strategy/">National Emergency Management Agency's National Disaster Resilience Strategy. </a> </li> <li> <a href="https://resiliencechallenge.nz/">Resilience to Nature's Challenge is one of Aotearoa New Zealand's National Science Challenges. </a> </li> <li> <a href="http://www.quakecore.nz/">QuakeCoRE is the NZ Centre of Research Excellence for Earthquake Resilience. </a> </li>  </ul>  </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty; Mental models; Natural hazards; Societal and economic factors. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Communicating uncertainties associated with complex events hazard/impact scenario assessment to decision makers. </code></td> </tr> </tbody> </table> |


#### U3. A review of uncertainty quantification in deep learning: Techniques, applications and challenges
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> A review of uncertainty quantification in deep learning: Techniques, applications and challenges [ <a href="https://doi.org/10.1016/j.inffus.2021.05.008">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe presents the application of Bayesian and ensemble techniques in various domains discussing the recent advancements in uncertainty methods within deep learning for optimization and decision-making processes.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-U-3-R|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> N/A  </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Quantification methods:  <ul> <li>Bayesian techniques: (i) Monte Carlo (MC) dropout, (ii) Markov chain Monte Carlo (MCMC), (iii) Variational inference (VI), (iv) Bayesian Active Learning (BAL), (v) Bayes by Backprop (BBB), (vi) Variational autoencoders, (vii) Laplacian approximations, and (viii) Uncertainty quantification in reinforcement learning. </li> <li>Ensemble techniques: (i) Deep NNs (DNNs), (ii) Deep ensemble Bayesian/Bayesian deep ensemble, and (iii) Uncertainty in Dirichlet deep networks. </li> <li>Uncertainties: (i) Two main types of uncertainty: (a) epistemic (model uncertainty) and (b) aleatoric (data uncertainty). (ii) Three (3) uncertainly models were considered: (1) the MC dropout, (2) the Bootstrap model, and (3) the GMM model. </li> </ul> </li> <li>Others: <ul> <li>Neural Architecture Distribution Search (NADs). </li><li>Single model estimates for DNNs of epistemic and aleatoric uncertainty.</li> <li>Method to find and reject distribution data points for training a deterministic deep model with a single forward pass at test time. </li> <li>MC-DropConnect. </li> <li>Gradient-based optimization techniques. </li> <li>Noise contrastive priors (NCPs) to estimate consistent uncertainty. </li><li>Uncertainty-based class imbalance learning.</li><li>Variational approximation, termed Bayes by hypernet. (BbH), deducting hypernetworks as implicit distributions. </li><li>I Do not Know (IDK) prediction cascade approach. </li><li>Models inspired by the nonlinear differential equations utilized by physics-informed neural networks. </li><li>ProbDepthNet. </li><li>DNNs trained with mix-up.</li><li>Local interpretable model-agnostic explanations (LIME). </li><li>Randomized approach sampling from the hidden layers. during the DNN interference period. </li><li>Certainty-driven consistency loss (CCL) method. </li><li>Modified knowledge distillation method.</li><li>Models based on kernel techniques. </li><li>Stochastic quantized activation distributions (SQUAD). </li><li>Probabilistic DL method (approximate Bayesian inference + heteroscedastic noise technique). </li><li>Gaussian Processes (GP). </li><li>Stochastic, low-rank, approximate natural gradient (SLANG) technique. </li><li>Dubbed prior networks (PNs). </li><li>DVERGE</li> <li> Direct epistemic uncertainty prediction (DEUP). </li> <li> Subjective Bayesian GNN (S-BGNN). </li> <li> Doubly stochastic variational neural process (DSVNP). </li> <li> Non-Bayesian NN models </li> <li> kol </li> <li> Uncertainty-aware deep Dirichlet neural networks. </li> <li> Deep Gaussian processes (DGPs): (i) In combination with stochastic weight averaging (SWA), (ii) SWA-Gaussian, (iii) GPDNNs: a hybrid model of GP and DNNs, (iv) GPs + YOLOv3, (v) A natural gradient-based algorithm for Gaussian mean-field, (vi) Matrix variate Gaussian (MVG), and (vii) Introduction of a variety of stochastic layers. </li> <li> A variety of other techniques uniquely specified and tailored for desired applications are listed within the last subsections of the paper.  </li> </ul></li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Gaps and methods to approach them: (1) Fusion-based methods, (2) Ensemble methods, (3) Decision making, (4) Active learning, (5) Transfer learning, (6) Neural architecture search (NAS) methods, (7) Self-supervised learning (SSL) methods, (8) Hypernetworks, (9) Continual learning, (10) GNNs: Graph Neural Networks, (11( BO: global optimization method for optimizing time-consuming black-box objective functions, and (12) Uncertainty calibration. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> N/A </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty quantification; Deep learning; Machine learning; Bayesian statistics; Ensemble learning; Review article. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard Data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty quantification in propagation of damage following consecutive compound events and/or cascading effects (Climate Change and Hazard data). </code></td> </tr> </tbody> </table> |


#### U4. SHELF: The Sheffield Elicitation Framework
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> SHELF: The Sheffield Elicitation Framework [ <a href="https://link.springer.com/chapter/10.1007/978-3-319-65052-4_4">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> R-based package of documents, templates and software to carry out elicitation of probability distributions for uncertain quantities from a group of experts. </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> CH-EV-4|<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Expert input and weighting through the SHELF package of documents, templates and software.</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Single expert</li> <li>Multiple experts</li> <li>Bivariate elicitation</li> <li> Dirichlet elicitation </li> <li> Extension method (continuous) </li> <li> Extension method (discrete) </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Probability distribution with respect to elicited variables.</li> <li>Multiple visual, graph and table formats. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://shelf.sites.sheffield.ac.uk/">SHELF Tool</a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Expert elicitation; Uncertainty quantification.</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Climate Change and Hazard data; Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Assess probability of compound events and cascading effects in selected case studies scenarios; Assess variables related to exposure and vulnerability analyses for specific single-hazards.</code></td> </tr> </tbody> </table> |


#### U5. Combining Quantitative and Qualitative Measures of Uncertainty in Model-Based Environmental Assessment: The NUSAP System
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> Combining Quantitative and Qualitative Measures of Uncertainty in Model-Based Environmental Assessment: The NUSAP System [ <a href="https://doi.org/10.1111/j.1539-6924.2005.00604.x">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> This recipe showcases the applicability of a system designed to combine quantitative and qualitative uncertainty measures, demonstrating its effectiveness for accessing both parameter uncertainty and model assumptions.  </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Data from environmental policy issues, for example, emissions of acidifying gases (NO~x~, SO~2~, and NH~3~). </li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Treatment of multidimensional uncertainty assessment with increasing complexity. </li> <li>Emission monitoring systems, complex energy models, and environmental indicators are used. </li> <li>NUSAP is applied to complex models in a meaningful way. </li> <li> Ability to serve as a diagnostic tool for assessing the robustness of a given knowledge base for policy-making. </li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Numeral Unit Spread Assessment Pedigree (NUSAP) system for multidimensional uncertainty assessment. </li> <li>Potentially applicable for ICARIA use cases/trials, etc...</li> <li>A tool for prioritizing uncertainties qualitatively and quantitatively. </li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> <ul> <li> <a href="https://doi.org/10.1007/s11069-016-2364-3">A framework to assess quality and uncertainty in disaster loss data </a> </li> </ul> </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Uncertainty; Controversy; Value-laden assumptions; Problem frames; Diagnostic analysis. </td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Exposure and Vulnerability data.</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> Uncertainty treatment methodology for trials and mini-trials. </code></td> </tr> </tbody> </table> |


### Other methodologies related to hazard, exposure, and vulnerability.

#### HEV1. Urban pluvial flood modelling in the absence of sewer drainage network data: A physics-based approach
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV2. Storm damage beyond wind speed – Impacts of wind characteristics and other meteorological factors on tree fall along railway lines
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV3. OpenStreetMap for multi-faceted climate risk assessments
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV4. On the positioning of emergencies detection units based on geospatial data of urban response centres
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV5. Advancing building data models for the automation of high-fidelity regional loss estimations using open data
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV6. Estimating exposure of residential assets to natural hazards in Europe using open data
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV7. Asset exposure data for global physical risk assessment
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV8. Mapping Europe into local climate zones
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV9. CLIMADA v1: a global weather and climate risk assessment platform
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |


#### HEV10. Comparing an insurer’s perspective on building damages with modelled damages from pan-European winter windstorm event sets: a case study from Zurich, Switzerland
|       Abbrev   |	Categories and data			 |
|----------------|-------------------------------|
| |<table>  <tbody>  <tr> <td>Title</td>  <td> text [ <a href="https://www.tutorialspoint.com/" target="_self">Link</a> ] </td> </tr> <tr> <td>Summary</td> <td> text </td></tr> <tr> </tr> </tbody>  </table>|
|Recipe Number <br> |<table>  <thead> <tr> <tr> <th></th> <th> </th> <th> </th>  </tr> </thead>  <tbody> <tr> <td> </td>  <td>Variables (Input)</td> <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> </code></td> </tr>  <tr> <td></td>  <td>Methods/Models</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td>   </tr>  <tr> <td> </td> <td>Results/Remarks</td>  <td><code> <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul></code></td> </tr>  <tr> <td>Resources</td> <td  colspan="2"> <code> Results/Remarks </code> </td> </tr>  <tr> <td>Keywords</td> <td  colspan="2">Results/Remarks</td> </tr> <tr> <td>Tag/Type</td> <td colspan="2">Results/Remarks</td> </tr> <tr> <td>Application in ICARIA</td> <td>Potential use in ICARIA </td>  <td><code> text</code></td> </tr> </tbody> </table> |

